{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2OvlxnFIsNyT"},"source":["# Demo Transformer Model para clasificar (atributo clase discreto) o estimar (atributo clase continuo) usando Serie Temporal\n","\n","Basado en \n"," \n"," https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3\n"," \n"," https://medium.com/mlearning-ai/transformer-implementation-for-time-series-forecasting-a9db2db5c820\n"," \n"," https://keras.io/examples/timeseries/timeseries_transformer_classification/"]},{"cell_type":"code","metadata":{"cellView":"form","id":"fOLnMhAYa4WJ"},"source":["#@title Librerías a usar\n","from tensorflow import keras\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import plot_model\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import math\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","import os\n","import csv\n","\n","print(\"Librerías cargadas\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"VheGnNxQa4WL"},"source":["#@title Acceder al Drive\n","\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# directorio local en Google Drive\n","path = '/content/gdrive/My Drive/IA/demoML/datos/'  #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"4Z_JWyyVa4WM"},"source":["#@title Cargar datos\n","\n","## selección de los parámetros \n","\n","def cargarNombreClases(path, archivo_datos, atributo_clase, nombre_clases):\n","  # importa definición de la clase\n","  arClasesFN = archivo_datos.split('.')[0] + '_nombreClases.txt'\n","  if os.path.isfile( path + '/' + arClasesFN ):\n","    with open( path + '/' + arClasesFN, mode='r') as csvfile:\n","        r = csv.reader(csvfile, delimiter=',')\n","        auxAtributo = r.__next__()\n","        auxClases = r.__next__()\n","    print('\\n> Definición de los valores discretos para la clase cargada de ' + arClasesFN +'.\\n')\n","    return auxAtributo[0], ','.join(auxClases)\n","  else:\n","    return atributo_clase, nombre_clases\n","\n","#@markdown ### Archivo de datos a utilizar:\n","archivo_datos = 'CLIMA.csv'  #@param {type:\"string\"}\n","#@markdown ### Nombre del atributo clase / objetivo:\n","atributo_clase = 'CantLluvia' #@param {type:\"string\"}\n","#@markdown ### Descripción de los valores del atributo clase / objetivo:  (nota: siempre debe comienzar en 0, por lo que si no tiene valor 0, agregar \"na\")\n","nombre_clases = '-' #@param {type:\"string\"}\n","\n","## aplicación de los parámetros elegidos\n","\n","# configura para que muestre todas las columnas y filas\n","pd.options.display.max_rows = 100\n","pd.options.display.max_columns = 100\n","\n","# Carga los datos del CSV y muestra los primeros\n","df = pd.read_csv(path + archivo_datos)\n","print(\"Archivo de datos \", archivo_datos, \" cargado\")\n","\n","print(\"\\n> Cabecera: \")\n","print(df.head())\n","print(\"\\n> Características: \")\n","print(df.describe())\n","\n","\n","# intenta cargar configuración asociada a los datos\n","if atributo_clase == '' or  atributo_clase == '-':\n","  # trata de obtener la configuración del archivo asociado\n","  atributo_clase, nombre_clases = cargarNombreClases(path, archivo_datos, atributo_clase, nombre_clases)\n","\n","# define nombre atributo de CLASE para ejemplo IRIS\n","ClassAttributeName = atributo_clase\n","\n","print(\"\\n> Atributo clase \", ClassAttributeName, \": [\", nombre_clases, \"]\")\n","\n","# genera los datos solo con la clase para entrenar y probar\n","Yori = np.array(df.pop(ClassAttributeName))\n","Xori = np.array(df)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"nTLcpIxCa4WO"},"source":["#@title Normalizar datos de entrada (opcional)\n","\n","aplica_normalizacion = False #@param {type:\"boolean\"}\n","#@markdown Si se aplica, seleccione el tipo de método de normalización a aplicar:\n","tipo_normalizacion = \"Standard Scaler\" #@param [\"Standard Scaler\", \"MinMax Scaler\", \"MaxAbs Scaler\", \"Robust Scaler\"]\n","\n","if aplica_normalizacion:\n","\n","  print(\"10 primeros datos de Entrada antes de normalizar: \")\n","  print(Xori[:10])\n","\n","  from sklearn import preprocessing\n","\n","  # elegir el método de normalización\n","  if tipo_normalizacion == \"Standard Scaler\": \n","    scaler = preprocessing.StandardScaler()\n","  elif tipo_normalizacion == \"MinMax Scaler\": \n","    scaler = preprocessing.MinMaxScaler()\n","  elif tipo_normalizacion == \"MaxMax Scaler\": \n","    scaler = preprocessing.MaxAbsScaler()\n","  elif tipo_normalizacion == \"Robust Scaler\": \n","    scaler = preprocessing.RobustScaler()\n","  \n","  # normaliza los datos de entrada\n","  X = scaler.fit_transform(X)\n","\n","  print(\"\\n\\n10 primeros datos de Entrada después de normalizar: \")\n","  print(Xori[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"KHhARaY3a4WO"},"source":["#@title Generar secuencia de datos como Serie\n","\n","cantidad_intervalos_secuencia = 1 #@param {type:\"integer\"}\n","\n","usar_atributos_secuencia = \"Solo atributos de Entrada\" #@param [\"Solo atributo a Estimar\", \"Solo atributos de Entrada\", \"Todos\"]\n","\n","if cantidad_intervalos_secuencia < 1:\n","  cantidad_intervalos_secuencia = 1\n","\n","# funciones auxilliares\n","def split_sequence(datosX, datosY, n_steps, atr_seq):\n","  x, y = [], []\n","  if len(datosX) != len(datosY):\n","    print(\"No coincide el largo de los datos X e Y!!!\")\n","    return None, None\n","  for i in range(len(datosY)):\n","    # find the end of this pattern\n","    end_ix = i + n_steps\n","    # check if we are beyond the sequence\n","    if end_ix > len(datosY)-1:\n","      break\n","    # gather input and output parts of the pattern\n","    if atr_seq == \"Y\":\n","      # sólo atributo a estimar (anteriores)\n","      seq_x = datosY[i:end_ix]\n","      seq_y = datosY[end_ix]   \n","    elif atr_seq == \"X\":\n","      # sólo atributos de entrada (anteriores y actuales)\n","      seq_x = datosX[i:end_ix]\n","      seq_y = datosY[end_ix-1]   \n","    else:\n","      # atributos de entrada y a estimar (anteriores)\n","      seq_xa = datosX[i:end_ix]\n","      seq_xb = datosY[i:end_ix] \n","      seq_y = datosY[end_ix]  \n","      seq_x = []\n","      for xa, xb in zip(seq_xa, seq_xb):        \n","        xa = list(xa)\n","        xa.append(xb)\n","        seq_x.append(xa)\n","\n","    x.append( seq_x )\n","    y.append( seq_y )\n","  return np.array(x), np.array(y)\n","\n","# muestra los primeros \"cant\" datos\n","def mostrarEjemplos(X, Y, cant=5):\n","  for i in range(min(len(X), cant)):\n","    print(X[i], Y[i])\n","  print(\"\\n\")\n","\n","print(\"\\n> Antes de generar serie: \")\n","mostrarEjemplos(Xori, Yori)\n","\n","# genera secuencias\n","print(\"> Generando series con \", cantidad_intervalos_secuencia ,\" intervalos \")\n","if (Xori.shape[1] == 0) or usar_atributos_secuencia == \"Solo atributo a Estimar\": \n","  atrSeq = \"Y\"\n","  cant_atributos_entrada = 1\n","elif usar_atributos_secuencia == \"Solo atributos de Entrada\":\n","  atrSeq = \"X\"\n","  cant_atributos_entrada = Xori.shape[1]\n","else: # \"Todos\"\n","  atrSeq = \"XY\"\n","  cant_atributos_entrada = Xori.shape[1] + 1\n","X, Y = split_sequence(Xori, Yori, cantidad_intervalos_secuencia, atrSeq)\n","\n","print(\"\\n> Después de generar serie: \")\n","mostrarEjemplos(X, Y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Preparar datos \n","\n","#@markdown Determina si el atributo clase debe ser considerado como Discreto o Continuo\n","considerar_atributo_clase = \"continuo - ESTIMACION\" #@param [\"dicreto - CLASIFICACION\", \"continuo - ESTIMACION\"] \n","\n","#@markdown Porcentaje de datos para usar en el entrenamiento:\n","proporcion_porcentaje_datos_entrenamiento =   75#@param {type:\"integer\"}\n","\n","# determina la proporción a usar para entrenar y probar\n","if proporcion_porcentaje_datos_entrenamiento>100:\n","  propTrain = 1\n","elif proporcion_porcentaje_datos_entrenamiento<1:\n","  propTrain = 0.1\n","else:\n","  propTrain = proporcion_porcentaje_datos_entrenamiento/100\n","\n","# determina si es problema de clasificación o estimación\n","esProblemaClasificacion = (considerar_atributo_clase[0].upper() == \"D\")\n","\n","\n","# reshape de [cant ejemplos, datos entrada] into [cant ejemplos, intervalos, datos entrada]\n","X =  X.reshape((X.shape[0], cantidad_intervalos_secuencia, cant_atributos_entrada))\n","\n","# separa al azar usando muestreo con proporción indicada\n","if esProblemaClasificacion:\n","  # intenta hacer muestreo estatificado \n","  try:\n","    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain), stratify=Y)\n","  except ValueError:\n","    print(\"-- No se puede aplicar Muestreo Estratificado! -> se usa Muestreo Simple \\n\")\n","    # hace muestreo simple\n","    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain))\n","else:\n","  # hace muestreo simple\n","  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain))\n","\n","CLASES = []\n","if esProblemaClasificacion:\n","  print(\"> se considera problema de CLASIFICACIÓN \\n\")\n","\n","  # define nombre de clases     \n","  if (nombre_clases == \"\") or (nombre_clases == \"-\"):\n","      # toma los valores de clase orginales del archivo\n","      for val in range(np.max(Y)+1):\n","        CLASES.append( \"clase {:>3}\".format(val) )\n","  else:\n","      # toma configuración de nombre de clases\n","      for val in nombre_clases.split(','):\n","        CLASES.append( val )\n","\n","  # genera salida codificada para softMax\n","  y_trainEnc =  np_utils.to_categorical(y_train)\n","  y_testEnc =  np_utils.to_categorical(y_test)\n","\n","  # muestra resultados\n","  print(\"> Definición de CLASES: \")\n","  print(\" - dictMapeo (\", len(CLASES), \"): \", CLASES)\n","else:\n","  print(\"> se considera problema de ESTIMACIÓN \\n\")\n","\n","  y_trainEnc = []\n","  y_testEnc =  []\n","\n","\n","print(\"\\n> Para Entrenamiento: \")\n","print(\" - x_train (cant ejemplos, intervalos, datos entrada): \", x_train.shape)\n","print(\" - y_train (cant): \", len(y_train))\n","if esProblemaClasificacion:\n","  for i in range(len(CLASES)):\n","    cant = 0\n","    for y in y_train:\n","      if i == y: cant = cant + 1\n","    print(\"    \", CLASES[i], \"[\", i, \"]:\", cant)\n","\n","print(\"\\n Para Prueba: \")\n","print(\" - x_test (cant ejemplos, intervalos, datos entrada): \", x_test.shape)\n","print(\" - y_test (cant): \", len(y_test))\n","if esProblemaClasificacion:\n","  for i in range(len(CLASES)):\n","    cant = 0\n","    for y in y_test:\n","      if i == y: cant = cant + 1\n","    print(\"    \", CLASES[i], \"[\", i, \"]:\", cant)\n"],"metadata":{"cellView":"form","id":"bKTkkIYpJCYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Establecer modelo\n","\n","#@markdown ### Parámetros para capas Transfotmer:\n","trnsf_MultiHeadAttention_head_size = 256 #@param {type: \"integer\"}\n","trnsf_MultiHeadAttention_num_heads = 4 #@param {type: \"integer\"}\n","trnsf_MultiHeadAttention_cant_bloques = 4 #@param {type: \"integer\"}\n","trnsf_Conv1D_cant_filters = 4 #@param {type: \"integer\"}\n","trnsf_porc_capa_DropOut = 0.25 #@param {type:\"number\"}\n","\n","#@markdown ### Parámetros de las capas Lineales:\n","lineal_cant_neuronas_capas_ocultas = '128,  64' #@param {type:\"string\"}\n","lineal_porc_capa_DropOut = 0.4 #@param {type:\"number\"}\n","\n","#@markdown ### Parámetros de la capa de Salida:\n","red_tipo_capa_salida = 'lineal-Numero' #@param [\"lineal-Numero\", \"softmax-MultiClase\"]\n","\n","#@markdown ### Parámetros del Optimizador:\n","opt_tipo = \"Adam\" #@param [\"Gradiente Decreciente\", \"Adam\", \"Adadelta\", \"Adagrad\", \"Adamax\", \"Nadam\", \"FTRL\"]\n","opt_learning_rate = 0.001 #@param {type: \"number\"}\n","\n","# aplica parámetros\n","\n","if trnsf_MultiHeadAttention_head_size < 1:\n","  trnsf_MultiHeadAttention_head_size = 1\n","\n","if trnsf_MultiHeadAttention_num_heads < 1:\n","  trnsf_MultiHeadAttention_num_heads = 1\n","\n","if trnsf_MultiHeadAttention_cant_bloques < 1:\n","  trnsf_MultiHeadAttention_cant_bloques = 1\n","\n","# cantidad de neuronas ocultas \n","hidden_layers = []\n","for val in lineal_cant_neuronas_capas_ocultas.split(','):\n","  val = val.strip()\n","  if val.isnumeric():\n","    hidden_layers.append( val )\n","  else:\n","    print(\"Capa \", val, \"descartada!\")\n","\n","# chequea configuración de drop out\n","if trnsf_porc_capa_DropOut <= 0:\n","  trnsf_porc_capa_DropOut = 0.10\n","elif trnsf_porc_capa_DropOut > 0.9:\n","    trnsf_porc_capa_DropOut = 0.9\n","\n","# chequea configuración de drop out\n","if lineal_porc_capa_DropOut <= 0:\n","  lineal_porc_capa_DropOut = 0.10\n","elif lineal_porc_capa_DropOut > 0.9:\n","    lineal_porc_capa_DropOut = 0.9\n","\n","# define si el tipo de capa de salida es softmax( True )  o lineal ( False )\n","# esto implica también cambiar cómo se codifican los valores de las clases a usar\n","if esProblemaClasificacion:\n","  tipo_output_softMax = (red_tipo_capa_salida[:7] == 'softmax')\n","else:\n","  print(\"-- se considera salida lineal porque es problema de Estimación!\")\n","  tipo_output_softMax = False\n","\n","# funciones auxiliares para crear el modelo\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0, layname_sub=0):\n","    # Normalization and Attention\n","    x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"trn_nrm_\"+str(layname_sub))(inputs)\n","    x = tf.keras.layers.MultiHeadAttention(\n","        key_dim=head_size, num_heads=num_heads, dropout=dropout, name=\"trn_mha_\"+str(layname_sub)\n","    )(x, x)\n","    x = tf.keras.layers.Dropout(dropout, name=\"trn_dp_\"+str(layname_sub))(x)\n","    res = x + inputs\n","    # Feed Forward Part\n","    x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"ffp_nrm_\"+str(layname_sub))(res)\n","    x = tf.keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\", name=\"ffp_cnn_\"+str(layname_sub)+\".1\")(x)\n","    x = tf.keras.layers.Dropout(dropout, name=\"ffp_dp_\"+str(layname_sub))(x)\n","    x = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1, name=\"ffp_cnn_\"+str(layname_sub)+\".2\")(x)\n","    return x + res\n","\n","def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0,\n","    mlp_dropout=0,\n","    output_softMax_num_Clases=0,\n","):\n","    inputs = keras.Input(shape=input_shape, name=\"input\")\n","    # agrega bloques transfomer\n","    x = inputs\n","    for n in range(num_transformer_blocks):\n","        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout, (n+1))\n","\n","    # genera un flatten especial\n","    x = tf.keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\", name=\"gap\")(x)\n","    \n","    # agrega bloques lineales\n","    i = 1\n","    for dim in mlp_units:\n","        x = tf.keras.layers.Dense(dim, activation=\"relu\", name=\"lineal_\"+str(i))(x)\n","        x = tf.keras.layers.Dropout(mlp_dropout, name=\"lineal_dp_\"+str(i))(x)\n","        i = i + 1\n","    \n","    if output_softMax_num_Clases <= 0:\n","      # se genera una capa lineal con una salida numérica\n","      outputs = tf.keras.layers.Dense(1, activation=None, name='output')(x)\n","    else:\n","      # se genera una salida softmax \n","      outputs = tf.keras.layers.Dense(units = len(CLASES), activation='softmax', name='output')(x)\n","\n","    return keras.Model(inputs, outputs)\n","\n","# determina tipo de entrada\n","input_shape = x_train.shape[1:]\n","\n","# crea el modelo del Transformer\n","model = build_model(\n","    input_shape,\n","    head_size = trnsf_MultiHeadAttention_head_size, #256,\n","    num_heads = trnsf_MultiHeadAttention_num_heads, # 4,\n","    ff_dim =  trnsf_Conv1D_cant_filters, # 4,\n","    num_transformer_blocks = trnsf_MultiHeadAttention_cant_bloques,\n","    mlp_units = hidden_layers,\n","    mlp_dropout = lineal_porc_capa_DropOut,\n","    dropout = trnsf_porc_capa_DropOut,\n","    output_softMax_num_Clases = (len(CLASES) if tipo_output_softMax else 0),\n",")\n","\n","if opt_tipo == \"Gradiente Decreciente\":\n","  opt = keras.optimizers.SGD(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adam\":\n","  opt = keras.optimizers.Adam(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adadelta\":\n","  opt = keras.optimizers.Adadelta(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adagrad\":\n","  opt = keras.optimizers.Adagrad(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adamax\":\n","  opt = keras.optimizers.Adamax(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Nadam\":\n","  opt = keras.optimizers.Nadam(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"FTRL\":\n","  opt = keras.optimizers.Ftrl(learning_rate=opt_learning_rate)\n","else:\n","  opt = keras.optimizers.Adam()\n","\n","# genera el modelo \n","if tipo_output_softMax:\n","    # utiliza un loss de multiple clases\n","    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","else:\n","    # utiliza un loss de valor numérico\n","    if esProblemaClasificacion:\n","      model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n","    else:\n","      model.compile(optimizer=opt, loss='mse', metrics=['RootMeanSquaredError'])\n","\n","print(\"Modelo creado con \", len(model.layers), \" capas:\")\n","model.summary()\n","print(\"\\n\")\n","plot_model(model, show_layer_names=True, show_shapes=True)\n"],"metadata":{"cellView":"form","id":"0pryP6f3bSju"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"6xMzL3OTa4WU"},"source":["#@title Entrenar\n","\n","cant_epocas_entrenamiento = 250 #@param {type:\"integer\"}\n","\n","# cantidad de épocas del entrenamiento\n","cantEpocas = (1 if cant_epocas_entrenamiento<1 else cant_epocas_entrenamiento)\n","\n","activar_corte_por_estabilidad_error_val = False #@param {type:\"boolean\"}\n","\n","# separa al azar usando muestreo al azar del 10%\n","# para tomar algunos como datos de validación\n","x_t, x_v, y_t, y_v = train_test_split(x_train, \n","                                       (y_trainEnc if tipo_output_softMax else y_train), \n","                                       test_size=0.1)\n","\n","\n","print(\"\\n> De los \", len(x_train), \"ejemplos de entrenamiento: \")\n","print(\"            se usan \", len(x_t), \"ejemplos para entrenar \")\n","print(\"            y \", len(x_v), \"ejemplos para validar.\")\n","\n","print(\"\\n\\n>Comienza el Entrenamiento:\")\n","\n","if activar_corte_por_estabilidad_error_val:\n","  # se agrega un callBack para que corte \n","  # si el error de validación no sigue bajando\n","  # y devuelva los mejores pesos obtenidos\n","  early_stopping_monitor = keras.callbacks.EarlyStopping(\n","      monitor='val_loss',\n","      min_delta=0.01,\n","      patience=20,\n","      verbose=0,\n","      mode='min',\n","      baseline=None,\n","      restore_best_weights=True\n","  )\n","  callbacksEntr = [early_stopping_monitor]\n","else:\n","  early_stopping_monitor = None\n","  callbacksEntr = []\n","\n","# lleva a cabo el entrenamiento\n","history = model.fit(x_t, y_t,\n","          epochs = cantEpocas, \n","          validation_data=(x_v, y_v,),\n","          callbacks=callbacksEntr ) \n","\n","print(\"\\n>Entrenamiento Finalizado.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"yxLrIqlga4WV"},"source":["#@title Mostrar Gráficos del Entrenamiento\n","plt.figure(figsize=(15,8)) \n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Gráfico del Error del Entrenamiento')\n","plt.ylabel('')\n","plt.xlabel('epoch')\n","plt.legend(['entrenamiento', 'validación'], loc='upper left')\n","plt.show()\n","\n","plt.figure(figsize=(15,8)) \n","if esProblemaClasificacion:\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Gráfico de la Exactitud del Entrenamiento')\n","else:\n","  plt.plot(history.history['root_mean_squared_error'])\n","  plt.plot(history.history['val_root_mean_squared_error'])\n","  plt.title('Gráfico de la Distancia Media Cuadrática Mínima del Entrenamiento')\n","  \n","plt.ylabel('')\n","plt.xlabel('epoch')\n","plt.legend(['entrenamiento', 'validación'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"RG4Tev_Va4WV"},"source":["#@title Probar red entrenada con datos de entrenamiento\n","\n","mostrar_detalle_entrenamiento = False #@param {type:\"boolean\"}\n","\n","# función auxiliar para el cálculo de error\n","def calcErrores(pred, real, mostrarDetalle=False):\n","  arAbs = []\n","  arRel = []\n","  \n","  if mostrarDetalle:\n","    print(\"\\n\")\n","    print(\"\\t Real \\t\\t\\t Estimado \\t\\t Error Absoluto \\t Error Relativo\")\n","\n","  for pV, r in zip(pred, real):\n","    # toma el valor estimado/predecido\n","    p = pV[0]\n","    # controla que sean números\n","    if not(math.isnan(r) or math.isnan(p)):\n","      # hace los cálculos\n","      eAbs = abs(r - p)\n","      if r != 0:\n","        eRel = (eAbs / r)*100.0\n","      else:\n","        eRel = (eAbs / 0.00001)*100.0\n","      arAbs.append(eAbs)\n","      arRel.append(eRel)\n","    \n","      if mostrarDetalle:\n","        print(\"\\t{:>8.2f} \\t\\t {:>8.2f} \\t\\t {:>8.2f} \\t\\t {:>8.2f}%\".format(r, p, eAbs, eRel))\n","\n","  return arAbs, arRel\n","\n","def generarGrafico(ar, tit, b=10, c=None):\n","     # genera gráfico de los errores\n","    fig = plt.figure(figsize=(15,5)) \n"," #   ax = fig.add_axes( [0, 0, 0.8, 0.8] )\n"," #   ax.boxplot( [arAbs, arRel] )\n"," #   ax.set_xticklabels( [\"Error Absoluto\", \"Error Relativo\"] )\n","#    plt.legend([\"Error Absoluto\", \"Error Relativo\"], loc='best')\n","    plt.hist( ar, bins=b, color=c )\n","    plt.grid(color='lightgrey', which='both', axis='both', linestyle='solid', linewidth=0.3)\n","    plt.title(\"Distribución de \"+ tit)\n","    plt.show()\n","\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo_Estimacion(x, y, detalle=False):\n","\n","    # procesa las imágenes de prueba con el modelo \n","    estimVals = model.predict(x, verbose=0)\n","\n","    # llama a la función\n","    arAbs, arRel = calcErrores(estimVals, y, detalle)\n","\n","    # muestra métricas\n","    print(\"\\n\")\n","    print(\"\\n Error Absoluto: \")\n","    print(\"            Mínimo: {:.5f} \".format(np.min(arAbs)) )\n","    print(\"            Promedio: {:.5f} ± {:.5f}\".format(np.mean(arAbs), np.std(arAbs)) )\n","    print(\"            Máximo: {:.5f} \".format(np.max(arAbs)) )\n","    generarGrafico(arAbs, \"Error Absoluto\", 20, \"red\")\n","    \n","    print(\"\\n Error Relativo: \")\n","    print(\"            Mínimo: {:.2f}% \".format(np.min(arRel)) )\n","    print(\"            Promedio: {:.2f} ± {:.2f}\".format(np.mean(arRel), np.std(arRel)) )\n","    print(\"            Máximo: {:.2f}% \".format(np.max(arRel)) )\n","    generarGrafico(arRel, \"Error Relativo\", 10, \"magenta\")\n","\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo_Clasificacion(x, y, clases_map, mostrarDetalle=False):\n","\n","    # procesa las imágenes de prueba con el modelo \n","    predClass = model.predict(x, verbose=0)\n","\n","    # muestra los resultados con las imágenes \n","    umbralClas = 0.5\n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # prepara salida\n","        clReal = clases_map[ y[i] ] \n","\n","        # determina la clase predecida\n","        if tipo_output_softMax:\n","            ## determina clase predecida de acuerdo a la que tiene mayor valor\n","            idclPred = int( np.argmax(predClass[i], axis=0) )\n","            idclPredRnd = idclPred\n","        else:\n","            ## determina clase predecida de acuerdo al umbral de clasificación\n","            idclPred = predClass[i][0]       \n","            idclPredRnd = int(idclPred)\n","            if (idclPred - idclPredRnd)>0.5 and (idclPredRnd+1)<len(clases_map):\n","                    idclPredRnd = idclPredRnd + 1\n","\n","        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n","            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA\"\n","        else:      \n","            clPred = clases_map[ idclPredRnd ]\n","\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","\n","        strTitulo = 'Real: ' + str(clReal) + ' / Modelo(RNA): ' \n","        strTitulo = strTitulo + str(clPred) + ' (' + str( idclPred ) +')'   \n","        strTitulo = strTitulo + \": \" + (\"ok\" if (clPred==clReal) else \"error!\")\n","\n","        # muestra comparación con la imagen\n","        if mostrarDetalle:\n","          print(strTitulo)\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds))\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión ( real / modelo ): ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm, \n","        index=['r:{:}'.format(x) for x in clases_map], \n","        columns=['m:{:}'.format(x) for x in clases_map]\n","      )\n","    # agrega para poder mostrar la matrix de confusión completa\n","    pd.options.display.max_rows = 100\n","    pd.options.display.max_columns = 100\n","    cmtx.sort_index(axis=0, inplace=True)\n","    cmtx.sort_index(axis=1, inplace=True)    \n","    print(cmtx)\n","    print(\"\\n\")\n","\n","    # gráfico de comparación\n","    plt.title('Gráfico de Confusión: ')\n","    plt.xlabel('Real')\n","    plt.ylabel('Modelo')\n","    plt.scatter(classReal, classPreds)\n","\n","# prueba con los datos de entrenamiento\n","print(\"*** Resultados con datos de Entrenamiento: \")\n","if esProblemaClasificacion:\n","  probarModelo_Clasificacion(x_train, y_train, CLASES, mostrar_detalle_entrenamiento)\n","else:\n","  probarModelo_Estimacion(x_train, y_train, mostrar_detalle_entrenamiento)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dv_ndi4Qa4WX"},"source":["6) Evaluar el modelo de la RNA entrenado con los datos de prueba:"]},{"cell_type":"code","metadata":{"cellView":"form","id":"MIvpw5pya4WY"},"source":["#@title Probar red entrenada con datos de prueba\n","mostrar_detalle_prueba = True #@param {type:\"boolean\"}\n","\n","  # evalua al modelo entrenado\n","resEval = model.evaluate(x_test, (y_testEnc if tipo_output_softMax else y_test), verbose=0)\n","print(\"\\n>Evaluación del Modelo: \")\n","print(\"    - Error: \", round(resEval[0],3))\n","if esProblemaClasificacion:\n","  print(\"    - Exactitud: \", round(resEval[1]*100,2))\n","else:\n","  print(\"    - Distancia Media Cuadrática Mínima: \", round(resEval[1],3))\n","  \n","#print(\"\\n\")\n","\n","# prueba con los datos de prueba\n","print(\"\\n\\n*** Resultados con datos de Prueba: \")\n","if esProblemaClasificacion:\n","  probarModelo_Clasificacion(x_test, y_test, CLASES, mostrar_detalle_prueba)\n","else:\n","  probarModelo_Estimacion(x_test, y_test, mostrar_detalle_prueba)\n"],"execution_count":null,"outputs":[]}]}