{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3868c680fcd341c58052af577661726f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "GridBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "GridBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "GridBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0064d19a236a46d895b62ccf5b0424f1",
              "IPY_MODEL_ce4ade1274e44cbb945e75ff2518f1c7",
              "IPY_MODEL_02836c64731c46bc9dd8e7f68349771c",
              "IPY_MODEL_5ba5cf0452bb46cab72aec6d4b16bdfc",
              "IPY_MODEL_5d1149d6670c491b8eaaa7122c52e7f3"
            ],
            "layout": "IPY_MODEL_8bcbe0a7eea44853ae601143b0a0be48"
          }
        },
        "0064d19a236a46d895b62ccf5b0424f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50268d98d2d44514a06a9f1275945ee8",
            "placeholder": "​",
            "style": "IPY_MODEL_8e5ec6a36d434e3a92a685907ec0f181",
            "value": "Ajuste para configuración de los Datos: "
          }
        },
        "ce4ade1274e44cbb945e75ff2518f1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "LargoSepalo",
              "AnchoSepalo",
              "LargoPetalo",
              "AnchoPetalo",
              "Clase"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Atributo clase:",
            "description_tooltip": null,
            "disabled": false,
            "index": 4,
            "layout": "IPY_MODEL_e7e8bd218b944198bd9e7f73d03849a9",
            "style": "IPY_MODEL_27a72003f91749009496f6f39bd59e8a"
          }
        },
        "02836c64731c46bc9dd8e7f68349771c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Nombre clases:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_67f1d67cd7c14295b4142ad9dda09bf0",
            "placeholder": "Ingrese nombre clases (si corresponde) separados por comas",
            "style": "IPY_MODEL_e1868d571961489dbfb6bd525559b35c",
            "value": "na,Setosa,Versicolor,Virginica"
          }
        },
        "5ba5cf0452bb46cab72aec6d4b16bdfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SelectMultipleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SelectMultipleModel",
            "_options_labels": [
              "LargoSepalo",
              "AnchoSepalo",
              "LargoPetalo",
              "AnchoPetalo",
              "Clase"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "SelectMultipleView",
            "description": "Atributos de entrada:",
            "description_tooltip": null,
            "disabled": false,
            "index": [
              0,
              1,
              2,
              3,
              4
            ],
            "layout": "IPY_MODEL_67af7badd26e4d51bfb7dc8579c959e8",
            "rows": 5,
            "style": "IPY_MODEL_121b504106714bbaad9659b92719d867"
          }
        },
        "5d1149d6670c491b8eaaa7122c52e7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Aplicar",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_6187a5128b4b4f749d0201e9e2bf0e8b",
            "style": "IPY_MODEL_1a2e589ea33e4cc2a6374a8dd16ab902",
            "tooltip": ""
          }
        },
        "8bcbe0a7eea44853ae601143b0a0be48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "50268d98d2d44514a06a9f1275945ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5ec6a36d434e3a92a685907ec0f181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7e8bd218b944198bd9e7f73d03849a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27a72003f91749009496f6f39bd59e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "67f1d67cd7c14295b4142ad9dda09bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1868d571961489dbfb6bd525559b35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "67af7badd26e4d51bfb7dc8579c959e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121b504106714bbaad9659b92719d867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "6187a5128b4b4f749d0201e9e2bf0e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2e589ea33e4cc2a6374a8dd16ab902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq5FIG7N-ulY"
      },
      "source": [
        "# Demo Deep Belief Network para para clasificar (atributo clase discreto) o estimar (atributo clase continuo)\n",
        "  Nota: se usan modelos copiados de https://github.com/albertbup/deep-belief-network porque falla al intentar instalarlos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noO34IYwDEFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23db29f6-71fa-41ae-e9d7-bfc8c979f7ef",
        "cellView": "form"
      },
      "source": [
        "#@title Librerías a usar\n",
        "\n",
        "# nota se debe indicar la versión 1 de TF para compatibilidad del código\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Box, Layout\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print (\"Librerías cargadas.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librerías cargadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clases copiadas de https://github.com/albertbup/deep-belief-network\n",
        "\n",
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import truncnorm\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, RegressorMixin\n",
        "\n",
        "\n",
        "def batch_generator(batch_size, data, labels=None):\n",
        "    \"\"\"\n",
        "    Generates batches of samples\n",
        "    :param data: array-like, shape = (n_samples, n_features)\n",
        "    :param labels: array-like, shape = (n_samples, )\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    n_batches = int(np.ceil(len(data) / float(batch_size)))\n",
        "    idx = np.random.permutation(len(data))\n",
        "    data_shuffled = data[idx]\n",
        "    if labels is not None:\n",
        "        labels_shuffled = labels[idx]\n",
        "    for i in range(n_batches):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "        if labels is not None:\n",
        "            yield data_shuffled[start:end, :], labels_shuffled[start:end]\n",
        "        else:\n",
        "            yield data_shuffled[start:end, :]\n",
        "\n",
        "\n",
        "def to_categorical(labels, num_classes):\n",
        "    \"\"\"\n",
        "    Converts labels as single integer to row vectors. For instance, given a three class problem, labels would be\n",
        "    mapped as label_1: [1 0 0], label_2: [0 1 0], label_3: [0, 0, 1] where labels can be either int or string.\n",
        "    :param labels: array-like, shape = (n_samples, )\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    new_labels = np.zeros([len(labels), num_classes])\n",
        "    label_to_idx_map, idx_to_label_map = dict(), dict()\n",
        "    idx = 0\n",
        "    for i, label in enumerate(labels):\n",
        "        if label not in label_to_idx_map:\n",
        "            label_to_idx_map[label] = idx\n",
        "            idx_to_label_map[idx] = label\n",
        "            idx += 1\n",
        "        new_labels[i][label_to_idx_map[label]] = 1\n",
        "    return new_labels, label_to_idx_map, idx_to_label_map\n",
        "\n",
        "class ActivationFunction(object):\n",
        "    \"\"\"\n",
        "    Class for abstract activation function.\n",
        "    \"\"\"\n",
        "    __metaclass__ = ABCMeta\n",
        "\n",
        "    @abstractmethod\n",
        "    def function(self, x):\n",
        "        return\n",
        "\n",
        "    @abstractmethod\n",
        "    def prime(self, x):\n",
        "        return\n",
        "\n",
        "\n",
        "class SigmoidActivationFunction(ActivationFunction):\n",
        "    @classmethod\n",
        "    def function(cls, x):\n",
        "        \"\"\"\n",
        "        Sigmoid function.\n",
        "        :param x: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return 1 / (1.0 + np.exp(-x))\n",
        "\n",
        "    @classmethod\n",
        "    def prime(cls, x):\n",
        "        \"\"\"\n",
        "        Compute sigmoid first derivative.\n",
        "        :param x: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return x * (1 - x)\n",
        "\n",
        "\n",
        "class ReLUActivationFunction(ActivationFunction):\n",
        "    @classmethod\n",
        "    def function(cls, x):\n",
        "        \"\"\"\n",
        "        Rectified linear function.\n",
        "        :param x: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return np.maximum(np.zeros(x.shape), x)\n",
        "\n",
        "    @classmethod\n",
        "    def prime(cls, x):\n",
        "        \"\"\"\n",
        "        Rectified linear first derivative.\n",
        "        :param x: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return (x > 0).astype(int)\n",
        "\n",
        "\n",
        "class TanhActivationFunction(ActivationFunction):\n",
        "    @classmethod\n",
        "    def function(cls, x):\n",
        "        \"\"\"\n",
        "        Hyperbolic tangent function.\n",
        "        :param x: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return np.tanh(x)\n",
        "\n",
        "    @classmethod\n",
        "    def prime(cls, x):\n",
        "        \"\"\"\n",
        "        Hyperbolic tangent first derivative.\n",
        "        :param x: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return 1 - x * x\n",
        "\n",
        "\n",
        "class BaseModel(object):\n",
        "    def save(self, save_path):\n",
        "        import pickle\n",
        "\n",
        "        with open(save_path, 'wb') as fp:\n",
        "            pickle.dump(self, fp)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, load_path):\n",
        "        import pickle\n",
        "\n",
        "        with open(load_path, 'rb') as fp:\n",
        "            return pickle.load(fp)\n",
        "\n",
        "\n",
        "class BinaryRBM(BaseEstimator, TransformerMixin, BaseModel):\n",
        "    \"\"\"\n",
        "    This class implements a Binary Restricted Boltzmann machine.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_hidden_units=100,\n",
        "                 activation_function='sigmoid',\n",
        "                 optimization_algorithm='sgd',\n",
        "                 learning_rate=1e-3,\n",
        "                 n_epochs=10,\n",
        "                 contrastive_divergence_iter=1,\n",
        "                 batch_size=500,\n",
        "                 verbose=True):\n",
        "        self.n_hidden_units = n_hidden_units\n",
        "        self.activation_function = activation_function\n",
        "        self.optimization_algorithm = optimization_algorithm\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_epochs = n_epochs\n",
        "        self.contrastive_divergence_iter = contrastive_divergence_iter\n",
        "        self.batch_size = batch_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Fit a model given data.\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # Initialize RBM parameters\n",
        "        self.n_visible_units = X.shape[1]\n",
        "        if self.activation_function == 'sigmoid':\n",
        "            self.W = np.random.randn(self.n_hidden_units, self.n_visible_units) / np.sqrt(self.n_visible_units)\n",
        "            self.c = np.random.randn(self.n_hidden_units) / np.sqrt(self.n_visible_units)\n",
        "            self.b = np.random.randn(self.n_visible_units) / np.sqrt(self.n_visible_units)\n",
        "            self._activation_function_class = SigmoidActivationFunction\n",
        "        elif self.activation_function == 'relu':\n",
        "            self.W = truncnorm.rvs(-0.2, 0.2, size=[self.n_hidden_units, self.n_visible_units]) / np.sqrt(\n",
        "                self.n_visible_units)\n",
        "            self.c = np.full(self.n_hidden_units, 0.1) / np.sqrt(self.n_visible_units)\n",
        "            self.b = np.full(self.n_visible_units, 0.1) / np.sqrt(self.n_visible_units)\n",
        "            self._activation_function_class = ReLUActivationFunction\n",
        "        else:\n",
        "            raise ValueError(\"Invalid activation function.\")\n",
        "\n",
        "        if self.optimization_algorithm == 'sgd':\n",
        "            self._stochastic_gradient_descent(X)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid optimization algorithm.\")\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transforms data using the fitted model.\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if len(X.shape) == 1:  # It is a single sample\n",
        "            return self._compute_hidden_units(X)\n",
        "        transformed_data = self._compute_hidden_units_matrix(X)\n",
        "        return transformed_data\n",
        "\n",
        "    def _reconstruct(self, transformed_data):\n",
        "        \"\"\"\n",
        "        Reconstruct visible units given the hidden layer output.\n",
        "        :param transformed_data: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return self._compute_visible_units_matrix(transformed_data)\n",
        "\n",
        "    def _stochastic_gradient_descent(self, _data):\n",
        "        \"\"\"\n",
        "        Performs stochastic gradient descend optimization algorithm.\n",
        "        :param _data: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        accum_delta_W = np.zeros(self.W.shape)\n",
        "        accum_delta_b = np.zeros(self.b.shape)\n",
        "        accum_delta_c = np.zeros(self.c.shape)\n",
        "        for iteration in range(1, self.n_epochs + 1):\n",
        "            idx = np.random.permutation(len(_data))\n",
        "            data = _data[idx]\n",
        "            for batch in batch_generator(self.batch_size, data):\n",
        "                accum_delta_W[:] = .0\n",
        "                accum_delta_b[:] = .0\n",
        "                accum_delta_c[:] = .0\n",
        "                for sample in batch:\n",
        "                    delta_W, delta_b, delta_c = self._contrastive_divergence(sample)\n",
        "                    accum_delta_W += delta_W\n",
        "                    accum_delta_b += delta_b\n",
        "                    accum_delta_c += delta_c\n",
        "                self.W += self.learning_rate * (accum_delta_W / self.batch_size)\n",
        "                self.b += self.learning_rate * (accum_delta_b / self.batch_size)\n",
        "                self.c += self.learning_rate * (accum_delta_c / self.batch_size)\n",
        "            if self.verbose:\n",
        "                error = self._compute_reconstruction_error(data)\n",
        "                print(\">> Epoch %d finished \\tRBM Reconstruction error %f\" % (iteration, error))\n",
        "\n",
        "    def _contrastive_divergence(self, vector_visible_units):\n",
        "        \"\"\"\n",
        "        Computes gradients using Contrastive Divergence method.\n",
        "        :param vector_visible_units: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        v_0 = vector_visible_units\n",
        "        v_t = np.array(v_0)\n",
        "\n",
        "        # Sampling\n",
        "        for t in range(self.contrastive_divergence_iter):\n",
        "            h_t = self._sample_hidden_units(v_t)\n",
        "            v_t = self._compute_visible_units(h_t)\n",
        "\n",
        "        # Computing deltas\n",
        "        v_k = v_t\n",
        "        h_0 = self._compute_hidden_units(v_0)\n",
        "        h_k = self._compute_hidden_units(v_k)\n",
        "        delta_W = np.outer(h_0, v_0) - np.outer(h_k, v_k)\n",
        "        delta_b = v_0 - v_k\n",
        "        delta_c = h_0 - h_k\n",
        "\n",
        "        return delta_W, delta_b, delta_c\n",
        "\n",
        "    def _sample_hidden_units(self, vector_visible_units):\n",
        "        \"\"\"\n",
        "        Computes hidden unit activations by sampling from a binomial distribution.\n",
        "        :param vector_visible_units: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        hidden_units = self._compute_hidden_units(vector_visible_units)\n",
        "        return (np.random.random_sample(len(hidden_units)) < hidden_units).astype(np.int64)\n",
        "\n",
        "    def _sample_visible_units(self, vector_hidden_units):\n",
        "        \"\"\"\n",
        "        Computes visible unit activations by sampling from a binomial distribution.\n",
        "        :param vector_hidden_units: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        visible_units = self._compute_visible_units(vector_hidden_units)\n",
        "        return (np.random.random_sample(len(visible_units)) < visible_units).astype(np.int64)\n",
        "\n",
        "    def _compute_hidden_units(self, vector_visible_units):\n",
        "        \"\"\"\n",
        "        Computes hidden unit outputs.\n",
        "        :param vector_visible_units: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        v = np.expand_dims(vector_visible_units, 0)\n",
        "        h = np.squeeze(self._compute_hidden_units_matrix(v))\n",
        "        return np.array([h]) if not h.shape else h\n",
        "\n",
        "    def _compute_hidden_units_matrix(self, matrix_visible_units):\n",
        "        \"\"\"\n",
        "        Computes hidden unit outputs.\n",
        "        :param matrix_visible_units: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return np.transpose(self._activation_function_class.function(\n",
        "            np.dot(self.W, np.transpose(matrix_visible_units)) + self.c[:, np.newaxis]))\n",
        "\n",
        "    def _compute_visible_units(self, vector_hidden_units):\n",
        "        \"\"\"\n",
        "        Computes visible (or input) unit outputs.\n",
        "        :param vector_hidden_units: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        h = np.expand_dims(vector_hidden_units, 0)\n",
        "        v = np.squeeze(self._compute_visible_units_matrix(h))\n",
        "        return np.array([v]) if not v.shape else v\n",
        "\n",
        "    def _compute_visible_units_matrix(self, matrix_hidden_units):\n",
        "        \"\"\"\n",
        "        Computes visible (or input) unit outputs.\n",
        "        :param matrix_hidden_units: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return self._activation_function_class.function(np.dot(matrix_hidden_units, self.W) + self.b[np.newaxis, :])\n",
        "\n",
        "    def _compute_free_energy(self, vector_visible_units):\n",
        "        \"\"\"\n",
        "        Computes the RBM free energy.\n",
        "        :param vector_visible_units: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        v = vector_visible_units\n",
        "        return - np.dot(self.b, v) - np.sum(np.log(1 + np.exp(np.dot(self.W, v) + self.c)))\n",
        "\n",
        "    def _compute_reconstruction_error(self, data):\n",
        "        \"\"\"\n",
        "        Computes the reconstruction error of the data.\n",
        "        :param data: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        data_transformed = self.transform(data)\n",
        "        data_reconstructed = self._reconstruct(data_transformed)\n",
        "        return np.mean(np.sum((data_reconstructed - data) ** 2, 1))\n",
        "\n",
        "\n",
        "class UnsupervisedDBN(BaseEstimator, TransformerMixin, BaseModel):\n",
        "    \"\"\"\n",
        "    This class implements a unsupervised Deep Belief Network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_layers_structure=[100, 100],\n",
        "                 activation_function='sigmoid',\n",
        "                 optimization_algorithm='sgd',\n",
        "                 learning_rate_rbm=1e-3,\n",
        "                 n_epochs_rbm=10,\n",
        "                 contrastive_divergence_iter=1,\n",
        "                 batch_size=500,\n",
        "                 verbose=True):\n",
        "        self.hidden_layers_structure = hidden_layers_structure\n",
        "        self.activation_function = activation_function\n",
        "        self.optimization_algorithm = optimization_algorithm\n",
        "        self.learning_rate_rbm = learning_rate_rbm\n",
        "        self.n_epochs_rbm = n_epochs_rbm\n",
        "        self.contrastive_divergence_iter = contrastive_divergence_iter\n",
        "        self.batch_size = batch_size\n",
        "        self.rbm_layers = None\n",
        "        self.verbose = verbose\n",
        "        self.rbm_class = BinaryRBM\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Fits a model given data.\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # Initialize rbm layers\n",
        "        self.rbm_layers = list()\n",
        "        for n_hidden_units in self.hidden_layers_structure:\n",
        "            rbm = self.rbm_class(n_hidden_units=n_hidden_units,\n",
        "                                 activation_function=self.activation_function,\n",
        "                                 optimization_algorithm=self.optimization_algorithm,\n",
        "                                 learning_rate=self.learning_rate_rbm,\n",
        "                                 n_epochs=self.n_epochs_rbm,\n",
        "                                 contrastive_divergence_iter=self.contrastive_divergence_iter,\n",
        "                                 batch_size=self.batch_size,\n",
        "                                 verbose=self.verbose)\n",
        "            self.rbm_layers.append(rbm)\n",
        "\n",
        "        # Fit RBM\n",
        "        if self.verbose:\n",
        "            print(\"[START] Pre-training step:\")\n",
        "        input_data = X\n",
        "        for rbm in self.rbm_layers:\n",
        "            rbm.fit(input_data)\n",
        "            input_data = rbm.transform(input_data)\n",
        "        if self.verbose:\n",
        "            print(\"[END] Pre-training step\")\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transforms data using the fitted model.\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        input_data = X\n",
        "        for rbm in self.rbm_layers:\n",
        "            input_data = rbm.transform(input_data)\n",
        "        return input_data\n",
        "\n",
        "\n",
        "class AbstractSupervisedDBN(BaseEstimator, BaseModel):\n",
        "    \"\"\"\n",
        "    Abstract class for supervised Deep Belief Network.\n",
        "    \"\"\"\n",
        "    __metaclass__ = ABCMeta\n",
        "\n",
        "    def __init__(self,\n",
        "                 unsupervised_dbn_class,\n",
        "                 hidden_layers_structure=[100, 100],\n",
        "                 activation_function='sigmoid',\n",
        "                 optimization_algorithm='sgd',\n",
        "                 learning_rate=1e-3,\n",
        "                 learning_rate_rbm=1e-3,\n",
        "                 n_iter_backprop=100,\n",
        "                 l2_regularization=1.0,\n",
        "                 n_epochs_rbm=10,\n",
        "                 contrastive_divergence_iter=1,\n",
        "                 batch_size=500,\n",
        "                 dropout_p=0,  # float between 0 and 1. Fraction of the input units to drop\n",
        "                 verbose=True):\n",
        "        self.unsupervised_dbn = unsupervised_dbn_class(hidden_layers_structure=hidden_layers_structure,\n",
        "                                                       activation_function=activation_function,\n",
        "                                                       optimization_algorithm=optimization_algorithm,\n",
        "                                                       learning_rate_rbm=learning_rate_rbm,\n",
        "                                                       n_epochs_rbm=n_epochs_rbm,\n",
        "                                                       contrastive_divergence_iter=contrastive_divergence_iter,\n",
        "                                                       batch_size=batch_size,\n",
        "                                                       verbose=verbose)\n",
        "        self.unsupervised_dbn_class = unsupervised_dbn_class\n",
        "        self.n_iter_backprop = n_iter_backprop\n",
        "        self.l2_regularization = l2_regularization\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.p = 1 - self.dropout_p\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def fit(self, X, y=None, pre_train=True):\n",
        "        \"\"\"\n",
        "        Fits a model given data.\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :param y : array-like, shape = (n_samples, )\n",
        "        :param pre_train: bool\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if pre_train:\n",
        "            self.pre_train(X)\n",
        "        self._fine_tuning(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts the target given data.\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if len(X.shape) == 1:  # It is a single sample\n",
        "            X = np.expand_dims(X, 0)\n",
        "        transformed_data = self.transform(X)\n",
        "        predicted_data = self._compute_output_units_matrix(transformed_data)\n",
        "        return predicted_data\n",
        "\n",
        "    def pre_train(self, X):\n",
        "        \"\"\"\n",
        "        Apply unsupervised network pre-training.\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.unsupervised_dbn.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, *args):\n",
        "        return self.unsupervised_dbn.transform(*args)\n",
        "\n",
        "    @abstractmethod\n",
        "    def _transform_labels_to_network_format(self, labels):\n",
        "        return\n",
        "\n",
        "    @abstractmethod\n",
        "    def _compute_output_units_matrix(self, matrix_visible_units):\n",
        "        return\n",
        "\n",
        "    @abstractmethod\n",
        "    def _determine_num_output_neurons(self, labels):\n",
        "        return\n",
        "\n",
        "    @abstractmethod\n",
        "    def _stochastic_gradient_descent(self, data, labels):\n",
        "        return\n",
        "\n",
        "    @abstractmethod\n",
        "    def _fine_tuning(self, data, _labels):\n",
        "        return\n",
        "\n",
        "\n",
        "class NumPyAbstractSupervisedDBN(AbstractSupervisedDBN):\n",
        "    \"\"\"\n",
        "    Abstract class for supervised Deep Belief Network in NumPy\n",
        "    \"\"\"\n",
        "    __metaclass__ = ABCMeta\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(NumPyAbstractSupervisedDBN, self).__init__(UnsupervisedDBN, **kwargs)\n",
        "\n",
        "    def _compute_activations(self, sample):\n",
        "        \"\"\"\n",
        "        Compute output values of all layers.\n",
        "        :param sample: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        input_data = sample\n",
        "        if self.dropout_p > 0:\n",
        "            r = np.random.binomial(1, self.p, len(input_data))\n",
        "            input_data *= r\n",
        "        layers_activation = list()\n",
        "\n",
        "        for rbm in self.unsupervised_dbn.rbm_layers:\n",
        "            input_data = rbm.transform(input_data)\n",
        "            if self.dropout_p > 0:\n",
        "                r = np.random.binomial(1, self.p, len(input_data))\n",
        "                input_data *= r\n",
        "            layers_activation.append(input_data)\n",
        "\n",
        "        # Computing activation of output layer\n",
        "        input_data = self._compute_output_units(input_data)\n",
        "        layers_activation.append(input_data)\n",
        "\n",
        "        return layers_activation\n",
        "\n",
        "    def _stochastic_gradient_descent(self, _data, _labels):\n",
        "        \"\"\"\n",
        "        Performs stochastic gradient descend optimization algorithm.\n",
        "        :param _data: array-like, shape = (n_samples, n_features)\n",
        "        :param _labels: array-like, shape = (n_samples, targets)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            matrix_error = np.zeros([len(_data), self.num_classes])\n",
        "        num_samples = len(_data)\n",
        "        accum_delta_W = [np.zeros(rbm.W.shape) for rbm in self.unsupervised_dbn.rbm_layers]\n",
        "        accum_delta_W.append(np.zeros(self.W.shape))\n",
        "        accum_delta_bias = [np.zeros(rbm.c.shape) for rbm in self.unsupervised_dbn.rbm_layers]\n",
        "        accum_delta_bias.append(np.zeros(self.b.shape))\n",
        "\n",
        "        for iteration in range(1, self.n_iter_backprop + 1):\n",
        "            idx = np.random.permutation(len(_data))\n",
        "            data = _data[idx]\n",
        "            labels = _labels[idx]\n",
        "            i = 0\n",
        "            for batch_data, batch_labels in batch_generator(self.batch_size, data, labels):\n",
        "                # Clear arrays\n",
        "                for arr1, arr2 in zip(accum_delta_W, accum_delta_bias):\n",
        "                    arr1[:], arr2[:] = .0, .0\n",
        "                for sample, label in zip(batch_data, batch_labels):\n",
        "                    delta_W, delta_bias, predicted = self._backpropagation(sample, label)\n",
        "                    for layer in range(len(self.unsupervised_dbn.rbm_layers) + 1):\n",
        "                        accum_delta_W[layer] += delta_W[layer]\n",
        "                        accum_delta_bias[layer] += delta_bias[layer]\n",
        "                    if self.verbose:\n",
        "                        loss = self._compute_loss(predicted, label)\n",
        "                        matrix_error[i, :] = loss\n",
        "                        i += 1\n",
        "\n",
        "                layer = 0\n",
        "                for rbm in self.unsupervised_dbn.rbm_layers:\n",
        "                    # Updating parameters of hidden layers\n",
        "                    rbm.W = (1 - (\n",
        "                        self.learning_rate * self.l2_regularization) / num_samples) * rbm.W - self.learning_rate * (\n",
        "                        accum_delta_W[layer] / self.batch_size)\n",
        "                    rbm.c -= self.learning_rate * (accum_delta_bias[layer] / self.batch_size)\n",
        "                    layer += 1\n",
        "                # Updating parameters of output layer\n",
        "                self.W = (1 - (\n",
        "                    self.learning_rate * self.l2_regularization) / num_samples) * self.W - self.learning_rate * (\n",
        "                    accum_delta_W[layer] / self.batch_size)\n",
        "                self.b -= self.learning_rate * (accum_delta_bias[layer] / self.batch_size)\n",
        "\n",
        "            if self.verbose:\n",
        "                error = np.mean(np.sum(matrix_error, 1))\n",
        "                print(\">> Epoch %d finished \\tANN training loss %f\" % (iteration, error))\n",
        "\n",
        "    def _backpropagation(self, input_vector, label):\n",
        "        \"\"\"\n",
        "        Performs Backpropagation algorithm for computing gradients.\n",
        "        :param input_vector: array-like, shape = (n_features, )\n",
        "        :param label: array-like, shape = (n_targets, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        x, y = input_vector, label\n",
        "        deltas = list()\n",
        "        list_layer_weights = list()\n",
        "        for rbm in self.unsupervised_dbn.rbm_layers:\n",
        "            list_layer_weights.append(rbm.W)\n",
        "        list_layer_weights.append(self.W)\n",
        "\n",
        "        # Forward pass\n",
        "        layers_activation = self._compute_activations(input_vector)\n",
        "\n",
        "        # Backward pass: computing deltas\n",
        "        activation_output_layer = layers_activation[-1]\n",
        "        delta_output_layer = self._compute_output_layer_delta(y, activation_output_layer)\n",
        "        deltas.append(delta_output_layer)\n",
        "        layer_idx = list(range(len(self.unsupervised_dbn.rbm_layers)))\n",
        "        layer_idx.reverse()\n",
        "        delta_previous_layer = delta_output_layer\n",
        "        for layer in layer_idx:\n",
        "            neuron_activations = layers_activation[layer]\n",
        "            W = list_layer_weights[layer + 1]\n",
        "            delta = np.dot(delta_previous_layer, W) * self.unsupervised_dbn.rbm_layers[\n",
        "                layer]._activation_function_class.prime(neuron_activations)\n",
        "            deltas.append(delta)\n",
        "            delta_previous_layer = delta\n",
        "        deltas.reverse()\n",
        "\n",
        "        # Computing gradients\n",
        "        layers_activation.pop()\n",
        "        layers_activation.insert(0, input_vector)\n",
        "        layer_gradient_weights, layer_gradient_bias = list(), list()\n",
        "        for layer in range(len(list_layer_weights)):\n",
        "            neuron_activations = layers_activation[layer]\n",
        "            delta = deltas[layer]\n",
        "            gradient_W = np.outer(delta, neuron_activations)\n",
        "            layer_gradient_weights.append(gradient_W)\n",
        "            layer_gradient_bias.append(delta)\n",
        "\n",
        "        return layer_gradient_weights, layer_gradient_bias, activation_output_layer\n",
        "\n",
        "    def _fine_tuning(self, data, _labels):\n",
        "        \"\"\"\n",
        "        Entry point of the fine tuning procedure.\n",
        "        :param data: array-like, shape = (n_samples, n_features)\n",
        "        :param _labels: array-like, shape = (n_samples, targets)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.num_classes = self._determine_num_output_neurons(_labels)\n",
        "        n_hidden_units_previous_layer = self.unsupervised_dbn.rbm_layers[-1].n_hidden_units\n",
        "        self.W = np.random.randn(self.num_classes, n_hidden_units_previous_layer) / np.sqrt(\n",
        "            n_hidden_units_previous_layer)\n",
        "        self.b = np.random.randn(self.num_classes) / np.sqrt(n_hidden_units_previous_layer)\n",
        "\n",
        "        labels = self._transform_labels_to_network_format(_labels)\n",
        "\n",
        "        # Scaling up weights obtained from pretraining\n",
        "        for rbm in self.unsupervised_dbn.rbm_layers:\n",
        "            rbm.W /= self.p\n",
        "            rbm.c /= self.p\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"[START] Fine tuning step:\")\n",
        "\n",
        "        if self.unsupervised_dbn.optimization_algorithm == 'sgd':\n",
        "            self._stochastic_gradient_descent(data, labels)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid optimization algorithm.\")\n",
        "\n",
        "        # Scaling down weights obtained from pretraining\n",
        "        for rbm in self.unsupervised_dbn.rbm_layers:\n",
        "            rbm.W *= self.p\n",
        "            rbm.c *= self.p\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"[END] Fine tuning step\")\n",
        "\n",
        "    @abstractmethod\n",
        "    def _compute_loss(self, predicted, label):\n",
        "        return\n",
        "\n",
        "    @abstractmethod\n",
        "    def _compute_output_layer_delta(self, label, predicted):\n",
        "        return\n",
        "\n",
        "\n",
        "class SupervisedDBNClassification(NumPyAbstractSupervisedDBN, ClassifierMixin):\n",
        "    \"\"\"\n",
        "    This class implements a Deep Belief Network for classification problems.\n",
        "    It appends a Softmax Linear Classifier as output layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def _transform_labels_to_network_format(self, labels):\n",
        "        \"\"\"\n",
        "        Converts labels as single integer to row vectors. For instance, given a three class problem, labels would be\n",
        "        mapped as label_1: [1 0 0], label_2: [0 1 0], label_3: [0, 0, 1] where labels can be either int or string.\n",
        "        :param labels: array-like, shape = (n_samples, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_labels = np.zeros([len(labels), self.num_classes])\n",
        "        self.label_to_idx_map, self.idx_to_label_map = dict(), dict()\n",
        "        idx = 0\n",
        "        for i, label in enumerate(labels):\n",
        "            if label not in self.label_to_idx_map:\n",
        "                self.label_to_idx_map[label] = idx\n",
        "                self.idx_to_label_map[idx] = label\n",
        "                idx += 1\n",
        "            new_labels[i][self.label_to_idx_map[label]] = 1\n",
        "        return new_labels\n",
        "\n",
        "    def _transform_network_format_to_labels(self, indexes):\n",
        "        \"\"\"\n",
        "        Converts network output to original labels.\n",
        "        :param indexes: array-like, shape = (n_samples, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return list(map(lambda idx: self.idx_to_label_map[idx], indexes))\n",
        "\n",
        "    def _compute_output_units(self, vector_visible_units):\n",
        "        \"\"\"\n",
        "        Compute activations of output units.\n",
        "        :param vector_visible_units: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        v = vector_visible_units\n",
        "        scores = np.dot(self.W, v) + self.b\n",
        "        # get unnormalized probabilities\n",
        "        exp_scores = np.exp(scores)\n",
        "        # normalize them for each example\n",
        "        return exp_scores / np.sum(exp_scores)\n",
        "\n",
        "    def _compute_output_units_matrix(self, matrix_visible_units):\n",
        "        \"\"\"\n",
        "        Compute activations of output units.\n",
        "        :param matrix_visible_units: shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        matrix_scores = np.transpose(np.dot(self.W, np.transpose(matrix_visible_units)) + self.b[:, np.newaxis])\n",
        "        exp_scores = np.exp(matrix_scores)\n",
        "        return exp_scores / np.expand_dims(np.sum(exp_scores, axis=1), 1)\n",
        "\n",
        "    def _compute_output_layer_delta(self, label, predicted):\n",
        "        \"\"\"\n",
        "        Compute deltas of the output layer, using cross-entropy cost function.\n",
        "        :param label: array-like, shape = (n_features, )\n",
        "        :param predicted: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        dscores = np.array(predicted)\n",
        "        dscores[np.where(label == 1)] -= 1\n",
        "        return dscores\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predicts probability distribution of classes for each sample in the given data.\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return super(SupervisedDBNClassification, self).predict(X)\n",
        "\n",
        "    def predict_proba_dict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts probability distribution of classes for each sample in the given data.\n",
        "        Returns a list of dictionaries, one per sample. Each dict contains {label_1: prob_1, ..., label_j: prob_j}\n",
        "        :param X: array-like, shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if len(X.shape) == 1:  # It is a single sample\n",
        "            X = np.expand_dims(X, 0)\n",
        "\n",
        "        predicted_probs = self.predict_proba(X)\n",
        "\n",
        "        result = []\n",
        "        num_of_data, num_of_labels = predicted_probs.shape\n",
        "        for i in range(num_of_data):\n",
        "            # key : label\n",
        "            # value : predicted probability\n",
        "            dict_prob = {}\n",
        "            for j in range(num_of_labels):\n",
        "                dict_prob[self.idx_to_label_map[j]] = predicted_probs[i][j]\n",
        "            result.append(dict_prob)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs = self.predict_proba(X)\n",
        "        indexes = np.argmax(probs, axis=1)\n",
        "        return self._transform_network_format_to_labels(indexes)\n",
        "\n",
        "    def _determine_num_output_neurons(self, labels):\n",
        "        \"\"\"\n",
        "        Given labels, compute the needed number of output units.\n",
        "        :param labels: shape = (n_samples, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return len(np.unique(labels))\n",
        "\n",
        "    def _compute_loss(self, probs, label):\n",
        "        \"\"\"\n",
        "        Computes categorical cross-entropy loss\n",
        "        :param probs:\n",
        "        :param label:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return -np.log(probs[np.where(label == 1)])\n",
        "\n",
        "\n",
        "class SupervisedDBNRegression(NumPyAbstractSupervisedDBN, RegressorMixin):\n",
        "    \"\"\"\n",
        "    This class implements a Deep Belief Network for regression problems.\n",
        "    \"\"\"\n",
        "\n",
        "    def _transform_labels_to_network_format(self, labels):\n",
        "        \"\"\"\n",
        "        Returns the same labels since regression case does not need to convert anything.\n",
        "        :param labels: array-like, shape = (n_samples, targets)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return labels\n",
        "\n",
        "    def _compute_output_units(self, vector_visible_units):\n",
        "        \"\"\"\n",
        "        Compute activations of output units.\n",
        "        :param vector_visible_units: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        v = vector_visible_units\n",
        "        return np.dot(self.W, v) + self.b\n",
        "\n",
        "    def _compute_output_units_matrix(self, matrix_visible_units):\n",
        "        \"\"\"\n",
        "        Compute activations of output units.\n",
        "        :param matrix_visible_units: shape = (n_samples, n_features)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return np.transpose(np.dot(self.W, np.transpose(matrix_visible_units)) + self.b[:, np.newaxis])\n",
        "\n",
        "    def _compute_output_layer_delta(self, label, predicted):\n",
        "        \"\"\"\n",
        "        Compute deltas of the output layer for the regression case, using common (one-half) squared-error cost function.\n",
        "        :param label: array-like, shape = (n_features, )\n",
        "        :param predicted: array-like, shape = (n_features, )\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return -(label - predicted)\n",
        "\n",
        "    def _determine_num_output_neurons(self, labels):\n",
        "        \"\"\"\n",
        "        Given labels, compute the needed number of output units.\n",
        "        :param labels: shape = (n_samples, n_targets)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if len(labels.shape) == 1:\n",
        "            return 1\n",
        "        else:\n",
        "            return labels.shape[1]\n",
        "\n",
        "    def _compute_loss(self, predicted, label):\n",
        "        \"\"\"\n",
        "        Computes Mean squared error loss.\n",
        "        :param predicted:\n",
        "        :param label:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        error = predicted - label\n",
        "        return error * error\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "B49GjcO-qbzl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXXg-gREJSyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "30f86107-58ec-476c-dcb7-eeaaa4ce8c7c"
      },
      "source": [
        "#@title Acceder al Drive\n",
        "\n",
        "# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# directorio local en Google Drive\n",
        "path = '/content/gdrive/My Drive/IA/demoML/datos/'  #@param {type:\"string\"}\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vYL-JW1-8pJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812,
          "referenced_widgets": [
            "3868c680fcd341c58052af577661726f",
            "0064d19a236a46d895b62ccf5b0424f1",
            "ce4ade1274e44cbb945e75ff2518f1c7",
            "02836c64731c46bc9dd8e7f68349771c",
            "5ba5cf0452bb46cab72aec6d4b16bdfc",
            "5d1149d6670c491b8eaaa7122c52e7f3",
            "8bcbe0a7eea44853ae601143b0a0be48",
            "50268d98d2d44514a06a9f1275945ee8",
            "8e5ec6a36d434e3a92a685907ec0f181",
            "e7e8bd218b944198bd9e7f73d03849a9",
            "27a72003f91749009496f6f39bd59e8a",
            "67f1d67cd7c14295b4142ad9dda09bf0",
            "e1868d571961489dbfb6bd525559b35c",
            "67af7badd26e4d51bfb7dc8579c959e8",
            "121b504106714bbaad9659b92719d867",
            "6187a5128b4b4f749d0201e9e2bf0e8b",
            "1a2e589ea33e4cc2a6374a8dd16ab902"
          ]
        },
        "cellView": "form",
        "outputId": "e1c88a05-8899-46ec-90df-a812da5758a9"
      },
      "source": [
        "\n",
        "#@title Cargar datos\n",
        "\n",
        "\n",
        "#@markdown ### Archivo de datos a utilizar:\n",
        "archivo_datos = 'IRIS.csv'  #@param {type:\"string\"}\n",
        "#@markdown ### Configuración del archivo CSV:\n",
        "delimitador_columnas = ',' #@param {type:\"string\"}\n",
        "\n",
        "## selección de los parámetros\n",
        "\n",
        "# función para cargar configuración datos automática\n",
        "def cargarNombreClases(path, archivo_datos):\n",
        "  # importa definición de la clase\n",
        "  arClasesFN = archivo_datos.split('.')[0] + '_nombreClases.txt'\n",
        "  if os.path.isfile( path + '/' + arClasesFN ):\n",
        "    with open( path + '/' + arClasesFN, mode='r') as csvfile:\n",
        "        r = csv.reader(csvfile, delimiter=',')\n",
        "        auxAtributo = r.__next__()\n",
        "        auxClases = r.__next__()\n",
        "    print('\\n> Definición de los valores discretos para la clase cargada de ' + arClasesFN +'.\\n')\n",
        "    return auxAtributo[0], ','.join(auxClases)\n",
        "  else:\n",
        "    return \"\", \"\"\n",
        "\n",
        "# función auxiliara para que no ejecute UI cada vez\n",
        "def hacerNada():\n",
        "  return\n",
        "\n",
        "# se define esta función para que se ocupe de aplicar la configuración\n",
        "def on_buttonAplicar_clicked(b):\n",
        "  print(\"\")\n",
        "  funcionCambiaSeleccion_ConfigDatos(combo_att_clase.value, texto_nomClases.value, combo_att_entrada.value)\n",
        "\n",
        "# aplica configuración de datos\n",
        "def funcionCambiaSeleccion_ConfigDatos(attClase, nomClases, att_entrada):\n",
        "  global Y, X, nombre_clases\n",
        "\n",
        "  if (attClase is None) or (attClase ==\"\") or\\\n",
        "    (att_entrada is None) or (att_entrada ==\"\"):\n",
        "    return\n",
        "\n",
        "  # si el atributo clase está como de entrada, lo saca (no tiene sentido)\n",
        "  att_entrada = list(att_entrada)\n",
        "  if attClase in att_entrada:\n",
        "    print(\"Eliminando atributo \" + attClase + \" como de entrada dado que es clase.\")\n",
        "    att_entrada.remove( attClase )\n",
        "\n",
        "  if (att_entrada == \"\") or (len(att_entrada)==0):\n",
        "    print(\"No se han definido atributos de entrada!\")\n",
        "    return\n",
        "\n",
        "  # guarda configuración\n",
        "  nombre_clases = nomClases\n",
        "\n",
        "    # genera los datos solo con los atributos seleccionados\n",
        "  Y = np.array(df[attClase])\n",
        "  X = np.array(df[att_entrada])\n",
        "\n",
        "  # muestra resultados\n",
        "  print(\"\\n> Atributos entrada: \", att_entrada)\n",
        "  print(\"\\t X: \", X.shape)\n",
        "\n",
        "  if (nombre_clases is None) or (nombre_clases==\"\"):\n",
        "    print(\"\\n> Atributo clase: \", attClase)\n",
        "  else:\n",
        "    print(\"\\n> Atributo clase: \", attClase, \" [\", nombre_clases, \"]\")\n",
        "  print(\"\\t Y: \", Y.shape)\n",
        "\n",
        "## aplicación de los parámetros elegidos\n",
        "\n",
        "# configura para que muestre todas las columnas y filas\n",
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.max_columns = 100\n",
        "\n",
        "# Carga los datos del CSV y muestra los primeros\n",
        "df = pd.read_csv(path + archivo_datos,  sep=delimitador_columnas, engine=\"python\")\n",
        "print(\"Archivo de datos \", archivo_datos, \" cargado\")\n",
        "\n",
        "print(\"\\n> Cabecera: \")\n",
        "print(df.head())\n",
        "print(\"\\n> Características: \")\n",
        "print(df.describe())\n",
        "print(\"\\n\")\n",
        "\n",
        "# inicializa valores\n",
        "X = None\n",
        "Y = None\n",
        "\n",
        "# intenta cargar configuración asociada a los datos\n",
        "# trata de obtener la configuración del archivo asociado\n",
        "atributo_clase, nombre_clases = cargarNombreClases(path, archivo_datos)\n",
        "\n",
        "# muestra interface para cargar configuración\n",
        "\n",
        "# auxiliar para que muestre bien la descripción\n",
        "style_3D = {'description_width': 'initial'}\n",
        "\n",
        "tit = widgets.Label(\"Ajuste para configuración de los Datos: \")\n",
        "\n",
        "# prepara combo para determinar atributo clase\n",
        "selecc_atributos = [ ]\n",
        "selecc_atributos.extend( df.columns.values.tolist() )\n",
        "if (atributo_clase is None) or (atributo_clase==\"\") or (atributo_clase not in selecc_atributos):\n",
        "  att_selecc_defecto = len(selecc_atributos)-1\n",
        "else:\n",
        "  att_selecc_defecto = selecc_atributos.index(atributo_clase)\n",
        "combo_att_clase = widgets.Dropdown(\n",
        "    options = selecc_atributos,\n",
        "    value = selecc_atributos[att_selecc_defecto], # mostrar por defecto de config\n",
        "    description = 'Atributo clase:',\n",
        "    style=style_3D,\n",
        "    disabled = False,\n",
        ")\n",
        "# prepara campo para ingresar nombre clases (toma por defecto de config)\n",
        "texto_nomClases = widgets.Text(\n",
        "    value=nombre_clases,\n",
        "    placeholder='Ingrese nombre clases (si corresponde) separados por comas',\n",
        "    description='Nombre clases:',\n",
        "    style=style_3D,\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "combo_att_entrada = widgets.SelectMultiple(\n",
        "    options=selecc_atributos,\n",
        "    value=selecc_atributos,\n",
        "    #rows=10,\n",
        "    description='Atributos de entrada:',\n",
        "    style=style_3D,\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# prepara botón y grilla con objetos\n",
        "btnAplicar = widgets.Button(\n",
        "    description='Aplicar'\n",
        ")\n",
        "configDatos_ui = widgets.GridBox(\n",
        "      children=[tit, combo_att_clase, texto_nomClases, combo_att_entrada, btnAplicar],\n",
        "      layout=Layout(width='100%')  )\n",
        "btnAplicar.on_click(on_buttonAplicar_clicked)\n",
        "\n",
        "#clear_output()\n",
        "out_config = widgets.interactive_output(hacerNada, {})\n",
        "display(configDatos_ui)\n",
        "\n",
        "# ejecuta para que muestre\n",
        "on_buttonAplicar_clicked(btnAplicar)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo de datos  IRIS.csv  cargado\n",
            "\n",
            "> Cabecera: \n",
            "   LargoSepalo  AnchoSepalo  LargoPetalo  AnchoPetalo  Clase\n",
            "0          5.1          3.5          1.4          0.2      1\n",
            "1          4.9          3.0          1.4          0.2      1\n",
            "2          4.7          3.2          1.3          0.2      1\n",
            "3          4.6          3.1          1.5          0.2      1\n",
            "4          5.0          3.6          1.4          0.2      1\n",
            "\n",
            "> Características: \n",
            "       LargoSepalo  AnchoSepalo  LargoPetalo  AnchoPetalo       Clase\n",
            "count   150.000000   150.000000   150.000000   150.000000  150.000000\n",
            "mean      5.843333     3.054000     3.758667     1.198667    2.000000\n",
            "std       0.828066     0.433594     1.764420     0.763161    0.819232\n",
            "min       4.300000     2.000000     1.000000     0.100000    1.000000\n",
            "25%       5.100000     2.800000     1.600000     0.300000    1.000000\n",
            "50%       5.800000     3.000000     4.350000     1.300000    2.000000\n",
            "75%       6.400000     3.300000     5.100000     1.800000    3.000000\n",
            "max       7.900000     4.400000     6.900000     2.500000    3.000000\n",
            "\n",
            "\n",
            "\n",
            "> Definición de los valores discretos para la clase cargada de IRIS_nombreClases.txt.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GridBox(children=(Label(value='Ajuste para configuración de los Datos: '), Dropdown(description='Atributo clas…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3868c680fcd341c58052af577661726f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Eliminando atributo Clase como de entrada dado que es clase.\n",
            "\n",
            "> Atributos entrada:  ['LargoSepalo', 'AnchoSepalo', 'LargoPetalo', 'AnchoPetalo']\n",
            "\t X:  (150, 4)\n",
            "\n",
            "> Atributo clase:  Clase  [ na,Setosa,Versicolor,Virginica ]\n",
            "\t Y:  (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hW0GxRenJO4",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97c47a0-3db3-41ba-e5cc-076909eb4316"
      },
      "source": [
        "#@title Normalizar datos de entrada\n",
        "\n",
        "aplica_normalizacion = True #param {type:\"boolean\"}\n",
        "#@markdown Si se aplica, seleccione el tipo de método de normalización a aplicar:\n",
        "tipo_normalizacion = \"Standard Scaler\" #@param [\"Standard Scaler\", \"MinMax Scaler\", \"MaxAbs Scaler\", \"Robust Scaler\"]\n",
        "\n",
        "if aplica_normalizacion:\n",
        "\n",
        "  print(\"10 primeros datos de Entrada antes de normalizar: \")\n",
        "  print(X[:10])\n",
        "\n",
        "  from sklearn import preprocessing\n",
        "\n",
        "  # elegir el método de normalización\n",
        "  if tipo_normalizacion == \"Standard Scaler\":\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "  elif tipo_normalizacion == \"MinMax Scaler\":\n",
        "    scaler = preprocessing.MinMaxScaler()\n",
        "  elif tipo_normalizacion == \"MaxMax Scaler\":\n",
        "    scaler = preprocessing.MaxAbsScaler()\n",
        "  elif tipo_normalizacion == \"Robust Scaler\":\n",
        "    scaler = preprocessing.RobustScaler()\n",
        "\n",
        "  # normaliza los datos de entrada\n",
        "  X = scaler.fit_transform(X)\n",
        "\n",
        "  print(\"\\n\\n10 primeros datos de Entrada después de normalizar: \")\n",
        "  print(X[:10])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 primeros datos de Entrada antes de normalizar: \n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]]\n",
            "\n",
            "\n",
            "10 primeros datos de Entrada después de normalizar: \n",
            "[[-0.90068117  1.03205722 -1.3412724  -1.31297673]\n",
            " [-1.14301691 -0.1249576  -1.3412724  -1.31297673]\n",
            " [-1.38535265  0.33784833 -1.39813811 -1.31297673]\n",
            " [-1.50652052  0.10644536 -1.2844067  -1.31297673]\n",
            " [-1.02184904  1.26346019 -1.3412724  -1.31297673]\n",
            " [-0.53717756  1.95766909 -1.17067529 -1.05003079]\n",
            " [-1.50652052  0.80065426 -1.3412724  -1.18150376]\n",
            " [-1.02184904  0.80065426 -1.2844067  -1.31297673]\n",
            " [-1.74885626 -0.35636057 -1.3412724  -1.31297673]\n",
            " [-1.14301691  0.10644536 -1.2844067  -1.4444497 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m19c6Vd7PBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ed06a071-1519-46cd-9657-f3c1d9d33654"
      },
      "source": [
        "#@title Preparar datos\n",
        "\n",
        "#@markdown Determina si el atributo clase debe ser considerado como Discreto o Continuo\n",
        "considerar_atributo_clase = \"discreto - CLASIFICACION\" #@param [\"discreto - CLASIFICACION\", \"continuo - ESTIMACION\"]\n",
        "\n",
        "#@markdown Porcentaje de datos para usar en el entrenamiento:\n",
        "proporcion_porcentaje_datos_entrenamiento =   75#@param {type:\"integer\"}\n",
        "\n",
        "# determina la proporción a usar para entrenar y probar\n",
        "if proporcion_porcentaje_datos_entrenamiento>100:\n",
        "  propTrain = 1\n",
        "elif proporcion_porcentaje_datos_entrenamiento<1:\n",
        "  propTrain = 0.1\n",
        "else:\n",
        "  propTrain = proporcion_porcentaje_datos_entrenamiento/100\n",
        "\n",
        "# determina si es problema de clasificación o estimación\n",
        "esProblemaClasificacion = (considerar_atributo_clase[0].upper() == \"D\")\n",
        "\n",
        "# separa al azar usando muestreo con proporción indicada\n",
        "if esProblemaClasificacion:\n",
        "  # intenta hacer muestreo estatificado\n",
        "  try:\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain), stratify=Y)\n",
        "  except ValueError:\n",
        "    print(\"-- No se puede aplicar Muestreo Estratificado! -> se usa Muestreo Simple \\n\")\n",
        "    # hace muestreo simple\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain))\n",
        "else:\n",
        "  # hace muestreo simple\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain))\n",
        "\n",
        "CLASES = []\n",
        "if esProblemaClasificacion:\n",
        "  print(\"> se considera problema de CLASIFICACIÓN \\n\")\n",
        "\n",
        "  # define nombre de clases\n",
        "  if (nombre_clases == \"\") or (nombre_clases == \"-\"):\n",
        "      # toma los valores de clase orginales del archivo\n",
        "      if str(Y[0]).replace(\".\",\"\").isnumeric():\n",
        "        # Y son numeros\n",
        "        for val in range(int(np.max(Y))+1):\n",
        "          CLASES.append( \"clase {:>3}\".format(val) )\n",
        "      else:\n",
        "          # Y no son números\n",
        "          CLASES = list(set(Y))\n",
        "          CLASES.sort()\n",
        "          # cambia valores para que sean enteros\n",
        "          y_train = [ CLASES.index(y) for y in y_train]\n",
        "          y_test = [ CLASES.index(y) for y in y_test]\n",
        "  else:\n",
        "      # toma configuración de nombre de clases\n",
        "      for val in nombre_clases.split(','):\n",
        "        CLASES.append( val )\n",
        "\n",
        "  # genera salida codificada para softMax\n",
        "  y_trainEnc = []\n",
        "  y_testEnc = []\n",
        "\n",
        "  # muestra resultados\n",
        "  print(\"> Definición de CLASES: \")\n",
        "  print(\" - dictMapeo (\", len(CLASES), \"): \", CLASES)\n",
        "else:\n",
        "  print(\"> se considera problema de ESTIMACIÓN \\n\")\n",
        "\n",
        "  y_trainEnc = []\n",
        "  y_testEnc =  []\n",
        "\n",
        "\n",
        "print(\"\\n> Para Entrenamiento: \")\n",
        "print(\" - x_train (cant ejemplos, datos entrada): \", x_train.shape)\n",
        "print(\" - y_train (cant): \", len(y_train))\n",
        "if esProblemaClasificacion:\n",
        "  for i in range(len(CLASES)):\n",
        "    cant = 0\n",
        "    for y in y_train:\n",
        "      if i == int(y): cant = cant + 1\n",
        "    print(\"    \", CLASES[i], \"[\", i, \"]:\", cant)\n",
        "\n",
        "print(\"\\n Para Prueba: \")\n",
        "print(\" - x_test (cant ejemplos, datos entrada): \", x_test.shape)\n",
        "print(\" - y_test (cant): \", len(y_test))\n",
        "if esProblemaClasificacion:\n",
        "  for i in range(len(CLASES)):\n",
        "    cant = 0\n",
        "    for y in y_test:\n",
        "      if i == int(y): cant = cant + 1\n",
        "    print(\"    \", CLASES[i], \"[\", i, \"]:\", cant)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> se considera problema de CLASIFICACIÓN \n",
            "\n",
            "> Definición de CLASES: \n",
            " - dictMapeo ( 4 ):  ['na', 'Setosa', 'Versicolor', 'Virginica']\n",
            "\n",
            "> Para Entrenamiento: \n",
            " - x_train (cant ejemplos, datos entrada):  (112, 4)\n",
            " - y_train (cant):  112\n",
            "     na [ 0 ]: 0\n",
            "     Setosa [ 1 ]: 37\n",
            "     Versicolor [ 2 ]: 38\n",
            "     Virginica [ 3 ]: 37\n",
            "\n",
            " Para Prueba: \n",
            " - x_test (cant ejemplos, datos entrada):  (38, 4)\n",
            " - y_test (cant):  38\n",
            "     na [ 0 ]: 0\n",
            "     Setosa [ 1 ]: 13\n",
            "     Versicolor [ 2 ]: 12\n",
            "     Virginica [ 3 ]: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4Lr5871DLiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "02f51ac6-8365-420b-eb85-58940d7bb99a"
      },
      "source": [
        "#@title Establecer el modelo\n",
        "\n",
        "#@markdown ### Parámetros de la Red:\n",
        "cant_neuronas_capas_ocultas = '256, 256, 256' #@param {type:\"string\"}\n",
        "act_funcion = \"relu\" #@param [\"relu\", \"sigmoid\"]\n",
        "porc_capa_DropOut = 0.1 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Parámetros del Optimizador:\n",
        "RBM_opt_learning_rate = 0.05 #@param {type: \"number\"}\n",
        "Backprop_opt_learning_rate = 0.1 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Parámetros del Entrenamiento:\n",
        "RBM_cant_epocas_entrenamiento = 10 #@param {type:\"integer\"}\n",
        "Backprop_cant_epocas_entrenamiento = 200 #@param {type:\"integer\"}\n",
        "\n",
        "# cantidad de neuronas ocultas\n",
        "hidden_layers = []\n",
        "for val in cant_neuronas_capas_ocultas.split(','):\n",
        "  val = val.strip()\n",
        "  hidden_layers.append( int(val) )\n",
        "\n",
        "# chequea configuración de drop out\n",
        "if porc_capa_DropOut < 0:\n",
        "  porc_capa_DropOut = 0.00\n",
        "elif porc_capa_DropOut > 0.9:\n",
        "    porc_capa_DropOut = 0.9\n",
        "\n",
        "\n",
        "# define el tipo de clase de acuerdo al problema\n",
        "if esProblemaClasificacion:\n",
        "  model = SupervisedDBNClassification(hidden_layers_structure = hidden_layers,\n",
        "                n_epochs_rbm = RBM_cant_epocas_entrenamiento,\n",
        "                n_iter_backprop = Backprop_cant_epocas_entrenamiento,\n",
        "                batch_size = len(x_train)//3,\n",
        "                activation_function = act_funcion,\n",
        "                learning_rate = Backprop_opt_learning_rate,\n",
        "                learning_rate_rbm = RBM_opt_learning_rate,\n",
        "                dropout_p = porc_capa_DropOut)\n",
        "else:\n",
        "  # Training\n",
        "  model = SupervisedDBNRegression(hidden_layers_structure = hidden_layers,\n",
        "                n_epochs_rbm = RBM_cant_epocas_entrenamiento,\n",
        "                n_iter_backprop = Backprop_cant_epocas_entrenamiento,\n",
        "                batch_size = len(x_train)//3,\n",
        "                activation_function = act_funcion,\n",
        "                learning_rate = Backprop_opt_learning_rate,\n",
        "                learning_rate_rbm = RBM_opt_learning_rate,\n",
        "                dropout_p = porc_capa_DropOut)\n",
        "\n",
        "\n",
        "print(\"DBN definida: \", model)\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DBN definida:  SupervisedDBNClassification()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szAiJSdGDMua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "21f31a98-45c2-450a-8684-71ecef8fa460"
      },
      "source": [
        "#@title Entrenar\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.256295\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.175709\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 2.164666\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 2.327734\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 2.633703\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 3.149002\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.161345\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 8.210897\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 13.202431\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 31.142551\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 174.980463\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 94620.166471\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 173.871471\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 169.679213\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 148.704953\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 151.113169\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 136.644491\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 124.882245\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 656.353195\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 112.303357\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.946013\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.346140\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.547715\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.694007\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.309311\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.230333\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.190769\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.153375\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.128894\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.103184\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 1 finished \tANN training loss 3.144281\n",
            ">> Epoch 2 finished \tANN training loss 2.913749\n",
            ">> Epoch 3 finished \tANN training loss 2.740982\n",
            ">> Epoch 4 finished \tANN training loss 2.601385\n",
            ">> Epoch 5 finished \tANN training loss 2.390271\n",
            ">> Epoch 6 finished \tANN training loss 2.063227\n",
            ">> Epoch 7 finished \tANN training loss 1.794954\n",
            ">> Epoch 8 finished \tANN training loss 1.672024\n",
            ">> Epoch 9 finished \tANN training loss 1.653397\n",
            ">> Epoch 10 finished \tANN training loss 1.555859\n",
            ">> Epoch 11 finished \tANN training loss 1.515472\n",
            ">> Epoch 12 finished \tANN training loss 1.489606\n",
            ">> Epoch 13 finished \tANN training loss 1.499680\n",
            ">> Epoch 14 finished \tANN training loss 1.477537\n",
            ">> Epoch 15 finished \tANN training loss 1.417618\n",
            ">> Epoch 16 finished \tANN training loss 1.360868\n",
            ">> Epoch 17 finished \tANN training loss 1.355638\n",
            ">> Epoch 18 finished \tANN training loss 1.345675\n",
            ">> Epoch 19 finished \tANN training loss 1.310085\n",
            ">> Epoch 20 finished \tANN training loss 1.217217\n",
            ">> Epoch 21 finished \tANN training loss 1.307267\n",
            ">> Epoch 22 finished \tANN training loss 1.208017\n",
            ">> Epoch 23 finished \tANN training loss 1.226316\n",
            ">> Epoch 24 finished \tANN training loss 1.190900\n",
            ">> Epoch 25 finished \tANN training loss 1.172703\n",
            ">> Epoch 26 finished \tANN training loss 1.087306\n",
            ">> Epoch 27 finished \tANN training loss 1.120166\n",
            ">> Epoch 28 finished \tANN training loss 1.054978\n",
            ">> Epoch 29 finished \tANN training loss 1.067485\n",
            ">> Epoch 30 finished \tANN training loss 1.048334\n",
            ">> Epoch 31 finished \tANN training loss 1.040479\n",
            ">> Epoch 32 finished \tANN training loss 0.941198\n",
            ">> Epoch 33 finished \tANN training loss 0.959223\n",
            ">> Epoch 34 finished \tANN training loss 0.905265\n",
            ">> Epoch 35 finished \tANN training loss 0.919261\n",
            ">> Epoch 36 finished \tANN training loss 0.962532\n",
            ">> Epoch 37 finished \tANN training loss 0.933354\n",
            ">> Epoch 38 finished \tANN training loss 0.926405\n",
            ">> Epoch 39 finished \tANN training loss 0.870228\n",
            ">> Epoch 40 finished \tANN training loss 0.886513\n",
            ">> Epoch 41 finished \tANN training loss 0.941603\n",
            ">> Epoch 42 finished \tANN training loss 0.859856\n",
            ">> Epoch 43 finished \tANN training loss 0.885039\n",
            ">> Epoch 44 finished \tANN training loss 0.875569\n",
            ">> Epoch 45 finished \tANN training loss 0.731653\n",
            ">> Epoch 46 finished \tANN training loss 0.697782\n",
            ">> Epoch 47 finished \tANN training loss 0.778181\n",
            ">> Epoch 48 finished \tANN training loss 0.732284\n",
            ">> Epoch 49 finished \tANN training loss 0.853479\n",
            ">> Epoch 50 finished \tANN training loss 0.696789\n",
            ">> Epoch 51 finished \tANN training loss 0.805190\n",
            ">> Epoch 52 finished \tANN training loss 0.710050\n",
            ">> Epoch 53 finished \tANN training loss 0.828871\n",
            ">> Epoch 54 finished \tANN training loss 0.790883\n",
            ">> Epoch 55 finished \tANN training loss 0.798046\n",
            ">> Epoch 56 finished \tANN training loss 0.684143\n",
            ">> Epoch 57 finished \tANN training loss 0.799153\n",
            ">> Epoch 58 finished \tANN training loss 0.677344\n",
            ">> Epoch 59 finished \tANN training loss 0.704906\n",
            ">> Epoch 60 finished \tANN training loss 0.738929\n",
            ">> Epoch 61 finished \tANN training loss 0.652261\n",
            ">> Epoch 62 finished \tANN training loss 0.799044\n",
            ">> Epoch 63 finished \tANN training loss 0.631856\n",
            ">> Epoch 64 finished \tANN training loss 0.619238\n",
            ">> Epoch 65 finished \tANN training loss 0.566165\n",
            ">> Epoch 66 finished \tANN training loss 0.608065\n",
            ">> Epoch 67 finished \tANN training loss 0.644278\n",
            ">> Epoch 68 finished \tANN training loss 0.626263\n",
            ">> Epoch 69 finished \tANN training loss 0.645868\n",
            ">> Epoch 70 finished \tANN training loss 0.632204\n",
            ">> Epoch 71 finished \tANN training loss 0.575992\n",
            ">> Epoch 72 finished \tANN training loss 0.568254\n",
            ">> Epoch 73 finished \tANN training loss 0.561473\n",
            ">> Epoch 74 finished \tANN training loss 0.609533\n",
            ">> Epoch 75 finished \tANN training loss 0.760163\n",
            ">> Epoch 76 finished \tANN training loss 0.591460\n",
            ">> Epoch 77 finished \tANN training loss 0.629957\n",
            ">> Epoch 78 finished \tANN training loss 0.508779\n",
            ">> Epoch 79 finished \tANN training loss 0.486852\n",
            ">> Epoch 80 finished \tANN training loss 0.679485\n",
            ">> Epoch 81 finished \tANN training loss 0.668330\n",
            ">> Epoch 82 finished \tANN training loss 0.458210\n",
            ">> Epoch 83 finished \tANN training loss 0.550822\n",
            ">> Epoch 84 finished \tANN training loss 0.552929\n",
            ">> Epoch 85 finished \tANN training loss 0.611924\n",
            ">> Epoch 86 finished \tANN training loss 0.462181\n",
            ">> Epoch 87 finished \tANN training loss 0.540575\n",
            ">> Epoch 88 finished \tANN training loss 0.586544\n",
            ">> Epoch 89 finished \tANN training loss 0.493655\n",
            ">> Epoch 90 finished \tANN training loss 0.529154\n",
            ">> Epoch 91 finished \tANN training loss 0.462334\n",
            ">> Epoch 92 finished \tANN training loss 0.412705\n",
            ">> Epoch 93 finished \tANN training loss 0.463512\n",
            ">> Epoch 94 finished \tANN training loss 0.455338\n",
            ">> Epoch 95 finished \tANN training loss 0.444939\n",
            ">> Epoch 96 finished \tANN training loss 0.564134\n",
            ">> Epoch 97 finished \tANN training loss 0.637959\n",
            ">> Epoch 98 finished \tANN training loss 0.414923\n",
            ">> Epoch 99 finished \tANN training loss 0.604569\n",
            ">> Epoch 100 finished \tANN training loss 0.479153\n",
            ">> Epoch 101 finished \tANN training loss 0.423417\n",
            ">> Epoch 102 finished \tANN training loss 0.469695\n",
            ">> Epoch 103 finished \tANN training loss 0.617427\n",
            ">> Epoch 104 finished \tANN training loss 0.517025\n",
            ">> Epoch 105 finished \tANN training loss 0.733479\n",
            ">> Epoch 106 finished \tANN training loss 0.414892\n",
            ">> Epoch 107 finished \tANN training loss 0.599924\n",
            ">> Epoch 108 finished \tANN training loss 0.523650\n",
            ">> Epoch 109 finished \tANN training loss 0.541579\n",
            ">> Epoch 110 finished \tANN training loss 0.464552\n",
            ">> Epoch 111 finished \tANN training loss 0.501329\n",
            ">> Epoch 112 finished \tANN training loss 0.451028\n",
            ">> Epoch 113 finished \tANN training loss 0.722391\n",
            ">> Epoch 114 finished \tANN training loss 0.520069\n",
            ">> Epoch 115 finished \tANN training loss 0.451456\n",
            ">> Epoch 116 finished \tANN training loss 0.470722\n",
            ">> Epoch 117 finished \tANN training loss 0.497340\n",
            ">> Epoch 118 finished \tANN training loss 0.612124\n",
            ">> Epoch 119 finished \tANN training loss 0.540911\n",
            ">> Epoch 120 finished \tANN training loss 0.393279\n",
            ">> Epoch 121 finished \tANN training loss 0.419276\n",
            ">> Epoch 122 finished \tANN training loss 0.355687\n",
            ">> Epoch 123 finished \tANN training loss 0.504127\n",
            ">> Epoch 124 finished \tANN training loss 0.589515\n",
            ">> Epoch 125 finished \tANN training loss 0.513087\n",
            ">> Epoch 126 finished \tANN training loss 0.396788\n",
            ">> Epoch 127 finished \tANN training loss 0.334274\n",
            ">> Epoch 128 finished \tANN training loss 0.470076\n",
            ">> Epoch 129 finished \tANN training loss 0.440528\n",
            ">> Epoch 130 finished \tANN training loss 0.482887\n",
            ">> Epoch 131 finished \tANN training loss 0.501524\n",
            ">> Epoch 132 finished \tANN training loss 0.514637\n",
            ">> Epoch 133 finished \tANN training loss 0.619178\n",
            ">> Epoch 134 finished \tANN training loss 0.615055\n",
            ">> Epoch 135 finished \tANN training loss 0.417962\n",
            ">> Epoch 136 finished \tANN training loss 0.343139\n",
            ">> Epoch 137 finished \tANN training loss 0.638631\n",
            ">> Epoch 138 finished \tANN training loss 0.384575\n",
            ">> Epoch 139 finished \tANN training loss 0.462283\n",
            ">> Epoch 140 finished \tANN training loss 0.492715\n",
            ">> Epoch 141 finished \tANN training loss 0.458702\n",
            ">> Epoch 142 finished \tANN training loss 0.474744\n",
            ">> Epoch 143 finished \tANN training loss 0.395909\n",
            ">> Epoch 144 finished \tANN training loss 0.434518\n",
            ">> Epoch 145 finished \tANN training loss 0.556953\n",
            ">> Epoch 146 finished \tANN training loss 0.401689\n",
            ">> Epoch 147 finished \tANN training loss 0.509026\n",
            ">> Epoch 148 finished \tANN training loss 0.355809\n",
            ">> Epoch 149 finished \tANN training loss 0.434289\n",
            ">> Epoch 150 finished \tANN training loss 0.560809\n",
            ">> Epoch 151 finished \tANN training loss 0.309394\n",
            ">> Epoch 152 finished \tANN training loss 0.412973\n",
            ">> Epoch 153 finished \tANN training loss 0.474530\n",
            ">> Epoch 154 finished \tANN training loss 0.495819\n",
            ">> Epoch 155 finished \tANN training loss 0.562909\n",
            ">> Epoch 156 finished \tANN training loss 0.390790\n",
            ">> Epoch 157 finished \tANN training loss 0.290158\n",
            ">> Epoch 158 finished \tANN training loss 0.538283\n",
            ">> Epoch 159 finished \tANN training loss 0.505911\n",
            ">> Epoch 160 finished \tANN training loss 0.484677\n",
            ">> Epoch 161 finished \tANN training loss 0.511077\n",
            ">> Epoch 162 finished \tANN training loss 0.432203\n",
            ">> Epoch 163 finished \tANN training loss 0.404185\n",
            ">> Epoch 164 finished \tANN training loss 0.686257\n",
            ">> Epoch 165 finished \tANN training loss 0.394048\n",
            ">> Epoch 166 finished \tANN training loss 0.424816\n",
            ">> Epoch 167 finished \tANN training loss 0.396861\n",
            ">> Epoch 168 finished \tANN training loss 0.384302\n",
            ">> Epoch 169 finished \tANN training loss 0.484797\n",
            ">> Epoch 170 finished \tANN training loss 0.556308\n",
            ">> Epoch 171 finished \tANN training loss 0.294568\n",
            ">> Epoch 172 finished \tANN training loss 0.344870\n",
            ">> Epoch 173 finished \tANN training loss 0.467045\n",
            ">> Epoch 174 finished \tANN training loss 0.638983\n",
            ">> Epoch 175 finished \tANN training loss 0.609190\n",
            ">> Epoch 176 finished \tANN training loss 0.356389\n",
            ">> Epoch 177 finished \tANN training loss 0.543348\n",
            ">> Epoch 178 finished \tANN training loss 0.480943\n",
            ">> Epoch 179 finished \tANN training loss 0.328671\n",
            ">> Epoch 180 finished \tANN training loss 0.474727\n",
            ">> Epoch 181 finished \tANN training loss 0.395461\n",
            ">> Epoch 182 finished \tANN training loss 0.776996\n",
            ">> Epoch 183 finished \tANN training loss 0.408967\n",
            ">> Epoch 184 finished \tANN training loss 0.388583\n",
            ">> Epoch 185 finished \tANN training loss 0.462575\n",
            ">> Epoch 186 finished \tANN training loss 0.460495\n",
            ">> Epoch 187 finished \tANN training loss 0.791984\n",
            ">> Epoch 188 finished \tANN training loss 0.412748\n",
            ">> Epoch 189 finished \tANN training loss 0.455544\n",
            ">> Epoch 190 finished \tANN training loss 0.656918\n",
            ">> Epoch 191 finished \tANN training loss 0.475528\n",
            ">> Epoch 192 finished \tANN training loss 0.336335\n",
            ">> Epoch 193 finished \tANN training loss 0.565785\n",
            ">> Epoch 194 finished \tANN training loss 0.433347\n",
            ">> Epoch 195 finished \tANN training loss 0.565307\n",
            ">> Epoch 196 finished \tANN training loss 0.645674\n",
            ">> Epoch 197 finished \tANN training loss 0.320240\n",
            ">> Epoch 198 finished \tANN training loss 0.693659\n",
            ">> Epoch 199 finished \tANN training loss 0.358424\n",
            ">> Epoch 200 finished \tANN training loss 0.435649\n",
            "[END] Fine tuning step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SupervisedDBNClassification()"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SupervisedDBNClassification()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SupervisedDBNClassification</label><div class=\"sk-toggleable__content\"><pre>SupervisedDBNClassification()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rca9M8C78JV9",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "95bc6b31-cf5f-43dd-95dd-39039ea1971a"
      },
      "source": [
        "#@title Evaluar red entrenada con datos de entrenamiento\n",
        "\n",
        "mostrar_detalle_entrenamiento = False #@param {type:\"boolean\"}\n",
        "\n",
        "# esta red no usa salida softMax (se mantiene por generlaización de código)\n",
        "tipo_output_softMax = False\n",
        "\n",
        "# función auxiliar para el cálculo de error\n",
        "def calcErrores(pred, real, mostrarDetalle=False):\n",
        "  arAbs = []\n",
        "  arRel = []\n",
        "\n",
        "  if mostrarDetalle:\n",
        "    print(\"\\n\")\n",
        "    print(\"\\t Real \\t\\t\\t Estimado \\t\\t Error Absoluto \\t Error Relativo\")\n",
        "\n",
        "  for pV, r in zip(pred, real):\n",
        "    # toma el valor estimado/predecido\n",
        "    p = pV[0]\n",
        "    # controla que sean números\n",
        "    if not(math.isnan(r) or math.isnan(p)):\n",
        "      # hace los cálculos\n",
        "      eAbs = abs(r - p)\n",
        "      if r != 0:\n",
        "        eRel = (eAbs / r)*100.0\n",
        "      else:\n",
        "        eRel = (eAbs / 0.00001)*100.0\n",
        "      arAbs.append(eAbs)\n",
        "      arRel.append(eRel)\n",
        "\n",
        "      if mostrarDetalle:\n",
        "        print(\"\\t{:>8.2f} \\t\\t {:>8.2f} \\t\\t {:>8.2f} \\t\\t {:>8.2f}%\".format(r, p, eAbs, eRel))\n",
        "\n",
        "  return arAbs, arRel\n",
        "\n",
        "def generarGrafico(ar, tit, b=10, c=None):\n",
        "     # genera gráfico de los errores\n",
        "    fig = plt.figure(figsize=(15,5))\n",
        " #   ax = fig.add_axes( [0, 0, 0.8, 0.8] )\n",
        " #   ax.boxplot( [arAbs, arRel] )\n",
        " #   ax.set_xticklabels( [\"Error Absoluto\", \"Error Relativo\"] )\n",
        "#    plt.legend([\"Error Absoluto\", \"Error Relativo\"], loc='best')\n",
        "    plt.hist( ar, bins=b, color=c )\n",
        "    plt.grid(color='lightgrey', which='both', axis='both', linestyle='solid', linewidth=0.3)\n",
        "    plt.title(\"Distribución de \"+ tit)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# función auxiliar para probar el modelo entrenado en detalle\n",
        "def probarModelo_Estimacion(x, y, detalle=False):\n",
        "\n",
        "    # procesa las imágenes de prueba con el modelo\n",
        "    estimVals = model.predict(x)\n",
        "\n",
        "    # llama a la función\n",
        "    arAbs, arRel = calcErrores(estimVals, y, detalle)\n",
        "\n",
        "    # muestra métricas\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n Error Absoluto: \")\n",
        "    print(\"            Mínimo: {:.5f} \".format(np.min(arAbs)) )\n",
        "    print(\"            Promedio: {:.5f} ± {:.5f}\".format(np.mean(arAbs), np.std(arAbs)) )\n",
        "    print(\"            Máximo: {:.5f} \".format(np.max(arAbs)) )\n",
        "    generarGrafico(arAbs, \"Error Absoluto\", 20, \"red\")\n",
        "\n",
        "    print(\"\\n Error Relativo: \")\n",
        "    print(\"            Mínimo: {:.2f}% \".format(np.min(arRel)) )\n",
        "    print(\"            Promedio: {:.2f} ± {:.2f}\".format(np.mean(arRel), np.std(arRel)) )\n",
        "    print(\"            Máximo: {:.2f}% \".format(np.max(arRel)) )\n",
        "    generarGrafico(arRel, \"Error Relativo\", 10, \"magenta\")\n",
        "\n",
        "\n",
        "# función auxiliar para probar el modelo entrenado en detalle\n",
        "def probarModelo_Clasificacion(x, y, clases_map, mostrarDetalle=False):\n",
        "\n",
        "    # procesa las imágenes de prueba con el modelo\n",
        "    predClass = model.predict(x)\n",
        "\n",
        "    # muestra los resultados con las imágenes\n",
        "    umbralClas = 0.5\n",
        "    classPreds = []\n",
        "    classReal = []\n",
        "    for i in range(len(x)):\n",
        "\n",
        "        # prepara salida\n",
        "        clReal = clases_map[ y[i] ]\n",
        "\n",
        "        # determina la clase predecida\n",
        "        if tipo_output_softMax:\n",
        "            ## determina clase predecida de acuerdo a la que tiene mayor valor\n",
        "            idclPred = int( np.argmax(predClass[i], axis=0) )\n",
        "            idclPredRnd = idclPred\n",
        "        else:\n",
        "            ## determina clase predecida de acuerdo al umbral de clasificación\n",
        "            idclPred = predClass[i]\n",
        "            idclPredRnd = int(idclPred)\n",
        "            if (idclPred - idclPredRnd)>0.5 and (idclPredRnd+1)<len(clases_map):\n",
        "                    idclPredRnd = idclPredRnd + 1\n",
        "\n",
        "        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n",
        "            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA\"\n",
        "        else:\n",
        "            clPred = clases_map[ idclPredRnd ]\n",
        "\n",
        "        classReal.append( clReal )\n",
        "        classPreds.append( clPred )\n",
        "\n",
        "        strTitulo = 'Real: ' + str(clReal) + ' / Modelo(RNA): '\n",
        "        strTitulo = strTitulo + str(clPred) + ' (' + str( idclPred ) +')'\n",
        "        strTitulo = strTitulo + \": \" + (\"ok\" if (clPred==clReal) else \"error!\")\n",
        "\n",
        "        # muestra comparación con la imagen\n",
        "        if mostrarDetalle:\n",
        "          print(strTitulo)\n",
        "\n",
        "    # muestra reporte de clasificación\n",
        "    print(\"\\n Reporte de Clasificación: \")\n",
        "    print(classification_report(classReal, classPreds))\n",
        "\n",
        "    # muestra matriz de confusion\n",
        "    print('\\nMatriz de Confusión ( real / modelo ): ')\n",
        "    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n",
        "    cmtx = pd.DataFrame(\n",
        "        cm,\n",
        "        index=['r:{:}'.format(x) for x in clases_map],\n",
        "        columns=['m:{:}'.format(x) for x in clases_map]\n",
        "      )\n",
        "    # agrega para poder mostrar la matrix de confusión completa\n",
        "    pd.options.display.max_rows = 100\n",
        "    pd.options.display.max_columns = 100\n",
        "    cmtx.sort_index(axis=0, inplace=True)\n",
        "    cmtx.sort_index(axis=1, inplace=True)\n",
        "    print(cmtx)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # gráfico de comparación\n",
        "    plt.title('Gráfico de Confusión: ')\n",
        "    plt.xlabel('Real')\n",
        "    plt.ylabel('Modelo')\n",
        "    plt.scatter(classReal, classPreds)\n",
        "\n",
        "# prueba con los datos de entrenamiento\n",
        "print(\"*** Resultados con datos de Entrenamiento: \")\n",
        "if esProblemaClasificacion:\n",
        "  probarModelo_Clasificacion(x_train, y_train, CLASES, mostrar_detalle_entrenamiento)\n",
        "else:\n",
        "  probarModelo_Estimacion(x_train, y_train, mostrar_detalle_entrenamiento)\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Resultados con datos de Entrenamiento: \n",
            "\n",
            " Reporte de Clasificación: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Setosa       1.00      1.00      1.00        37\n",
            "  Versicolor       0.97      0.97      0.97        38\n",
            "   Virginica       0.97      0.97      0.97        37\n",
            "\n",
            "    accuracy                           0.98       112\n",
            "   macro avg       0.98      0.98      0.98       112\n",
            "weighted avg       0.98      0.98      0.98       112\n",
            "\n",
            "\n",
            "Matriz de Confusión ( real / modelo ): \n",
            "              m:Setosa  m:Versicolor  m:Virginica  m:na\n",
            "r:Setosa            37             0            0     0\n",
            "r:Versicolor         0            37            1     0\n",
            "r:Virginica          0             1           36     0\n",
            "r:na                 0             0            0     0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gm_70hZDO90",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "outputId": "c1eb5061-ad7d-4d29-e2be-32242775c18d"
      },
      "source": [
        "#@title Evaluar red entrenada con datos de prueba\n",
        "mostrar_detalle_prueba = False #@param {type:\"boolean\"}\n",
        "\n",
        "# prueba con los datos de prueba\n",
        "print(\"\\n\\n*** Resultados con datos de Prueba: \")\n",
        "if esProblemaClasificacion:\n",
        "  probarModelo_Clasificacion(x_test, y_test, CLASES, mostrar_detalle_prueba)\n",
        "else:\n",
        "  probarModelo_Estimacion(x_test, y_test, mostrar_detalle_prueba)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*** Resultados con datos de Prueba: \n",
            "\n",
            " Reporte de Clasificación: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Setosa       1.00      1.00      1.00        13\n",
            "  Versicolor       0.91      0.83      0.87        12\n",
            "   Virginica       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.92        38\n",
            "   macro avg       0.92      0.92      0.92        38\n",
            "weighted avg       0.92      0.92      0.92        38\n",
            "\n",
            "\n",
            "Matriz de Confusión ( real / modelo ): \n",
            "              m:Setosa  m:Versicolor  m:Virginica  m:na\n",
            "r:Setosa            13             0            0     0\n",
            "r:Versicolor         0            10            2     0\n",
            "r:Virginica          0             1           12     0\n",
            "r:na                 0             0            0     0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inspeccionar influencia de los Atributos de Entrada\n",
        "# fuente: https://scikit-learn.org/stable/modules/permutation_importance.html\n",
        "determinar_influencia = False #@param {type:\"boolean\"}\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# define la función para calculo del error\n",
        "# contando la cantidad de diferencias\n",
        "# entre clase real y predecida\n",
        "def calc_error(realClasses, predClasses):\n",
        "    res = 0\n",
        "    for i in range(len(realClasses)):\n",
        "      res = res + abs(realClasses[i]-predClasses[i])\n",
        "    return res\n",
        "errorScorer = make_scorer(calc_error, greater_is_better=False)\n",
        "\n",
        "def realizarInspeccion(tipoDatos, xScoring, yScoring):\n",
        "  print(\"\")\n",
        "  # Genera el scoring usando permutaciones\n",
        "  # para realizar el cálculo del scoring\n",
        "  scoring = {'R2 score':'r2',\n",
        "             'Error de Clase':errorScorer}\n",
        "  r_multi  = permutation_importance(model, xScoring, yScoring,\n",
        "                              n_repeats=30,\n",
        "                              random_state=0,\n",
        "                              scoring=scoring)\n",
        "\n",
        "  # muesta las métricas\n",
        "  print(\"> Cálculo de influencia con datos de \" + tipoDatos + \":\")\n",
        "  for metric in r_multi:\n",
        "    print(\"- Métrica \"+metric+\":\")\n",
        "    r = r_multi[metric]\n",
        "    i = 0\n",
        "    for imp in r.importances:\n",
        "        print(f\"\\tAtributo {i:<2} [ {df.columns[i]} ]:  \"\n",
        "              f\"{np.mean(imp):.3f} ± {np.std(imp):.3f}\"\n",
        "              f\" [ {np.min(imp):.3f}; {np.max(imp):.3f} ]\"\n",
        "              )\n",
        "        i = i + 1\n",
        "  return\n",
        "\n",
        "if determinar_influencia:\n",
        "  # Ejecuta con ambos sets de datos\n",
        "  realizarInspeccion(tipoDatos=\"Entrenamiento\",\n",
        "                    xScoring = x_train,\n",
        "                    yScoring = y_train)\n",
        "\n",
        "  realizarInspeccion(tipoDatos=\"Prueba\",\n",
        "                    xScoring = x_test,\n",
        "                    yScoring = y_test)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ooTorhluxfFs"
      },
      "execution_count": 70,
      "outputs": []
    }
  ]
}