{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Imag-objDetection-TF-Hub-CNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ok7LonchvbTl"},"source":["\n","#*Demo de uso de TF-Hub  para detectar múltiples objetos en una imagen*\n","Basado en info de https://github.com/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb"]},{"cell_type":"markdown","metadata":{"id":"BrufV2ptwL1F"},"source":["1) Cargar Librerías:"]},{"cell_type":"code","metadata":{"id":"uHP-kWh5wOrX","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658249833627,"user_tz":180,"elapsed":3563,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"b7141ae0-14d9-447b-bc4c-d48f73470b77"},"source":["#@title Cargar Librerías\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","import numpy as np\n","from PIL import Image\n","from PIL import ImageColor\n","from PIL import ImageDraw\n","from PIL import ImageFont\n","from PIL import ImageOps\n","\n","import tempfile\n","import time\n","import os\n","\n","print(\"Librerías cargadas.\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Librerías cargadas.\n"]}]},{"cell_type":"markdown","metadata":{"id":"4KrRlxXy5kLT"},"source":["2) Montar el Drive:\n","\n"]},{"cell_type":"code","metadata":{"id":"byeW20QT4LIG","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658249864073,"user_tz":180,"elapsed":30457,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"fc056931-d714-485b-e993-db561c270cf0"},"source":["#@title Montar Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demoML/imagenes/MUCHOS'  #@param {type:\"string\"}"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"AwCU5MIrw0Oj"},"source":["3) Seleccionar modelo a cargar y utilizar:\n","\n","*Nota: MobileNet es más rápido pero Inception tiene mejor precisión.*"]},{"cell_type":"code","metadata":{"id":"KyGJ3JS96y1Q","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658249954806,"user_tz":180,"elapsed":90769,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"7de737d6-7bea-414f-ec15-156fc48102d5"},"source":["#@title Seleccionar el modelo a usar\n","module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" ]\n","\n","# carga el módulo a usar\n","detector = hub.load(module_handle).signatures['default']\n","\n","print(\"Modelo \", module_handle, \"cargado\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"]},{"output_type":"stream","name":"stdout","text":["Modelo  https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1 cargado\n"]}]},{"cell_type":"markdown","metadata":{"id":"WaX5qOluwzIr"},"source":["4) Cargar las imágenes a procesar:"]},{"cell_type":"code","metadata":{"id":"_oY5yNCE7Rj2","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658249956697,"user_tz":180,"elapsed":1905,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"0fe3b6a0-a881-44fa-889d-56bbcc2b4af9"},"source":["#@title Cargar imágenes del directorio\n","# levanta imágenes \n","all_images_array = []\n","auxiPath = path\n","all_files = os.listdir(auxiPath)\n","for each_file in all_files:\n","    if(each_file.endswith(\".jpg\") or each_file.endswith(\".png\")):\n","        all_images_array.append(auxiPath + \"/\" + each_file)\n","\n","print(len(all_images_array), \" imágenes cargadas.\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["5  imágenes cargadas.\n"]}]},{"cell_type":"markdown","metadata":{"id":"MO0ZR_6eCH6M"},"source":["5) Ejecutar el modelo seleccionado sobre las imágenes cargadas y mostrar los resultados:"]},{"cell_type":"code","metadata":{"id":"u5n5dDAYcrJs","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19zBhnGWBFm3U9W0KxfzDfIe4iStAAD5I"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1658250151026,"user_tz":180,"elapsed":194341,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"518c17ba-5c63-4131-b9c1-d161b66ec456"},"source":["#@title Procesar imágenes\n","## funciones auxiliares\n","mostrar_subimagenes_objetos = False #@param {type:\"boolean\"}\n","\n","# genera borde para objetos encontrados\n","def draw_bounding_box_on_image(image,\n","                               ymin,\n","                               xmin,\n","                               ymax,\n","                               xmax,\n","                               color,\n","                               font,\n","                               thickness=4,\n","                               display_str_list=()):\n","  \"\"\"Adds a bounding box to an image.\"\"\"\n","  draw = ImageDraw.Draw(image)\n","  im_width, im_height = image.size\n","  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n","                                ymin * im_height, ymax * im_height)\n","  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n","             (left, top)],\n","            width=thickness,\n","            fill=color)\n","\n","  # If the total height of the display strings added to the top of the bounding\n","  # box exceeds the top of the image, stack the strings below the bounding box\n","  # instead of above.\n","  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n","  # Each display_str has a top and bottom margin of 0.05x.\n","  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n","\n","  if top > total_display_str_height:\n","    text_bottom = top\n","  else:\n","    text_bottom = bottom + total_display_str_height\n","  # Reverse list and print from bottom to top.\n","  for display_str in display_str_list[::-1]:\n","    text_width, text_height = font.getsize(display_str)\n","    margin = np.ceil(0.05 * text_height)\n","    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n","                    (left + text_width, text_bottom)],\n","                   fill=color)\n","    draw.text((left + margin, text_bottom - text_height - margin),\n","              display_str,\n","              fill=\"black\",\n","              font=font)\n","    text_bottom -= text_height - 2 * margin\n","\n","\n","# indicar objetos detectados en una imagen\n","def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n","  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n","  colors = list(ImageColor.colormap.values())\n","\n","  try:\n","    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n","                              25)\n","  except IOError:\n","    print(\"Font not found, using default font.\")\n","    font = ImageFont.load_default()\n","\n","  countBoxDisplayed = 0\n","  for i in range(min(boxes.shape[0], max_boxes)):\n","    if scores[i] >= min_score:\n","      countBoxDisplayed = countBoxDisplayed + 1\n","      ymin, xmin, ymax, xmax = tuple(boxes[i])\n","      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n","                                     int(100 * scores[i]))\n","      color = colors[hash(class_names[i]) % len(colors)]\n","      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n","      draw_bounding_box_on_image(\n","          image_pil,\n","          ymin,\n","          xmin,\n","          ymax,\n","          xmax,\n","          color,\n","          font,\n","          display_str_list=[display_str])\n","      np.copyto(image, np.array(image_pil))\n","  return image, countBoxDisplayed\n","\n","# define la minima probabilidad que se va a usar para detectar objetos\n","mininaProbabilidad = 50 #@param {type:\"integer\"}\n","min_score_display = mininaProbabilidad / 100\n","max_boxes_per_image = 50\n","\n","# indica si muestra detalle de resultados o no\n","print(\"> Modelo \", module_handle, \":\")\n","\n","# procesalas imágenes cargadas\n","for each_image in all_images_array:\n","  \n","  print(\"-----------------------------------------------------------------------------\") \n","  print(\"* \", each_image)\n","\n","  # carga la imagen, la prepar grabandolo en un archivo temporal para su uso\n","  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n","  pil_image = Image.open(each_image)\n","  pil_image = ImageOps.fit(pil_image, (640, 480), Image.ANTIALIAS)\n","  pil_image_rgb = pil_image.convert(\"RGB\")\n","  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n","\n","  img = tf.io.read_file(filename)\n","  img = tf.image.decode_jpeg(img, channels=3)\n","  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n","\n","  # procesa la imagen en el modelo previamente cargado\n","  # devolviendo un vector con los resultados   \n","  start_time = time.time()\n","  result = detector(converted_img)\n","  end_time = time.time()  \n","  result = {key:value.numpy() for key,value in result.items()}\n","\n","  image_with_boxes, countBoxDisplayed = draw_boxes(\n","      img.numpy(), \n","      result[\"detection_boxes\"],\n","      result[\"detection_class_entities\"], \n","      result[\"detection_scores\"],\n","      max_boxes_per_image, \n","      min_score_display)\n","\n","  # muestra la imagen con los objetos detectados\n","  imMostrar = Image.fromarray(image_with_boxes, 'RGB')\n","  display( imMostrar )\n","\n","  countObjMinScore = 0\n","  for eachScore in result[\"detection_scores\"]:\n","    if eachScore >= min_score_display:\n","      countObjMinScore = countObjMinScore + 1\n","\n","  print(\" -- Objetos mostrados: %d de %d detectados total.\" % (countBoxDisplayed, len(result[\"detection_boxes\"])) )\n","  print(\" -- Objetos detectados con mínimo score %3.2f: %d.\" % (min_score_display, countObjMinScore) )\n","  print(\" -- Tiempo de procesamiento: \", (end_time - start_time))\n","\n","  if mostrar_subimagenes_objetos:\n","    print(\"\\n\")\n","    imCargada_ancho, imCargada_alto = pil_image.size\n","\n","    # muestra detalle de los objetos detectados\n","    for detClass, detBox, detScore in zip( result[\"detection_class_entities\"], result[\"detection_boxes\"],  result[\"detection_scores\"]):    \n","      if detScore >= min_score_display:\n","          print(\"\\n    - \", detClass, \" : \", detScore, \"% : \", detBox)\n","\n","        # como las coordenadas están normalizadas las debe convertir \n","          # teniendo en cuenta el tamaño de la imagen\n","          # además notar que vienen datas en otro orden\n","          # - detBox = (ini alto, ini ancho, fin alto, fin ancho)\n","          # - nuevoRangoIn = (ini ancho, ini alto, fin ancho, fin alto)    \n","          nuevoRangoIm = (detBox[1] * imCargada_ancho, \n","                          detBox[0] * imCargada_alto,\n","                          detBox[3] * imCargada_ancho,\n","                          detBox[2] * imCargada_alto) \n","          display ( pil_image.crop(nuevoRangoIm) )\n","\n","print(\"\\n-----------------------------------------------------------------------------\\n\")"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}