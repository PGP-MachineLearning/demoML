{"cells":[{"cell_type":"markdown","metadata":{"id":"a9kUSIpP3xvb"},"source":["# Demo de Deep Autoencoder (DAE) con imágenes \n","Basado en: \n","\n","https://blog.keras.io/building-autoencoders-in-keras.html\n","\n","\n","https://towardsdatascience.com/deep-autoencoders-using-tensorflow-c68f075fd1a3"]},{"cell_type":"markdown","source":["# Preparación:"],"metadata":{"id":"mcPbVa1v4P99"}},{"cell_type":"code","metadata":{"cellView":"form","id":"MlA4a-JJ3xvd"},"source":["#@title Librerías a usar\n","from tensorflow import keras\n","from keras.models import Model\n","from tensorflow.keras.utils import plot_model\n","from keras.utils import np_utils\n","\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","import random\n","import copy\n","import math\n","\n","import ipywidgets as widgets\n","from ipywidgets import Box, Layout\n","\n","import cv2\n","from PIL import Image\n","\n","import os\n","import csv\n","\n","print(\"\\nLibrerías importadas\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4p0oqQMaHwX","cellView":"form"},"source":["#@title Acceder al Drive\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demoML/imagenes/NUMEROS' #@param {type:\"string\"}\n","path_entrenamiento = '/train'  #@param {type:\"string\"}\n","path_prueba = '/test'  #@param {type:\"string\"}\n","\n","imagPath_train = path + path_entrenamiento\n","imagPath_test = path + path_prueba"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYz8mV4SnJ4O","cellView":"form"},"source":["#@title Cargar imágenes\n","\n","\n","#@markdown ### Parámetros para imágenes:\n","imagen_ancho = 32 #@param {type:\"integer\"}\n","imagen_largo = 32 #@param {type:\"integer\"}\n","imagen_color = True #@param {type:\"boolean\"}\n","incluir_imagenes_generadas_con_data_augmentation = False #@param {type:\"boolean\"}\n","\n","\n","# tamaño de las imágenes\n","if imagen_ancho<=10:\n","  imagen_largo = 10\n","if imagen_largo<=10:\n","  imagen_largo = 10\n","IMAGE_SHAPE = (imagen_ancho, imagen_largo, (3 if imagen_color else 1))\n","\n","# define tamaño de datos de entrada \n","num_inputs = IMAGE_SHAPE[0] * IMAGE_SHAPE[1] * IMAGE_SHAPE[2]\n","\n","# indica si se usan las imágenes generadas por data augmentation\n","usarDA = incluir_imagenes_generadas_con_data_augmentation\n","\n","\n","# define función para cargar las imágenes\n","def cargarImagenes(imagPath):\n","  classes_ori = [] \n","  images_ori = []\n","  esDA_ori = []\n","\n","  all_dirs = os.listdir( imagPath )\n","  for each_dir in all_dirs:\n","\n","      auxiPath = imagPath + '/' + each_dir \n","      imagFN  = os.listdir( auxiPath )\n","      for each_imagFN in imagFN:\n","\n","            esImagDA = (each_imagFN[:2] == 'da')\n","            \n","            if usarDA or (not esImagDA): \n","                \n","                # abre la imagen\n","                imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","                \n","                # ajusta el tamaño\n","                if IMAGE_SHAPE[2]==1:              \n","                  tipoImage = 'L'\n","                else:                \n","                  tipoImage = 'RGB'\n","                imag = imag.convert(tipoImage)\n","                imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.ANTIALIAS)          \n","                \n","                # transforma a un vector de nros\n","                arImag = np.array(imag)\n","                \n","                # agrega a los vectores\n","                classes_ori.append( each_dir )\n","                images_ori.append( arImag )\n","                esDA_ori.append( esImagDA )\n","\n","  return classes_ori, images_ori, esDA_ori, tipoImage\n","\n","# carga las imagenes de entrenamiento\n","classes_train, images_train, esDAimag_train, tipoImage_train = cargarImagenes(imagPath_train)\n","print(\"> Para Entrenamiento: \")\n","print(\"- Clases cargadas: \", len(np.unique(classes_train)))\n","print(\"- Imágenes cargadas: \", len(classes_train))\n","\n","if len(classes_train)>0:\n","  print(\"- Ejemplo \", classes_train[0], \" \", images_train[0].shape, \": \")\n","  display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","# carga las imagenes de prueba\n","classes_test, images_test, esDAimag_test, tipoImage_test = cargarImagenes(imagPath_test)\n","print(\"\\n\\n> Para Prueba: \")\n","print(\"- Clases cargadas: \", len(np.unique(classes_test)))\n","print(\"- Imágenes cargadas: \", len(images_test))\n","\n","if len(classes_test)>0:\n","  print(\"- Ejemplo \", classes_test[0], \" \", images_test[0].shape, \": \")\n","  display( Image.fromarray(images_test[0], tipoImage_test) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Ajustar imágenes para reducir el fondo (opcional)\n","\n","accion_realizar = \"-\" #@param [\"-\", \"Blur Fondo\", \"Eliminar Fondo y pasar a Negro\", \"Eliminar Fondo y pasar a Blanco\"]\n","\n","def cambiarColorNegro(img, nuevoColor=[255, 255, 255]):\n","    black_pixels = np.where(\n","        (img[:, :, 0] == 0) & \n","        (img[:, :, 1] == 0) & \n","        (img[:, :, 2] == 0)\n","    )\n","    img[black_pixels] = nuevoColor\n","    return img\n","\n","def blurFondoImagen(im):\n","  # Convert to the HSV color space\n","  hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n","  # aplica filtro Otsu threshold para obtener máscara\n","  ret, maskthresh = cv2.threshold(hsv[:,:,0], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","  # Genera la máscara negada\n","  maskthresh = 255 - maskthresh\n","  # We need a to copy the mask 3 times to fit the frames\n","  maskthresh = np.repeat(maskthresh[:, :, np.newaxis], 3, axis=2)\n","  #  Create a blurred frame using Gaussian blur\n","  blurred_frame = cv2.GaussianBlur(im, (25, 25), 0)\n","  # Combine the original with the blurred frame based on mask\n","  return np.where(maskthresh == (255, 255, 255), im, blurred_frame)\n","\n","def reducirFondoImagen(im):\n","  # aplica filtro Hue\n","  imhsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n","  # aplica filtro Otsu threshold para obtener máscara\n","  ret, maskthresh = cv2.threshold(imhsv[:,:,0], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","  # Genera la máscara negada\n","  maskthresh = 255 - maskthresh\n","  # aplica la máscara sobre la imagen\n","  imgfin = cv2.bitwise_and(im, im, mask = maskthresh)\n","  return imgfin\n","\n","def procesarImgRedFondo(imgList):\n","  nList = []\n","  for im in imgList:\n","    if accion_realizar == \"Blur Fondo\":\n","      # hacer blur del fondo\n","      imn = blurFondoImagen(im)\n","    elif accion_realizar == \"Eliminar Fondo y pasar a Negro\":\n","      # eliminar fondo y dejar negro\n","      imn = reducirFondoImagen(im)\n","    elif accion_realizar == \"Eliminar Fondo y pasar a Blanco\":\n","        # cambia fondo negro a casi negro \n","        # (para que no cambié después) \n","        imn = cambiarColorNegro(im, [0, 0, 1])\n","        # eliminar fondo\n","        imn = reducirFondoImagen(imn)\n","        # cambiar fondo a blanco\n","        imn = cambiarColorNegro(imn, [255, 255, 255])\n","    else:\n","      print(\"Acción no definida!\")\n","      break\n","    nList.append( imn )\n","  return nList\n","\n","\n","# degermina si hace algo o no\n","if accion_realizar != \"-\":\n","  # aplica filtros para intentar reducir el fondo de la imagen\n","  # cambiando las imágenes disponibles\n","  images_train = procesarImgRedFondo(images_train)\n","  images_test = procesarImgRedFondo(images_test)\n","\n","  if len(classes_train)>0:\n","    print(\"- Ejemplo Entrenamiento con fondo reducido \", classes_train[0], \" \", images_train[0].shape, \": \")\n","    display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","  if len(classes_test)>0:\n","    print(\"- Ejemplo Prueba con fondo reducido \", classes_test[0], \" \", images_test[0].shape, \": \")\n","    display( Image.fromarray(images_test[0], tipoImage_test) )"],"metadata":{"cellView":"form","id":"M4Er08Jt_PMy"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPPvnkjTnTQN","cellView":"form"},"source":["#@title Preparar imágenes para usar en el modelo\n","\n","#@title Preparar imágenes\n","\n","def agregarRuidoImagen(x_datos, gradoRuido):\n","  # copia datos para no cambiar original\n","  x_datos = copy.deepcopy(x_datos)\n","  # si es negativo, determina el grado al azar\n","  if gradoRuido < 0:\n","    gradoRuido = random.randint(0, 100)\n","  # agrega ruido al azar  \n","  x_datos = x_datos + np.random.normal(loc=0.0, scale=gradoRuido/100, size=x_datos.shape)\n","  x_datos = np.clip(x_datos, 0., 1.)\n","  return x_datos\n","\n","# define función auxiliar para mostrar imágenes preparadas\n","def plot_image(imag):\n","  if IMAGE_SHAPE[2]==1:\n","    plt.imshow((imag*255).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8))\n","    plt.gray()\n","  else:\n","    plt.imshow((imag*255).reshape(IMAGE_SHAPE).astype(np.uint8))\n","  plt.axis(\"off\")  \n","\n","# define función auxiliar para preparar la lista de imágenes a procesar\n","def prepare_imageList(imagList, normValores=True):    \n","  auxiAr = np.array(imagList)\n","  if normValores:\n","    auxiAr = auxiAr.astype('float32') / 255.\n","  auxiAr = auxiAr.reshape((len(auxiAr), num_inputs))  \n","  return np.array(auxiAr)\n","\n","# define vector auxiliar de datos de entrada para usar en el entrenamiento y prueba\n","x_train = prepare_imageList(images_train)\n","x_test = prepare_imageList(images_test)\n","\n","# define función auxiliar para preparar lista de clases \n","def prepare_clasesList(classesList, dictMapeo=None):\n","  if dictMapeo==None:\n","    # genera diccionario de mapeo\n","    auxDict = list(set(classesList))\n","    dictMapeo = dict( zip( auxDict, range(len(auxDict)) ) )\n","  # realiza el mapeo\n","  y = []\n","  for cl in classesList:\n","      y.append( dictMapeo[cl] )\n","  # convierte valores numéricos a columnas de vaores binarios (i.e. one hot encoded)\n","  dummy_y = np_utils.to_categorical(y)\n","  # devuelve\n","  return np.array(y), np.array(dummy_y), dictMapeo\n","\n","# define vector auxiliar de datos de entrada para usar en el entrenamiento y prueba\n","x_train = prepare_imageList(images_train)\n","x_test = prepare_imageList(images_test)\n","\n","# define vector auxiliar de datos de salida para usar en el entrenamiento y prueba\n","# también usa esta información para determinar la cantida de neuronas de salida\n","y_train, y_trainEnc, dictMapeo = prepare_clasesList(classes_train)\n","y_test, y_testEnc,_ = prepare_clasesList(classes_test, dictMapeo)\n","\n","daLayers_modelo = []\n","\n","# genera diccionario auxiliar para poder convertir de ID de clase a nombre de clase\n","CLASES = [ x for x, y in dictMapeo.items() ]\n","\n","print(\"> Para Entrenamiento: \")\n","print(\" - x_train (cant ejemplos, datos entrada): \", x_train.shape)\n","print(\" - y_trainEnc (cant): \", len(y_trainEnc))\n","print(\" - y_train (cant): \", len(y_train))\n","print(\"\\n\\n> Para Prueba: \")\n","print(\" - x_test (cant ejemplos, datos entrada): \", x_test.shape)\n","print(\" - y_testEnc (cant): \", len(y_testEnc))\n","print(\" - y_test (cant): \", len(y_test))\n","print(\"\\n\\n> Para Ambos: \")\n","print(\" - dictMapeo: \", dictMapeo)\n","print(\" - CLASES: \", CLASES)\n","if len(y_train)>0:\n","  print(\"\\n - Imagen reconstruida de \", CLASES[y_train[0]],  \"(\", y_train[0], \" / \", y_trainEnc[0], \")\")\n","  plot_image(x_train[0])\n","\n","\n","# inicializa lista para ejemplos con ruido\n","x_ruido_train_in = []\n","x_ruido_train_out = []  "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Agregar ejemplos que tienen ruido al azar para entrenamiento\n","\n","gradoRuidoImagenes_entrenamiento = -1 #@param {type:\"slider\", min:-1, max:100, step:1}\n","#@markdown (Nota: si se indica negativo, se determina un grado al azar)\n","\n","if (len(x_train) > 0) and (gradoRuidoImagenes_entrenamiento != 0):\n","  # agrega ruido al azar\n","  x_nuevasRuido = agregarRuidoImagen(x_train, gradoRuidoImagenes_entrenamiento)\n","  x_ruido_train_in.extend( x_nuevasRuido )\n","  x_ruido_train_out.extend( x_train)\n","  print(\"> Ejemplos de imágenes con ruido: \")\n","  for _ in range(10):\n","      # elige al azar\n","      posAzar = random.randint(0, len(x_nuevasRuido)-1)\n","      # prepara para mostrar\n","      fig = plt.figure()\n","      fig.suptitle( \"clase: \" + str( CLASES[y_train[posAzar]] ) )\n","\n","      # muestra la real\n","      ax1 = fig.add_subplot(122)\n","      plot_image( x_train[posAzar] )\n","\n","      # muestra la imagen con ruido\n","      ax2 = fig.add_subplot(121)\n","      plot_image( x_nuevasRuido[posAzar] )\n","\n","      plt.tight_layout()\n","      fig = plt.gcf()\n","\n","  print(\"\\n> Se agregaron IN:\", len(x_ruido_train_in), \"/ OUT:\", len(x_ruido_train_out), \" imágenes con ruido para entrenamiento.\\n\")\n","else:\n","  print(\"\\n> No se agregan imágenes con ruido para entrenamiento.\\n\")"],"metadata":{"cellView":"form","id":"ew6A2fjhgr_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Construcción de Deep AutoEncoder: \n"],"metadata":{"id":"dapfStiY3lcI"}},{"cell_type":"code","metadata":{"id":"oVxgknOY3xvm"},"source":["#@title Establecer el modelo DAE\n","\n","#@markdown ### Parámetros de la Red:\n","rna_cant_neuronas_capas_ocultas = '512, 128, 64,16' #@param {type:\"string\"}\n","rna_neuronas_funcion_activacion = \"relu\" #@param [\"linear\", \"relu\", \"sigmoid\", \"tanh\"]\n","rna_cant_neuronas_capa_features = 8 #@param {type:\"integer\"}\n","\n","#@markdown ### Parámetros para ayudar aprender a capas Encoder:\n","rna_valor_L1_activity_regularizer = False #@param {type:\"boolean\"}\n","#@markdown (Nota: si se indica verdadero, se agrega la restricción de las representaciones para que sean compactas en capas de Encoders - nunca en Decoders)\n","\n","rna_porc_capa_DropOut = 0.0 #@param {type:\"number\"}\n","#@markdown (Nota: si se indica valor mayor a cero, se agregan capas DropOut en capas de Encoders - nunca en Decoders)\n","\n","#@markdown ### Parámetros del Optimizador:\n","opt_tipo = \"Adam\" #@param [\"Gradiente Decreciente\", \"Adam\", \"Adadelta\", \"Adagrad\", \"Adamax\", \"Nadam\", \"FTRL\"]\n","opt_learning_rate = 0.001 #@param {type: \"number\"}\n","\n","# define tamaño de datos de entrada y salida\n","num_outputs = num_inputs\n","\n","# cantidad de neuronas ocultas para features (datos comprimidos o codings)\n","if rna_cant_neuronas_capa_features < 1:\n","  num_features = 1\n","else:\n","  num_features = rna_cant_neuronas_capa_features\n","\n","\n","if opt_tipo == \"Gradiente Decreciente\":\n","  opt = keras.optimizers.SGD(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adam\":\n","  opt = keras.optimizers.Adam(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adadelta\":\n","  opt = keras.optimizers.Adadelta(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adagrad\":\n","  opt = keras.optimizers.Adagrad(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adamax\":\n","  opt = keras.optimizers.Adamax(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Nadam\":\n","  opt = keras.optimizers.Nadam(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"FTRL\":\n","  opt = keras.optimizers.Ftrl(learning_rate=opt_learning_rate)\n","else:\n","  opt = keras.optimizers.Adam()\n","\n","\n","# cantidad de neuronas ocultas para la parte Encoder \n","#   (cada elemento de la lista es la cantidad de pesos que tiene cada una)\n","dae_layers = []\n","for val in rna_cant_neuronas_capas_ocultas.split(','):\n","  val = val.strip()\n","  dae_layers.append( int(val) )\n","\n","#  agrega la capa de features a las capas\n","dae_layers.append( num_features ) \n","\n","# cantidad de neuronas ocultas para la parte Decoder \n","#   (usa la la lista de Encoder inversa)\n","for eachEncLayer in dae_layers[0:len(dae_layers)-1][::-1]:\n","  dae_layers.append( eachEncLayer )\n","\n","if rna_porc_capa_DropOut > 0.9:\n","  rna_porc_capa_DropOut = 0.9\n","\n","# define la arquitectura de capas del Deep Autoencoder\n","# teniendo en cuenta la definición dada anteriomente\n","input_data_Lay = tf.keras.layers.Input(shape=(num_inputs,), name='input_data') # capa de entrada\n","eachLay = input_data_Lay\n","auxName = 'enc_'\n","auxId = 1 \n","for num_hid in dae_layers:  \n","\n","    # define el nombre de la capa oculta\n","    actReg_Dense = None\n","    if num_features==num_hid:\n","        # capa tipo Features\n","        auxlayerName = 'features'\n","        auxName = 'dec_'\n","        auxId = auxId - 1\n","    else:\n","        auxlayerName = auxName+str(auxId)\n","        if auxName == 'enc_':\n","          # capa tipo Encoder\n","          auxId = auxId + 1\n","          if rna_valor_L1_activity_regularizer:\n","            # agrega regulizer\n","            actReg_Dense = tf.keras.regularizers.l1(10e-5)\n","        else:\n","          # capa tipo Decoder\n","          auxId = auxId - 1\n","\n","    # agrega la capa oculta\n","    eachLay = tf.keras.layers.Dense(num_hid, \n","                                    activation = rna_neuronas_funcion_activacion, \n","                                    activity_regularizer = actReg_Dense,\n","                                    name = auxlayerName)(eachLay) # capas ocultas\n","    \n","    if num_features==num_hid:\n","      # guarda capa Features\n","      features_Lay = eachLay\n","\n","    # agrega capa Drop si es Encoder y se indica probabilidad > 0\n","    if (rna_porc_capa_DropOut>0.0) and (auxName == 'enc_'):\n","      eachLay = tf.keras.layers.Dropout(rna_porc_capa_DropOut, \n","                                        name = auxlayerName+\"_dp\")(eachLay)\n","\n","##if imagen_color:\n","##rna_salida_funcion_activacion = \"tanh\"\n","##else:\n","rna_salida_funcion_activacion = \"sigmoid\"\n","\n","# capa de salida\n","output_data_Lay = tf.keras.layers.Dense(num_outputs, \n","                                         activation = rna_salida_funcion_activacion, \n","                                         name='output_data')(eachLay) # capa de salida\n","\n","# genera el modelo Deep Autoencoder\n","DAEmodel = Model(input_data_Lay, output_data_Lay, name='DAE')\n","\n","# dependiendo de la función de la capa de salida y si son imágenes con color \n","# determinar cómo se calcula el loss\n","if imagen_color and (rna_salida_funcion_activacion == \"sigmoid\"):\n","  lossFunc = \"mse\"\n","else:\n","   lossFunc = \"binary_crossentropy\"\n","\n","\n","DAEmodel.compile(optimizer=opt, loss=lossFunc, metrics=['RootMeanSquaredError'])\n","\n","print(\"Modelo DAE creado con \", len(DAEmodel.layers), \" capas:\")\n","DAEmodel.summary()\n","print(\"\\n\")\n","plot_model(DAEmodel, show_layer_names=True, show_shapes=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"GkHpdOsx3xvo"},"source":["#@title Entrenar DAE\n","\n","cant_epocas_entrenamiento = 500 #@param {type:\"integer\"}\n","\n","# cantidad de épocas del entrenamiento\n","cantEpocas = (1 if cant_epocas_entrenamiento<1 else cant_epocas_entrenamiento)\n","\n","# inicializa listtas auxiliares para entrenar\n","x_train_in = list( copy.deepcopy(x_train) )\n","x_train_out = list( copy.deepcopy(x_train) )\n","\n","# si hay datos con ruido para agregar\n","if not(x_ruido_train_in is None) and (len(x_ruido_train_in)>0) and not(x_ruido_train_out is None) and (len(x_ruido_train_out)>0): \n","  x_train_in.extend( x_ruido_train_in )\n","  x_train_out.extend( x_ruido_train_out )\n","\n","# prepara para que lo pueda usar el modelo\n","# (no se vuelven a normalizar los valores porque ya lo están)\n","x_train_in = prepare_imageList( x_train_in, False )\n","x_train_out = prepare_imageList( x_train_out, False )\n","\n","print(\"-- Cantidad de ejemplos para entrenar: \",  x_train_in.shape, \"/\", x_train_out.shape, \"\\n\")\n","\n","# determina datos para entrenar\n","# lleva a cabo el entrenamiento\n","history = DAEmodel.fit(x_train_in, x_train_out,\n","                epochs = cantEpocas, \n","                shuffle = True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jy8EwlnmMaRN","cellView":"form"},"source":["#@title Mostrar Gráficos del Entrenamiento\n","plt.figure(figsize=(15,8)) \n","plt.plot(history.history['loss'])\n","plt.title('Gráfico del Error del Entrenamiento')\n","plt.ylabel('')\n","plt.xlabel('epoch')\n","plt.show()\n","\n","plt.figure(figsize=(15,8)) \n","plt.plot(history.history['root_mean_squared_error'])\n","plt.title('Gráfico de la Distancia Media Cuadrática Mínima del Entrenamiento')\n","plt.ylabel('')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Evaluar el modelo con las imágenes de entrenamiento\n","\n","# para sacar warning por cantidad de imágenes mostradas\n","plt.rcParams.update({'figure.max_open_warning': 0})\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo_DAE(x, y, esDAimag, claseFiltrar=None, gradoRuido=0):\n","\n","  # determina clase a filtrar\n","  if (claseFiltrar is None) or (claseFiltrar == \"TODOS\"):\n","        clFiltrarID = None\n","  else:\n","        clFiltrarID = dictMapeo[claseFiltrar]\n","\n","  # agrega ruido según corresponda\n","  if gradoRuido == 0:\n","    x_in = x\n","  else:\n","    x_in = agregarRuidoImagen(x, gradoRuido)\n","\n","  # procesa las imágenes con el modelo \n","  reconstr_imgs = DAEmodel.predict(x_in, verbose=0)\n","  cantMostradas = 0\n","  for i in range(len(x)):\n","    # determina si filtra por clase\n","    if (clFiltrarID is None) or (clFiltrarID == y[i]):\n","      # no muestra las generadas por DA\n","      if not esDAimag[i]:\n","           # prepara para mostrar\n","            fig = plt.figure()\n","            fig.suptitle( \"clase: \" + str( CLASES[y[i]] ) )\n","\n","            # muestra la real\n","            ax1 = fig.add_subplot(121)\n","            plot_image( x_in[i] )\n","\n","            # muestra la generada por el modelo\n","            ax2 = fig.add_subplot(122)\n","            plot_image( reconstr_imgs[i] )\n","\n","            plt.tight_layout()\n","            fig = plt.gcf()\n","            cantMostradas = cantMostradas + 1\n","  print(\"\\n\\t Cantidad imágenes mostradas: \", cantMostradas, \"\\n\")\n","\n","# genera toda la interface para evaluar modeo DAE\n","def crearUI_evaluarModeloDAE(clDefecto, ruidoPorDefecto, funcionCambiaSeleccion):\n","  # prepara combo para filtrar por clase\n","  seleccion_CLASES = [\"-\", \"TODOS\"]\n","  seleccion_CLASES.extend( CLASES )\n","  seleccion_CLASES.sort()\n","\n","  # auxiliar para que muestre bien la descripción\n","  style_3D = {'description_width': 'initial'}\n","\n","  combo_clase = widgets.Dropdown(\n","      options = seleccion_CLASES,\n","      value = clDefecto,\n","      description = 'Filtrar por clase:',\n","      style=style_3D,\n","      disabled = False,\n","  )\n","\n","  # prepara para seleccionar grado de ruido\n","  gradoRuidoImagenes = widgets.FloatSlider(\n","          value=ruidoPorDefecto,\n","          min=-1,\n","          max=100,\n","          step=1,\n","          description='Grado ruido para agregar:',\n","          style=style_3D,\n","          disabled=False,\n","          continuous_update=False,\n","          orientation='horizontal',\n","          readout=True,\n","          readout_format='.1f',)\n","\n","\n","  prueba_ui = widgets.GridBox(children=[combo_clase, gradoRuidoImagenes],\n","          layout=Layout(width='100%') \n","        )\n","  out_prueba = widgets.interactive_output(funcionCambiaSeleccion, {'cl':combo_clase, 'r':gradoRuidoImagenes})\n","\n","  return prueba_ui, out_prueba\n","\n","# función para filtrar por clase\n","def cambiaSeleccion_clase_evaluar_imEntrenamiento(cl, r):  \n","  if (cl == \"-\"):\n","    return\n","  # prueba con los datos de entrenamiento\n","  print(\"*** Resultados con datos de Entrenamiento: clase \"+cl)\n","  probarModelo_DAE(x_train, y_train, esDAimag_train, cl, r)\n","\n","# muestra la interface \n","ev_entrenamiento_ui, ev_entrenamiento_out = crearUI_evaluarModeloDAE( \"-\", gradoRuidoImagenes_entrenamiento, cambiaSeleccion_clase_evaluar_imEntrenamiento )\n","display(ev_entrenamiento_ui, ev_entrenamiento_out)\n"],"metadata":{"cellView":"form","id":"_9mJOY5M6ycU"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"_9yxMZe53xvt"},"source":["#@title Evaluar el modelo con las imágenes de prueba\n","\n","# función para filtrar por clase\n","def cambiaSeleccion_clase_evaluar_imPrueba(cl, r):  \n","  if (cl == \"-\"):\n","    return\n","  # prueba con los datos de entrenamiento\n","  print(\"*** Resultados con datos de Prueba: clase \"+cl)\n","  probarModelo_DAE(x_test, y_test, esDAimag_test, cl, r)\n","\n","# muestra la interface \n","ev_prueba_ui, ev_prueba_out = crearUI_evaluarModeloDAE( \"TODOS\", gradoRuidoImagenes_entrenamiento, cambiaSeleccion_clase_evaluar_imPrueba )\n","display(ev_prueba_ui, ev_prueba_out)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FAIHLjzx3xvu"},"source":["\n","# Extraer y usar el sub-modelo Encoder:\n"]},{"cell_type":"code","metadata":{"cellView":"form","id":"0EeME5rO3xvu"},"source":["#@title Generar el sub-modelo Encoder para Clustering\n","## (desde input hasta features)\n","\n","# reutiliza las capas entrenadas del modelo DAE original\n","clust_input_Lay = input_data_Lay  # capa de entrada\n","clust_output_Lay =  features_Lay  # capa de salida\n","\n","# genera el modelo\n","CLUSTmodel = Model(input_data_Lay, features_Lay, name='Encoder/Clustering')\n","\n","print(\"> Modelo Encoder: \")\n","CLUSTmodel.summary()\n","#plot_model(CLUSTmodel, show_layer_names=True, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gb8-7QzAQsDq","cellView":"form"},"source":[" #@title Generar Clustering\n","  # Muestra estadísticas y gráfico de los datos codificados\n","\n","# determina datos a usar\n","usarDatos = 'Datos Entrenamiento' #@param [\"Datos Entrenamiento\", \"Datos de Prueba\"] {allow-input: false}\n","if usarDatos == 'Datos Entrenamiento':\n","  datosUsar = x_train\n","  datosUsar_y = y_train\n","else:\n","  datosUsar = x_test\n","  datosUsar_y = y_test \n","\n","# procesa los datos para recibir el valor codificado de cada una\n","x_encoded = CLUSTmodel.predict(datosUsar)\n","\n","# calcula estadisticas\n","minArClust = np.empty(num_features)\n","minArClust.fill(9999.99)\n","maxArClust = np.empty(num_features)\n","maxArClust.fill(-9999.99)\n","sumArClust = np.zeros(num_features)\n","for val in x_encoded:\n","  for i in range(num_features):\n","      sumArClust[i] = sumArClust[i]+val[i]\n","      if val[i]<minArClust[i]: \n","          minArClust[i] = val[i]\n","      if val[i]>maxArClust[i]: \n","          maxArClust[i] = val[i]\n","print(\"\\n\\n> Estadísticas de Clutering de Datos Originales codificado en \", num_features,\" features: \")\n","print(\"- Mínimos:   \", minArClust)\n","print(\"- Máximos:   \", maxArClust)\n","print(\"- Totales:   \", sumArClust)\n","print(\"- Promedios: \", sumArClust/len(x_encoded))\n","print(\"\\n\\n\")\n","\n","if len(x_encoded)>0 and len(x_encoded[0])>0:\n","  \n","  import ipywidgets as widgets\n","  from ipywidgets import Box, Layout\n","\n","\n","  #colValues = range(len(x_encoded[0]))\n","  colValues = []\n","  for col in range(len(x_encoded[0])):\n","    colValues.append(\"feature_\"+str(col))\n","\n","  # agrega los combos\n","  comboColX = widgets.Dropdown(\n","      options=colValues,\n","      value=colValues[0],\n","      description='Columna X:',\n","      disabled=False,\n","  )\n","  if len(colValues)>1:\n","    valYsel = colValues[1]\n","  else:\n","    valYsel = colValues[0]\n","\n","  comboColY = widgets.Dropdown(\n","      options=colValues,\n","      value=valYsel,\n","      description='Columna Y:',\n","      disabled=False,\n","  )\n","\n","\n","  ui = widgets.HBox([comboColX, comboColY])\n","\n","  import matplotlib.ticker as ticker\n","    \n","  def fmtClases(x, pos):\n","    return CLASES[int(x)]\n","\n","  def cambiaSeleccion(fx, fy):\n","    # llama a la función \n","    # para generar el gráfico con las columnas seleccionadas\n","    # muestra el gráfico codificado \n","    plt.figure(figsize=(16, 10))\n","    x = int(fx.replace(\"feature_\", \"\"))\n","    y = int(fy.replace(\"feature_\", \"\"))\n","    plt.scatter(x_encoded[:,x], x_encoded[:,y], c=datosUsar_y, cmap='jet')\n","    plt.colorbar(format=ticker.FuncFormatter(fmtClases))    \n","    plt.grid(color='grey', which='major', axis='y', linestyle='solid', linewidth=0.3)\n","    plt.grid(color='grey', which='major', axis='x', linestyle='solid', linewidth=0.3)\n","    plt.title(\"Representación de Datos Clusterizados\", fontsize = 20)\n","    plt.show()\n","\n","  out = widgets.interactive_output(cambiaSeleccion, {'fx': comboColX, 'fy': comboColY})\n","  display(ui, out)      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"DzknnEb-Q5ib"},"source":["#@title Función auxiliar para generar gráfico PCA de comparación\n","\n","# función auxiliar para generar un gráfico \n","# con los valores codificados \n","# usando PCA para simplificarlos en 2 ejes\n","def genera_grafico_pca(datos, clases, titulo):\n","    pca = PCA(n_components=2)\n","    principalComponents = pca.fit_transform(datos)\n","    principalDf = pd.DataFrame(data = principalComponents,\n","                columns = ['pca_1', 'pca_2'])\n","    finalDf = pd.concat([principalDf, \n","                        pd.DataFrame(clases, columns = ['target'])], \n","                        axis = 1)\n","\n","    fig = plt.figure(figsize = (15,8))\n","    ax = fig.add_subplot(1,1,1) \n","    ax.set_xlabel('PCA1', fontsize = 15)\n","    ax.set_ylabel('PCA2', fontsize = 15)\n","    ax.set_title(titulo, fontsize = 20)\n","    for target in set(clases):\n","        indicesToKeep = finalDf['target'] == target\n","        ax.scatter(finalDf.loc[indicesToKeep, 'pca_2'],\n","                  finalDf.loc[indicesToKeep, 'pca_1'],\n","                  s = 50)\n","    ax.legend(CLASES[1:])\n","    ax.grid()\n","\n","\n","# muestra el gráfico con originales con PCA (para que tenga 2 dimensiones)\n","generar_grafico_PCA = True #@param{type:\"boolean\"}\n","if generar_grafico_PCA:\n","  genera_grafico_pca(datosUsar, datosUsar_y, \"Representación de Datos Originales con PCA\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Aplicar Algoritmo de Inducción usando como entrada valores de Features/Clusters\n","\n","from sklearn import tree\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo_Inducc(clf, x, y, clases_map, mostrarDetalle=False):\n","\n","    # procesa las imágenes de prueba con el modelo \n","    predClass = clf.predict(x)\n","\n","    # muestra los resultados con las imágenes \n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # prepara salida\n","        clReal = y[i]\n","        clPred = predClass[i]\n","\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","\n","        strTitulo = 'Real: ' + clReal + ' / Modelo(Árbol): ' \n","        strTitulo = strTitulo + clPred \n","        strTitulo = strTitulo + \": \" + (\"ok\" if (clPred==clReal) else \"error!\")\n","\n","        # muestra comparación con la imagen\n","        if mostrarDetalle:\n","          print(strTitulo)\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds))\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión ( real / modelo ): ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm, \n","        index=['r:{:}'.format(x) for x in clases_map], \n","        columns=['m:{:}'.format(x) for x in clases_map]\n","      )\n","    # agrega para poder mostrar la matrix de confusión completa\n","    pd.options.display.max_rows = 100\n","    pd.options.display.max_columns = 100\n","    cmtx.sort_index(axis=0, inplace=True)\n","    cmtx.sort_index(axis=1, inplace=True)    \n","    print(cmtx)\n","    print(\"\\n\")\n","\n","\n","if len(x_encoded)>0 and len(x_encoded[0])>0:\n","    \n","  # parámetros\n","  param_criterio = \"Gini impurity\" #@param [\"Entropy\", \"Error\", \"Gini impurity\"]\n","  if param_criterio == \"Entropy\":\n","    pCriteria = \"entropy\"\n","  elif param_criterio == \"Error\":\n","    pCriteria = \"log_loss\"\n","  #elif param_criterio == \"Gini impurity\":\n","  else:\n","    pCriteria = \"gini\"\n","  param_max_depth = 0 #@param {type:\"number\"}\n","  if param_max_depth < 1: \n","      # menor que 1 es opcional\n","      param_max_depth = None\n","  param_split_strategy = \"Best\" #@param [\"Best\", \"Random\"]\n","  if param_split_strategy== \"Best\":\n","    pSpliter = \"best\"\n","  #elif param_split_strategy == \"Random\":\n","  else:\n","    pSpliter = \"random\"\n","  param_min_samples_split  = 0 #@param {type:\"number\"}\n","  if param_min_samples_split  < 2: \n","      param_min_samples_split  = 2\n","  param_min_samples_leaf  = 1 #@param {type:\"number\"}\n","  if param_min_samples_leaf  < 1: \n","      param_min_samples_leaf  = 1\n","  param_max_leaf_nodes = 0 #@param {type:\"number\"}\n","  if param_max_leaf_nodes < 2: \n","      param_max_leaf_nodes = None\n","\n","  # preparar datos\n","  x_encoded_train = CLUSTmodel.predict(x_train)\n","  y_clases_train = [CLASES[y] for y in y_train]\n","  x_encoded_test = CLUSTmodel.predict(x_test)\n","  y_clases_test = [CLASES[y] for y in y_test]\n","\n","  # genera el árbol y lo muestra\n","  clf = tree.DecisionTreeClassifier(criterion=pCriteria,\n","                                    splitter=pSpliter,\n","                                    max_depth=param_max_depth,\n","                                    min_samples_split=param_min_samples_split,\n","                                    min_samples_leaf=param_min_samples_leaf,\n","                                    max_leaf_nodes=param_max_leaf_nodes)\n","  \n","  clf = clf.fit(x_encoded_train, y_clases_train)\n","  \n","  # muestra las reglas\n","  r = tree.export_text(clf)\n","\n","  print(\"> Reglas:\" )\n","  print(r)\n","\n","  # prueba con los datos de entrenamiento\n","  print(\"\\n*** Resultados con datos de Entrenamiento: \")\n","  probarModelo_Inducc(clf, x_encoded_train, y_clases_train, CLASES, False)\n","\n","  # prueba con los datos de entrenamiento\n","  print(\"\\n*** Resultados con datos de Prueba: \")\n","  probarModelo_Inducc(clf, x_encoded_test, y_clases_test, CLASES, False)\n","\n","\n"],"metadata":{"cellView":"form","id":"iny7uHqs8ikl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cXaMmq5i3xvy"},"source":["\n","# Extraer y usar el sub-modelo Decoder:\n"]},{"cell_type":"code","metadata":{"cellView":"form","id":"SHxXZynj3xvz"},"source":["#@title Generar el sub-modelo Decoder como Generator\n","## (desde features hasta output)\n","\n","# genera una copia del modelo DAE original para evitar romperlo\n","auxiCloneModel = keras.models.model_from_json(DAEmodel.to_json())\n","#auxiCloneModel.summary()\n","\n","# genera la nueva estructura del Generator\n","input_gen = tf.keras.layers.Input(shape=(num_features,), name='input_gen') # nueva capa de entrada\n","auxLay_gen = input_gen\n","for pos in range(len(DAEmodel.layers)):\n","\n","  # obtiene el nombre de la capa actual\n","  auxName = DAEmodel.layers[pos].name  \n","  \n","  # sólo considera las capas luego de features (decoder y output)\n","  # para copiar los pesos del DAE original y actualizar la estructura\n","  if auxName.startswith('dec_') or auxName=='output_data':\n","    auxiCloneModel.layers[pos].set_weights(DAEmodel.layers[pos].get_weights()) \n","    auxLay_gen = auxiCloneModel.layers[pos](auxLay_gen) \n","\n","# crea el nuevo modelo Generator\n","GENmodel = Model(input_gen, auxLay_gen, name = 'Decoder/Generator')\n","\n","print(\"> Modelo Decoder: \")\n","GENmodel.summary()\n","#plot_model(GENmodel, show_layer_names=True, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"u3ToAUhU3xvz"},"source":["#@title Ejecutar el Generator con Features al Azar\n","#  usando valores definidos al azar como datos de entrada\n","cantGenerar = 10 #@param {type:\"integer\"}\n","\n","# genera los datos de entrada\n","# (como la codificación tiene varias posiciones con ceros \n","# se considera que sólo se ponen al azar entre 10% y el 70% de los valores, el resto queda en cero,\n","# --sino se podría hacer con \" np.random.rand(cantImagenGenerar, num_features) \"-- )\n","arX = []\n","minRnd = 1\n","maxRnd = num_features\n","for i in range(cantGenerar):\n","  X = np.zeros(num_features)\n","  for j in range(np.random.randint(low=minRnd, high=maxRnd)):\n","      pos = np.random.randint(low=0, high=num_features-1)\n","      # si están definidas las estadisticas las usa, sino no\n","      if (minArClust is None or  maxArClust is None):\n","          X[pos] = np.random.uniform()    \n","      else:\n","          X[pos] = np.random.uniform(minArClust[pos], maxArClust[pos])              \n","      \n","  arX.append( X )\n","\n","\n","# ejecuta el modelo Generator\n","imagOut = GENmodel.predict( np.array(arX).reshape((len(arX), num_features)) )  \n"," \n","# muestra las imágenes generadas\n","print(\"\\n> Resultados: \")\n","for i in range(len(arX)):\n","\n","    fig = plt.figure()\n","\n","    # muestra los datos\n","    ax1 = fig.add_subplot(121)\n","    datosMostrar = arX[i].reshape(num_features, 1) \n","    ax1.table(cellText=datosMostrar, loc='center')   \n","    ax1.get_xaxis().set_visible(False)\n","    ax1.get_yaxis().set_visible(False)  \n","\n","    #  muestra reconstrucción\n","    ax2 = fig.add_subplot(122)\n","    plot_image(imagOut[i])  \n","\n","    plt.tight_layout()\n","    fig = plt.gcf()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Ejecuta el Generator con Features Personalizados\n","\n","if colValues is not None and len(colValues) > 0:\n","  fValueList = []\n","  for i in range(len(colValues)):\n","\n","    if (minArClust is None or  maxArClust is None):\n","        fsMin = -100.0\n","        fsVal = 0.0\n","        fsMax = 100.0\n","    else:\n","        fsMin = minArClust[i] - 25\n","        fsVal = ( maxArClust[i] - minArClust[i] ) / 2.0\n","        fsMax = maxArClust[i] + 25\n","\n","    fValue = widgets.FloatSlider(\n","        value=fsVal,\n","        min=fsMin,\n","        max=fsMax,\n","        step=0.1,\n","        description=colValues[i] + ':',\n","        disabled=False,\n","        continuous_update=False,\n","        orientation='horizontal',\n","        readout=True,\n","        readout_format='.1f',\n","      )\n","    fValueList.append(fValue)\n","    \n","  button = widgets.Button(description=\"Generar\")\n","\n","  def on_button_clicked(b):\n","      with out:\n","          X = []\n","          for i in range(len(fValueList)):\n","            X.append( fValueList[i].value )\n","          X = np.array(X)\n","\n","          # ejecuta el modelo Generator\n","          arX= [X]\n","          imagOut = GENmodel.predict( np.array(arX).reshape((len(arX), num_features)), verbose=0 )  \n","          \n","          fig = plt.figure()\n","\n","          # muestra los datos\n","          ax1 = fig.add_subplot(121)\n","          datosMostrar = X.reshape(num_features, 1) \n","          ax1.table(cellText=datosMostrar, loc='center')   \n","          ax1.get_xaxis().set_visible(False)\n","          ax1.get_yaxis().set_visible(False)  \n","\n","          #  muestra reconstrucción\n","          ax2 = fig.add_subplot(122)\n","          plot_image(imagOut[0])  \n","\n","          plt.tight_layout()\n","          fig = plt.gcf()\n","          \n","          print(\"\\n\")  \n","\n","\n","  button.on_click(on_button_clicked)\n","  \n","  ui = widgets.VBox(fValueList + [button])\n","  out = widgets.Output()\n","  display(ui, out)\n","  print(\"\\n\")\n","  \n"],"metadata":{"cellView":"form","id":"mXk0CqIUBykv"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1gEcMqfeYOJnjxHE-AACF0t8SJTXIsif6","timestamp":1580735169391}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}