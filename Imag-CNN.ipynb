{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2OvlxnFIsNyT"},"source":["# Demo Convolutional Neural Network (CNN o ConvNet) para procesar imágenes e identificar la clase que corresponde"]},{"cell_type":"code","metadata":{"id":"gcVLfyLKsaCj","cellView":"form"},"source":["#@title Librerías a usar\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Model\n","from keras.utils import plot_model\n","\n","import random\n","\n","import keras.backend as K\n","from tensorflow.keras.preprocessing import image\n","import cv2\n","import copy \n","\n","from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","from PIL import Image\n","\n","from  sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"Librerías cargadas\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysaIl300nDud","cellView":"form"},"source":["#@title Acceder al Drive\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demoML/imagenes/NUMEROS' #@param {type:\"string\"}\n","path_entrenamiento = '/train'  #@param {type:\"string\"}\n","path_prueba = '/test'  #@param {type:\"string\"}\n","\n","imagPath_train = path + path_entrenamiento\n","imagPath_test = path + path_prueba"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYz8mV4SnJ4O","cellView":"form"},"source":["#@title Cargar imágenes\n","\n","#@markdown ### Parámetros para imágenes:\n","imagen_ancho =  32#@param {type:\"integer\"}\n","imagen_largo =  32#@param {type:\"integer\"}\n","imagen_color = True #@param {type:\"boolean\"}\n","incluir_imagenes_generadas_con_data_augmentation = False #@param {type:\"boolean\"}\n","\n","# indica si se usan las imágenes generadas por data augmentation\n","usarDA = incluir_imagenes_generadas_con_data_augmentation\n","\n","# tamaño de las imágenes\n","if imagen_ancho<=10:\n","  imagen_largo = 10\n","if imagen_largo<=10:\n","  imagen_largo = 10\n","IMAGE_SHAPE = (imagen_ancho, imagen_largo, (3 if imagen_color else 1))\n","\n","# define función para cargar las imágenes\n","def cargarImagenes(imagPath):\n","  classes_ori = [] \n","  images_ori = []\n","  esDA_ori = []\n","\n","  all_dirs = os.listdir( imagPath )\n","  for each_dir in all_dirs:\n","\n","      auxiPath = imagPath + '/' + each_dir \n","      imagFN  = os.listdir( auxiPath )\n","      for each_imagFN in imagFN:\n","\n","            esImagDA = (each_imagFN[:2] == 'da')\n","            \n","            if usarDA or (not esImagDA): \n","                \n","                # abre la imagen\n","                imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","                \n","                # ajusta el tamaño\n","                if IMAGE_SHAPE[2]==1:              \n","                  tipoImage = 'L'\n","                else:                \n","                  tipoImage = 'RGB'\n","                imag = imag.convert(tipoImage)\n","                imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.ANTIALIAS)          \n","                \n","                # transforma a un vector de nros\n","                arImag = np.array(imag)\n","                \n","                # agrega a los vectores\n","                classes_ori.append( each_dir )\n","                images_ori.append( arImag )\n","                esDA_ori.append( esImagDA )\n","\n","  return classes_ori, images_ori, esDA_ori, tipoImage\n","\n","# carga las imagenes de entrenamiento\n","classes_train, images_train, esDAimag_train, tipoImage_train = cargarImagenes(imagPath_train)\n","print(\"> Para Entrenamiento: \")\n","print(\"- Clases cargadas: \", len(np.unique(classes_train)))\n","print(\"- Imágenes cargadas: \", len(classes_train))\n","\n","if len(classes_train)>0:\n","  print(\"- Ejemplo \", classes_train[0], \" \", images_train[0].shape, \": \")\n","  display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","# carga las imagenes de prueba\n","classes_test, images_test, esDAimag_test, tipoImage_test = cargarImagenes(imagPath_test)\n","print(\"\\n\\n> Para Prueba: \")\n","print(\"- Clases cargadas: \", len(np.unique(classes_test)))\n","print(\"- Imágenes cargadas: \", len(images_test))\n","\n","if len(classes_test)>0:\n","  print(\"- Ejemplo \", classes_test[0], \" \", images_test[0].shape, \": \")\n","  display( Image.fromarray(images_test[0], tipoImage_test) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Ajustar imágenes para reducir el fondo (opcional)\n","\n","accion_realizar = \"-\" #@param [\"-\", \"Blur Fondo\", \"Eliminar Fondo y pasar a Negro\", \"Eliminar Fondo y pasar a Blanco\"]\n","\n","def cambiarColorNegro(img, nuevoColor=[255, 255, 255]):\n","    black_pixels = np.where(\n","        (img[:, :, 0] == 0) & \n","        (img[:, :, 1] == 0) & \n","        (img[:, :, 2] == 0)\n","    )\n","    img[black_pixels] = nuevoColor\n","    return img\n","\n","def blurFondoImagen(im):\n","  # Convert to the HSV color space\n","  hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n","  # aplica filtro Otsu threshold para obtener máscara\n","  ret, maskthresh = cv2.threshold(hsv[:,:,0], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","  # Genera la máscara negada\n","  maskthresh = 255 - maskthresh\n","  # We need a to copy the mask 3 times to fit the frames\n","  maskthresh = np.repeat(maskthresh[:, :, np.newaxis], 3, axis=2)\n","  #  Create a blurred frame using Gaussian blur\n","  blurred_frame = cv2.GaussianBlur(im, (25, 25), 0)\n","  # Combine the original with the blurred frame based on mask\n","  return np.where(maskthresh == (255, 255, 255), im, blurred_frame)\n","\n","def reducirFondoImagen(im):\n","  # aplica filtro Hue\n","  imhsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n","  # aplica filtro Otsu threshold para obtener máscara\n","  ret, maskthresh = cv2.threshold(imhsv[:,:,0], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","  # Genera la máscara negada\n","  maskthresh = 255 - maskthresh\n","  # aplica la máscara sobre la imagen\n","  imgfin = cv2.bitwise_and(im, im, mask = maskthresh)\n","  return imgfin\n","\n","def procesarImgRedFondo(imgList):\n","  nList = []\n","  for im in imgList:\n","    if accion_realizar == \"Blur Fondo\":\n","      # hacer blur del fondo\n","      imn = blurFondoImagen(im)\n","    elif accion_realizar == \"Eliminar Fondo y pasar a Negro\":\n","      # eliminar fondo y dejar negro\n","      imn = reducirFondoImagen(im)\n","    elif accion_realizar == \"Eliminar Fondo y pasar a Blanco\":\n","        # cambia fondo negro a casi negro \n","        # (para que no cambié después) \n","        imn = cambiarColorNegro(im, [0, 0, 1])\n","        # eliminar fondo\n","        imn = reducirFondoImagen(imn)\n","        # cambiar fondo a blanco\n","        imn = cambiarColorNegro(imn, [255, 255, 255])\n","    else:\n","      print(\"Acción no definida!\")\n","      break\n","    nList.append( imn )\n","  return nList\n","\n","\n","# degermina si hace algo o no\n","if accion_realizar != \"-\":\n","  # aplica filtros para intentar reducir el fondo de la imagen\n","  # cambiando las imágenes disponibles\n","  images_train = procesarImgRedFondo(images_train)\n","  images_test = procesarImgRedFondo(images_test)\n","\n","  if len(classes_train)>0:\n","    print(\"- Ejemplo Entrenamiento con fondo reducido \", classes_train[0], \" \", images_train[0].shape, \": \")\n","    display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","  if len(classes_test)>0:\n","    print(\"- Ejemplo Prueba con fondo reducido \", classes_test[0], \" \", images_test[0].shape, \": \")\n","    display( Image.fromarray(images_test[0], tipoImage_test) )"],"metadata":{"cellView":"form","id":"g-Z21zWxFG_Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPPvnkjTnTQN"},"source":["#@title Preparar imágenes para usar en el modelo\n","\n","# define función auxiliar para mostrar imágenes preparadas\n","def plot_image(imag):\n","  if IMAGE_SHAPE[2]==1:\n","    plt.imshow((imag).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8)) ## *255\n","    plt.gray()\n","  else:\n","    plt.imshow((imag).reshape(IMAGE_SHAPE).astype(np.uint8)) ## *255\n","  plt.axis(\"off\")  \n","\n","# define función auxiliar para preparar la lista de imágenes a procesar\n","def prepare_imageList(imagList):    \n","  auxiAr = np.array(imagList) ##.astype('float32') / 255.\n","  auxiAr = auxiAr.reshape((len(auxiAr), IMAGE_SHAPE[0], IMAGE_SHAPE[1], IMAGE_SHAPE[2]))  \n","  return auxiAr\n","  \n","# define función auxiliar para preparar lista de clases \n","def prepare_clasesList(classesList, dictMapeo=None):\n","  if dictMapeo==None:\n","    # genera diccionario de mapeo\n","    auxDict = list(set(classesList))\n","    dictMapeo = dict( zip( auxDict, range(len(auxDict)) ) )\n","  # realiza el mapeo\n","  y = []\n","  for cl in classesList:\n","      y.append( dictMapeo[cl] )\n","  # convierte valores numéricos a columnas de vakores binarios (i.e. one hot encoded)\n","  dummy_y = np_utils.to_categorical(y)\n","  # devuelve\n","  return np.array(y), np.array(dummy_y), dictMapeo\n","\n","# define vector auxiliar de datos de entrada para usar en el entrenamiento y prueba\n","x_train = prepare_imageList(images_train)\n","x_test = prepare_imageList(images_test)\n","\n","# define vector auxiliar de datos de salida para usar en el entrenamiento y prueba\n","# también usa esta información para determinar la cantida de neuronas de salida\n","y_train, y_trainEnc, dictMapeo = prepare_clasesList(classes_train)\n","y_test, y_testEnc,_ = prepare_clasesList(classes_test, dictMapeo)\n","\n","# genera diccionario auxiliar para poder convertir de ID de clase a nombre de clase\n","clases_map = [ x for x,y in dictMapeo.items() ]\n","\n","print(\"> Para Entrenamiento: \")\n","print(\" - x_train (cant ejemplos, datos entrada): \", x_train.shape)\n","print(\" - y_trainEnc (cant): \", len(y_trainEnc))\n","print(\" - y_train (cant): \", len(y_train))\n","print(\"\\n\\n> Para Prueba: \")\n","print(\" - x_test (cant ejemplos, datos entrada): \", x_test.shape)\n","print(\" - y_testEnc (cant): \", len(y_testEnc))\n","print(\" - y_test (cant): \", len(y_test))\n","print(\"\\n\\n> Para Ambos: \")\n","print(\" - dictMapeo: \", dictMapeo)\n","print(\" - clases_map: \", clases_map)\n","if len(y_train)>0:\n","  print(\"\\n - Imagen reconstruida de \", clases_map[y_train[0]],  \"(\", y_train[0], \" / \", y_trainEnc[0], \")\")\n","  plot_image(x_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Establecer capas de Image Augmentation (opcional)\n","\n","aplicar_da_preProcesamiento = False #@param {type:\"boolean\"}\n","\n","#@markdown Nota: estas capas se agregan al modelo para generar automaticamente data augmentation sólo durante el entrenamiento.\n","da_preProcesamiento_RandomFlip_Horizontal = False #@param {type:\"boolean\"}\n","da_preProcesamiento_RandomFlip_Vertical = False #@param {type:\"boolean\"}\n","da_preProcesamiento_RandomTranslation_Horizontal_factor = 0.2 #@param {type:\"number\"}\n","da_preProcesamiento_RandomTranslation_Vertical_factor = 0.2 #@param {type:\"number\"}\n","da_preProcesamiento_RandomRotation_factor = 0.1 #@param {type:\"number\"}\n","da_preProcesamiento_RandomZoom_factor = 0.4 #@param {type:\"number\"}\n","da_preProcesamiento_RandomContrast_factor = 0.5 #@param {type:\"number\"}\n","da_preProcesamiento_RandomBrightness_factor = 0.5 #@param {type:\"number\"}\n","\n","daLayers_modelo = []\n","\n","# capas de data augmentation (solo para training)\n","if aplicar_da_preProcesamiento:\n","    \n","  if da_preProcesamiento_RandomFlip_Horizontal or da_preProcesamiento_RandomFlip_Vertical:\n","    if da_preProcesamiento_RandomFlip_Horizontal:\n","      modeDAFlip = \"horizontal\"\n","      if da_preProcesamiento_RandomFlip_Vertical:\n","        modeDAFlip = modeDAFlip + \"_and_vertical\"\n","    else:\n","      modeDAFlip = \"vertical\"\n","    daLayers_modelo.append( tf.keras.layers.RandomFlip(mode=modeDAFlip, seed=None, name=\"da_rndFlip_\"+modeDAFlip) )\n","\n","  if (da_preProcesamiento_RandomTranslation_Horizontal_factor != 0.0) or (da_preProcesamiento_RandomTranslation_Vertical_factor != 0.0):\n","    daLayers_modelo.append( tf.keras.layers.RandomTranslation(height_factor=da_preProcesamiento_RandomTranslation_Vertical_factor, width_factor=da_preProcesamiento_RandomTranslation_Horizontal_factor, name=\"da_rndTranslation\") )\n","\n","  if da_preProcesamiento_RandomRotation_factor != 0.0:\n","      daLayers_modelo.append( tf.keras.layers.RandomRotation(factor=da_preProcesamiento_RandomRotation_factor, name=\"da_rndRotation\") )\n","\n","  if da_preProcesamiento_RandomZoom_factor != 0.0:\n","    daLayers_modelo.append( tf.keras.layers.RandomZoom(height_factor=da_preProcesamiento_RandomZoom_factor, name=\"da_rndZoom\") )\n","\n","  if da_preProcesamiento_RandomContrast_factor != 0.0:\n","    daLayers_modelo.append( tf.keras.layers.RandomContrast(factor=da_preProcesamiento_RandomContrast_factor, name=\"da_rndContrast\") )\n","\n","  if da_preProcesamiento_RandomBrightness_factor != 0.0:\n","    daLayers_modelo.append( tf.keras.layers.RandomBrightness(factor=da_preProcesamiento_RandomBrightness_factor, name=\"da_rndBrightness\") )\n","\n","# Visualize images and augmentations\n","cantCapasDA = len(daLayers_modelo) + 2\n","if cantCapasDA <= 2:\n","  print(\"No se aplican capas de Image Augmentation.\")\n","else:\n","  print(\"Ejemplo de posibles aplicaciones:\")\n","  fig, ax = plt.subplots(cantCapasDA, 5, figsize=(15,cantCapasDA*3))\n","\n","  j = 0\n","  for j in range(5):\n","    \n","    # toma al azar las imágenes a mostrar\n","    posIm = random.randint(1, len(x_train))\n","    im = x_train[posIm-1]\n","  \n","    # muestra imagen original\n","    ax[0][j].imshow((im.astype(\"uint8\")))\n","    if j == 0:\n","      ax[0][j].set_title(\"original\")\n","    ax[0][j].axis('off')\n","\n","    # muestra imagen con aplicación de capa\n","    i = 1\n","    for da_lay in daLayers_modelo:\n","            ax[i][j].imshow(da_lay(im).numpy().astype(\"uint8\"))\n","            if j == 0:\n","              ax[i][j].set_title(\"sólo capa \" + da_lay.name)\n","            ax[i][j].axis('off')\n","            i = i + 1\n","\n","    # aplica todas las capas\n","    for da_lay in daLayers_modelo:\n","        im = da_lay(im)\n","\n","    ax[i][j].imshow(im.numpy().astype(\"uint8\"))\n","    if j == 0:      \n","      ax[i][j].set_title(\"TODAS LAS CAPAS\")\n","    ax[i][j].axis('off')\n","    \n","    j = j + 1\n","\n","  plt.show()   "],"metadata":{"cellView":"form","id":"FMhcZJ8cF4kL"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_ehBHOatp4H"},"source":["#@title Establecer modelo\n","\n","#@markdown ### Parámetros de las capas ConvNet:\n","convNet_tamaño_kernel_NxN =  2 #@param {type:\"integer\"}\n","convNet_tamaño_pooling_MxM = 2 #@param {type:\"integer\"}\n","convNet_cantidad_capas_ocultas =  3#@param {type:\"integer\"}\n","convNet_hacer_Flatten_con_GlobalAveragePooling2D  = False #@param {type:\"boolean\"}\n","\n","#@markdown ### Parámetros de las capas Lineales:\n","lineal_cant_neuronas_capas_ocultas = '64, D, 32' #@param {type:\"string\"}\n","#@markdown (Nota: se puede indicar Cantidad de neuronas, D para DropOut, BN para BatchNormalization)\n","lineal_porc_capa_DropOut = 0.4 #@param {type:\"number\"}\n","\n","#@markdown ### Parámetros de la capa de Salida:\n","red_tipo_capa_salida = 'softmax-MultiClase' #@param [\"lineal-Numero\", \"softmax-MultiClase\"]\n","\n","#@markdown ### Parámetros del Optimizador:\n","opt_tipo = \"Adam\" #@param [\"Gradiente Decreciente\", \"Adam\", \"Adadelta\", \"Adagrad\", \"Adamax\", \"Nadam\", \"FTRL\"]\n","opt_learning_rate = 0.001 #@param {type: \"number\"}\n","\n","\n","## aplicación de los parámetros elegidos\n","\n","# tamaño de los kernels y pooling (para simplificar son todas iguales)\n","if convNet_tamaño_kernel_NxN<1:\n","  convNet_tamaño_kernel_NxN = 1\n","cnn_kernel_shape = (convNet_tamaño_kernel_NxN, convNet_tamaño_kernel_NxN)\n","if convNet_tamaño_pooling_MxM<1:\n","  convNet_tamaño_pooling_MxM=1\n","cnn_pooling_shape = (convNet_tamaño_pooling_MxM, convNet_tamaño_pooling_MxM)\n","\n","# indica la configuración para la parte Encoder \n","#   (cada elemento de las listas son la configuración de las capas Conv)\n","if convNet_cantidad_capas_ocultas<1:\n","  convNet_cantidad_capas_ocultas = 1\n","cnn_filters = []\n","for i in range(convNet_cantidad_capas_ocultas, 0, -1):\n","  cnn_filters.append( 2**(i+2) )\n","last_conv_layer_name = None\n","last_conv_layer_shape = None\n","\n","# chequea configuración de drop out\n","if lineal_porc_capa_DropOut <= 0:\n","  lineal_porc_capa_DropOut = 0.10\n","elif lineal_porc_capa_DropOut > 0.9:\n","    lineal_porc_capa_DropOut = 0.9\n","  \n","# cantidad de neuronas ocultas \n","hidden_layers = []\n","for val in lineal_cant_neuronas_capas_ocultas.split(','):\n","  val = val.strip()\n","  if val == \"D\":\n","    hidden_layers.append( \"DropOut\" )  \n","  elif val == \"BN\":\n","    hidden_layers.append( \"BatchNormalization\" )  \n","  elif val.isnumeric():\n","    hidden_layers.append( val )\n","  else:\n","    print(\"Capa \", val, \"descartada!\")\n","\n","\n","# define si el tipo de capa de salida es softmax( True )  o lineal ( False )\n","# esto implica también cambiar cómo se codifican los valores de las clases a usar\n","tipo_output_softMax = (red_tipo_capa_salida[:7] == 'softmax')\n","\n","# define la arquitectura de capas de la CNN\n","# teniendo en cuenta la definición dada anteriomente\n","input_img_Lay =  tf.keras.layers.Input(shape=IMAGE_SHAPE, name='input_img') # capa de entrada\n","eachLay = input_img_Lay\n","\n","# agrega capas de data augmentation si se usan\n","if len(daLayers_modelo)>0:\n","  for da_lay in daLayers_modelo:\n","    eachLay = da_lay(eachLay)\n","\n","# agrega capa para ajuste de imágenes\n","eachLay = tf.keras.layers.Rescaling(1./255, name='slng_1/255')(eachLay)\n","\n","auxName = 'conv_'\n","for i in range(len(cnn_filters)):  \n","\n","    # define el nombre de la capa oculta\n","    auxlayerName = 'conv_'+str(i+1)\n","\n","    # agrega las capas ocultas de tipo Conv2D + MaxPooling \n","    eachLay =  tf.keras.layers.Conv2D(cnn_filters[i], cnn_kernel_shape, activation='relu', padding='same', name='c_'+auxlayerName)(eachLay) \n","    # determina nombre y shape de la capa conv2D\n","    last_conv_layer_name = 'c_'+auxlayerName\n","    last_conv_layer_shape = (eachLay.shape[1], eachLay.shape[2])\n","    ##print(last_conv_layer_name, last_conv_layer_shape, eachLay.shape)\n","    eachLay =  tf.keras.layers.MaxPooling2D(cnn_pooling_shape, padding='same', name='p_'+auxlayerName)(eachLay)\n","\n","#  agrega capa Flatten \n","if convNet_hacer_Flatten_con_GlobalAveragePooling2D:\n","  eachLay = tf.keras.layers.GlobalAveragePooling2D(name='flat_GAP')(eachLay)\n","else:\n","  eachLay = tf.keras.layers.Flatten(name='flat')(eachLay)\n","\n","# agrega capas lineales\n","auxName = 'lineal_'\n","auxId = 1 \n","for val_hid in hidden_layers:  \n","\n","  if val_hid == \"DropOut\":\n","    auxlayerName = \"d_\"+str(auxId)\n","    auxId = auxId + 1\n","    eachLay =  tf.keras.layers.Dropout(lineal_porc_capa_DropOut,name=auxlayerName)(eachLay)\n","  elif val_hid == \"BatchNormalization\":\n","    auxlayerName = \"bn_\"+str(auxId)\n","    auxId = auxId + 1\n","    eachLay =  tf.keras.layers.BatchNormalization(name=auxlayerName)(eachLay)\n","  elif val_hid.isnumeric():\n","    # agrega la capa oculta\n","    auxlayerName = auxName+str(auxId)\n","    auxId = auxId + 1\n","    eachLay =  tf.keras.layers.Dense(int(val_hid), name=auxlayerName)(eachLay) # capas ocultas\n","\n","# agrega capa de salida\n","if tipo_output_softMax:\n","    # se genera una capa softmax\n","    output_img_Lay = tf.keras.layers.Dense(units = len(dictMapeo), activation='softmax', name='output')(eachLay) # capa de salida\n","else:\n","    # se genera una capa lineal con una salida numérica\n","    output_img_Lay = tf.keras.layers.Dense(1, activation=None, name='output')(eachLay) # capa de salida\n","\n","if opt_tipo == \"Gradiente Decreciente\":\n","  opt = keras.optimizers.SGD(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adam\":\n","  opt = keras.optimizers.Adam(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adadelta\":\n","  opt = keras.optimizers.Adadelta(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adagrad\":\n","  opt = keras.optimizers.Adagrad(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adamax\":\n","  opt = keras.optimizers.Adamax(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Nadam\":\n","  opt = keras.optimizers.Nadam(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"FTRL\":\n","  opt = keras.optimizers.Ftrl(learning_rate=opt_learning_rate)\n","else:\n","  opt = keras.optimizers.Adam()\n","\n","# genera el modelo ConvNet\n","model = Model(input_img_Lay, output_img_Lay, name='ConvNet')\n","if tipo_output_softMax:\n","    # utiliza un loss de multiple clases\n","    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","else:\n","    # utiliza un loss de valor numérico\n","    model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n","\n","print(\"Modelo creado con \", len(model.layers), \" capas:\")\n","model.summary()\n","print(\"\\n\")\n","plot_model(model, show_layer_names=True, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"21pQvmtCtn-T"},"source":["#@title Entrenar\n","\n","cant_epocas_entrenamiento =  100#@param {type:\"integer\"}\n","\n","activar_corte_por_estabilidad_error_val = False #@param {type:\"boolean\"}\n","\n","\n","# cantidad de épocas del entrenamiento\n","cantEpocas = (1 if cant_epocas_entrenamiento<1 else cant_epocas_entrenamiento)\n","\n","\n","# separa al azar usando muestreo al azar del 10%\n","# para tomar algunos como datos de validación\n","x_t, x_v, y_t, y_v = train_test_split(x_train, \n","                                       (y_trainEnc if tipo_output_softMax else y_train), \n","                                       test_size=0.05)\n","\n","print(\"\\n> De los \", len(x_train), \"ejemplos de entrenamiento: \")\n","print(\"            se usan \", len(x_t), \"ejemplos para entrenar \")\n","print(\"            y \", len(x_v), \"ejemplos para validar.\")\n","\n","print(\"\\n\\n>Comienza el Entrenamiento:\")\n","\n","\n","if activar_corte_por_estabilidad_error_val:\n","  # se agrega un callBack para que corte \n","  # si el error de validación no sigue bajando\n","  # y devuelva los mejores pesos obtenidos\n","  early_stopping_monitor = keras.callbacks.EarlyStopping(\n","      monitor='val_loss',\n","      min_delta=0.01,\n","      patience=20,\n","      verbose=0,\n","      mode='min',\n","      baseline=None,\n","      restore_best_weights=True\n","  )\n","  callbacksEntr = [early_stopping_monitor]\n","else:\n","  early_stopping_monitor = None\n","  callbacksEntr = []\n","\n","# lleva a cabo el entrenamiento\n","history = model.fit(x_t, y_t,\n","          epochs = cantEpocas, \n","          validation_data=(x_v, y_v,),\n","          callbacks=callbacksEntr ) \n","\n","print(\"\\n>Entrenamiento Finalizado.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxcR9WBKx4XA","cellView":"form"},"source":["#@title Mostrar Gráficos del Entrenamiento\n","plt.figure(figsize=(15,8)) \n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Gráfico del Error del Entrenamiento')\n","plt.ylabel('')\n","plt.xlabel('epoch')\n","plt.legend(['entrenamiento', 'validación'], loc='upper left')\n","plt.show()\n","\n","plt.figure(figsize=(15,8)) \n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Gráfico de la Exactitud del Entrenamiento')\n","plt.ylabel('')\n","plt.xlabel('epoch')\n","plt.legend(['entrenamiento', 'validación'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzmLDXuUHkdf","cellView":"form"},"source":["#@title Probar red entrenada con datos de entrenamiento\n","mostrar_detalle_imagenes_entrenamiento = False #@param {type:\"boolean\"}\n","\n","mostrar_HeatMap_de_GradCAM = False #@param {type:\"boolean\"}\n","  # explicación y fuente de GradCAM en:\n","  #   https://medium.com/analytics-vidhya/visualizing-activation-heatmaps-using-tensorflow-5bdba018f759\n","\n","def prepareGradCAM(model, last_conv_layer_name):\n","  # genera sub-modelo desde capa de entrada a última capa convultional\n","  last_conv_layer = model.get_layer(last_conv_layer_name)\n","  subModel = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])                   \n","  return subModel\n","\n","def aplicarGradCAM(subModel, last_conv_layer_shape, imgOrig, intensity=0.5, res=250):\n","  # prepara la imagen a procesar\n","  img = copy.deepcopy(imgOrig)\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)  \n","  # genera el heatmap\n","  with tf.GradientTape() as tape:\n","    model_out, last_conv_layer = subModel(x)\n","    class_out = model_out[:, np.argmax(model_out[0])]\n","    grads = tape.gradient(class_out, last_conv_layer)\n","    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n","  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n","  heatmap = np.maximum(heatmap, 0)\n","  heatmap /= np.max(heatmap)\n","  heatmap = heatmap.reshape(last_conv_layer_shape) # (8, 8))\n","  # aplica el heatmap\n","  imgHM = copy.deepcopy(imgOrig)\n","  heatmap = cv2.resize(heatmap, (imgHM.shape[1], imgHM.shape[0]))\n","  heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n","  imgHM = heatmap * intensity + imgHM\n","  # devuelve imagen con HeatMap\n","  return imgHM\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo(x, y, esDAimag, clases_map, mostrarImagenes=False, mostrarGradCAM=False):\n","\n","    if mostrarGradCAM:\n","      # genera submodelo\n","      subModel = prepareGradCAM(model, last_conv_layer_name)\n","      # si muestra GradCAM también muestra imagen original\n","      mostrarImagenes = True\n","\n","    # procesa las imágenes de prueba con el modelo \n","    predClass = model.predict(x, verbose=0)\n","\n","    if mostrarImagenes:\n","      print(\"\\n>Resultados: \")\n","\n","    # muestra los resultados con las imágenes \n","    umbralClas = 0.5\n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # asigna el nombre de la clase real\n","        clReal = clases_map[ y[i] ] \n","\n","        # determina la clase predecida\n","        if tipo_output_softMax:\n","            ## determina clase predecida de acuerdo a la que tiene mayor valor\n","            idclPred = int( np.argmax(predClass[i], axis=0) )\n","            idclPredRnd = idclPred\n","        else:\n","            ## determina clase predecida de acuerdo al umbral de clasificación\n","            idclPred = predClass[i][0]       \n","            idclPredRnd = int(idclPred)\n","            if (idclPred - idclPredRnd)>0.5 and (idclPredRnd+1)<len(clases_map):\n","                    idclPredRnd = idclPredRnd + 1\n","\n","        # asigna el nombre de la clase predecida\n","        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n","            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA!\"\n","        else:      \n","            clPred = clases_map[ idclPredRnd ]\n","\n","        # agrega a vevtores auxiliares\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","\n","        if mostrarImagenes:\n","\n","          # sólo muestra las imágenes no generadas por DA\n","          strTitulo = 'Real: ' + clReal + ' / RNA: ' \n","          strTitulo = strTitulo + clPred + ' (' + str( idclPred ) +')'    \n","\n","          # muestra comparación con la imagen\n","          fig = plt.figure()\n","          fig.suptitle( strTitulo )\n","          ax1 = fig.add_subplot(121)\n","          plot_image( x[i] )\n","          # muestra resultado aplicar GRADCAM\n","          if mostrarGradCAM:            \n","            imgGradCAM = aplicarGradCAM(subModel, last_conv_layer_shape, x[i]) \n","            ax1 = fig.add_subplot(122)\n","            plot_image(  imgGradCAM)  \n","          plt.tight_layout()\n","          fig = plt.gcf()\n","          plt.show()\n","          plt.close(fig)          \n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds))\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión ( real / modelo ): ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm, \n","        index=['r:{:}'.format(x) for x in clases_map], \n","        columns=['m:{:}'.format(x) for x in clases_map]\n","      )\n","    cmtx.sort_index(axis=0, inplace=True)\n","    cmtx.sort_index(axis=1, inplace=True)\n","    print(cmtx)\n","    print(\"\\n\")\n","\n","# prueba con los datos de prueba\n","print(\"*** Resultados con datos de Entrenamiento: \")\n","probarModelo(x_train, y_train, esDAimag_train, clases_map, mostrar_detalle_imagenes_entrenamiento, mostrar_HeatMap_de_GradCAM)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yh-6p2xDtrUU"},"source":["7) Evaluar el modelo de la RNA entrenado usando las imágenes de prueba:"]},{"cell_type":"code","metadata":{"id":"A15K-9TRtq7U","cellView":"form"},"source":["#@title Probar red entrenada con datos de prueba\n","mostrar_detalle_imagenes_prueba = False #@param {type:\"boolean\"}\n","mostrar_HeatMap_de_GradCAM_prueba = False #@param {type:\"boolean\"}\n","\n"," # evalua al modelo entrenado\n","resEval = model.evaluate(x_test, (y_testEnc if tipo_output_softMax else y_test),)\n","print(\"\\n>Evaluación del Modelo: \")\n","print(\"    - Error: \", resEval[0])\n","print(\"    - Exactitud: \", resEval[1]*100)\n","print(\"\\n\")\n","\n","# prueba con los datos de entrenamiento\n","print(\"\\n\\n*** Resultados con datos de Prueba: \")\n","probarModelo(x_test, y_test, esDAimag_test, clases_map, mostrar_detalle_imagenes_prueba, mostrar_HeatMap_de_GradCAM_prueba)"],"execution_count":null,"outputs":[]}]}