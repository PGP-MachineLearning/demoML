{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2OvlxnFIsNyT"},"source":["# Demo RNA  usando Auto-Keras para procesar imágenes e identificar la clase que corresponde\n","Fuente:https://autokeras.com/\n","\n","( *No se usa GPU porque tira error de memoria * )"]},{"cell_type":"code","source":["#@title Instalar Auto-Keras \n","#!pip install git+https://github.com/keras-team/keras-tuner.git\n","!pip install keras-tuner --upgrade\n","!pip install autokeras\n"],"metadata":{"cellView":"form","id":"YyiSRke3gjqM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674215250444,"user_tz":180,"elapsed":15789,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"5e7f304d-a233-461b-daca-f311a6ed62a2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-tuner\n","  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.9.1)\n","Collecting kt-legacy\n","  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (21.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (57.4.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras-tuner) (3.0.9)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (3.19.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.38.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (2.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.51.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (5.2.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (6.0.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.2)\n","Installing collected packages: kt-legacy, jedi, keras-tuner\n","Successfully installed jedi-0.18.2 keras-tuner-1.1.3 kt-legacy-1.0.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting autokeras\n","  Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.4/162.4 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from autokeras) (1.3.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from autokeras) (21.3)\n","Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from autokeras) (2.9.2)\n","Requirement already satisfied: keras-tuner>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from autokeras) (1.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.25.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.21.6)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (7.9.0)\n","Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.0.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.3.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.51.1)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (15.0.6.1)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.12)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.19.6)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.29.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->autokeras) (3.0.9)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2.8.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.38.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (2.16.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.0.10)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.18.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.7.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (5.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (6.0.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.2)\n","Installing collected packages: autokeras\n","Successfully installed autokeras-1.0.20\n"]}]},{"cell_type":"code","metadata":{"id":"gcVLfyLKsaCj","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674215371967,"user_tz":180,"elapsed":14,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"05d6fbcc-c515-45d0-e379-95a6ae718158"},"source":["#@title Librerías a usar\n","import autokeras as ak\n","\n","from tensorflow.keras.utils import plot_model\n","from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","from PIL import Image\n","\n","from  sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"Librerías cargadas\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Librerías cargadas\n"]}]},{"cell_type":"code","metadata":{"id":"ysaIl300nDud","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1674215390316,"user_tz":180,"elapsed":6878,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"b23d3676-59e8-4ac4-feee-98094121c2c3"},"source":["#@title Acceder al Drive\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demoML/imagenes/NUMEROS' #@param {type:\"string\"}\n","path_entrenamiento = '/train'  #@param {type:\"string\"}\n","path_prueba = '/test'  #@param {type:\"string\"}\n","\n","imagPath_train = path + path_entrenamiento\n","imagPath_test = path + path_prueba"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"uYz8mV4SnJ4O","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"ok","timestamp":1674215477853,"user_tz":180,"elapsed":87568,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"0100d48e-de28-4e62-cc08-27293265d505"},"source":["#@title Cargar imágenes\n","\n","\n","#@markdown ### Parámetros de imágenes:\n","imagen_ancho = 24 #@param {type:\"integer\"}\n","imagen_largo = 24 #@param {type:\"integer\"}\n","imagen_color = True #@param {type:\"boolean\"}\n","incluir_imagenes_generadas_con_data_augmentation = True #@param {type:\"boolean\"}\n","\n","\n","# tamaño de las imágenes\n","if imagen_ancho<=10:\n","  imagen_largo = 10\n","if imagen_largo<=10:\n","  imagen_largo = 10\n","IMAGE_SHAPE = (imagen_ancho, imagen_largo, (3 if imagen_color else 1))\n","\n","# define tamaño de datos de entrada \n","num_inputs = IMAGE_SHAPE[0] * IMAGE_SHAPE[1] * IMAGE_SHAPE[2]\n","\n","# indica si se usan las imágenes generadas por data augmentation\n","usarDA = incluir_imagenes_generadas_con_data_augmentation\n","\n","\n","# define función para cargar las imágenes\n","def cargarImagenes(imagPath):\n","  classes_ori = [] \n","  images_ori = []\n","  esDA_ori = []\n","\n","  all_dirs = os.listdir( imagPath )\n","  for each_dir in all_dirs:\n","\n","      auxiPath = imagPath + '/' + each_dir \n","      imagFN  = os.listdir( auxiPath )\n","      for each_imagFN in imagFN:\n","\n","            esImagDA = (each_imagFN[:2] == 'da')\n","            \n","            if usarDA or (not esImagDA): \n","                \n","                # abre la imagen\n","                imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","                \n","                # ajusta el tamaño\n","                if IMAGE_SHAPE[2]==1:              \n","                  tipoImage = 'L'\n","                else:                \n","                  tipoImage = 'RGB'\n","                imag = imag.convert(tipoImage)\n","                imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.ANTIALIAS)          \n","                \n","                # transforma a un vector de nros\n","                arImag = np.array(imag)\n","                \n","                # agrega a los vectores\n","                classes_ori.append( each_dir )\n","                images_ori.append( arImag )\n","                esDA_ori.append( esImagDA )\n","\n","  return classes_ori, images_ori, esDA_ori, tipoImage\n","\n","# carga las imagenes de entrenamiento\n","classes_train, images_train, esDAimag_train, tipoImage_train = cargarImagenes(imagPath_train)\n","print(\"> Para Entrenamiento: \")\n","print(\"- Clases cargadas: \", len(np.unique(classes_train)))\n","print(\"- Imágenes cargadas: \", len(classes_train))\n","\n","if len(classes_train)>0:\n","  print(\"- Ejemplo \", classes_train[0], \" \", images_train[0].shape, \": \")\n","  display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","# carga las imagenes de prueba\n","classes_test, images_test, esDAimag_test, tipoImage_test = cargarImagenes(imagPath_test)\n","print(\"\\n\\n> Para Prueba: \")\n","print(\"- Clases cargadas: \", len(np.unique(classes_test)))\n","print(\"- Imágenes cargadas: \", len(images_test))\n","\n","if len(classes_test)>0:\n","  print(\"- Ejemplo \", classes_test[0], \" \", images_test[0].shape, \": \")\n","  display( Image.fromarray(images_test[0], tipoImage_test) )"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["> Para Entrenamiento: \n","- Clases cargadas:  10\n","- Imágenes cargadas:  240\n","- Ejemplo  0   (24, 24, 3) : \n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=24x24 at 0x7F440ADE0280>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAIAAABvFaqvAAACjklEQVR4nI2VMU8qQRDH/8txemIwQTEkSIGFMSaEghA/AIna2RBjrCzsrKnga9gYY2lJYWP8AJbYegUUhLBqQUJINCG53Z1XzHMDy8l7U+3dzv7mv7Ozs4KI8C8zxhCRECKRSPzmI5aDtNae59lPIiKiWNwykDGG13S73clkks1mi8Xi7P85o19MKUVE7Xa7Wq0GQQBgbW3t5OTk7e2NiLTWjn88iCnNZnNR5vb2dhiGxhiHFQNiyu3tLQDf9wFUKpWLi4sgCFZWVgAcHx8vinJBWmtjTL/fX19fTyaTAE5PT6MoIqL7+3sAnuf5vt/r9RyWC2I519fXvGZjY0NKyf+llEEQCCEAtNtt68w2l3wi8jxvNBo9PDwkEgmtdb1ez+fzURR5nkdErBHA5+cn+9u1cyCtNYDn5+fJZMLlc35+/lc58P39PZ1O+eBpoWjmQCz78fFRCKGU2traOjw8tAUtpVRK8TibzTqgpLOv6XTa6XQ4YLlczmQyxhh2CMPQOu/s7NjAriJeLKUcDocctlKpALCg19dXAEqpdDq9t7cHYLa+Y0BKKU5QqVTiKc50p9Nht1KplMvliCheEdvX15eFFgoFHgshut1uGIYc4OjoCD8n8ytoVl0qlbJbe3p6iqKIE1+v1519xYAymYwdCyG4jRDR3d0dH2WtViuXyzENwJYmd6/xeLy5uclOrVaLp1qtFgC+aC8vL05Nx1wRnr66ugKwurrKu6jVavwJoNFoxFJckNZaa/3+/r67u7uYuMvLS2OMUoq1LwPRz4UeDAZnZ2fpdBqA7/sHBwc3Nze8/VgKEcW0WlsgUsqPj49UKrW/v88pny0cx+J7NgeZPRfnFfhfEJt9hdiWUAD8AYRBsOn8iAAFAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","> Para Prueba: \n","- Clases cargadas:  10\n","- Imágenes cargadas:  60\n","- Ejemplo  0   (24, 24, 3) : \n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=24x24 at 0x7F440ADE0370>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAIAAABvFaqvAAACkElEQVR4nJ2VsUvsQBDGZ3djDMRGLNIoATFEG+EsT2OnXBCtrGzE0korSxtbq2strPwTBJsTRcRGDgUR4YiiWLlCEKJidHdeMRjOXOK996acnfyYb74ZwhAR/iKojDFWVsC7IrTWSinGGGMMEbXW/wNSSnHOhRBJkjw9PTHGOOfFIrA8vr6+ELHZbC4uLg4NDfm+HwTB6ekpIiqlcsWlIKLs7e1ZliWEODw8fH5+9n3ftu37+3vS2x1ElP39fZru5uYm5VdXVwFgY2MDET8/P7uAlFJKKSml4zgAYJrm9fW1UkprvbCwwBibmJjQWmutu4ConbW1NfJ7cnKS8mmaep4HAI7jxHGMiO2sPIiUPzw82LYthACA7e1terq6uqLMwMCAlDIHyttPa7K7u/v6+soYMwwjDEMy9+joSCkFALZt9/X1dbFfa52m6ejoKL3SOKjNWq1GyUqlkmsn3xFt8MXFxc3NjWEYABCGIe20lPLs7IxMHBsby3ov3mxEBICTkxP4PivSxRg7Pj5+eXkxTRMAqtVqVlwsjfxaWlqiJ9d1397eSNfKygoACCF6enparRZ2LPcPEL1NT08TaHl5mZJJkgwODpLGmZmZTsqPGSEi5xwA4jimDE2Xc35+fv74+CiEyPYrr6tdWubC+Pg4AFiWFUURZdbX12lkQRDQ3mNHFMxofn6ec+553vv7u1Lq4+NjZGSEc26a5uXlZVb2G4jucGdnBwCmpqYo2Wg0qJ16vV5GyYPoFJMk8Tyvt7f37u7u9vbWdV0A2Nrawo6LLwXhtx1RFM3NzQ0PD/u+Pzs7e3BwgEVOtQfDjvkjImmRUhqG0d/fT3tMnpZFAQi+15++JDfp7v8ZlLUGv/6C2uMPq6+C/fZvTDkAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":["#@title Ajustar imágenes para reducir el fondo (opcional)\n","\n","accion_realizar = \"-\" #@param [\"-\", \"Blur Fondo\", \"Eliminar Fondo y pasar a Negro\", \"Eliminar Fondo y pasar a Blanco\"]\n","\n","def cambiarColorNegro(img, nuevoColor=[255, 255, 255]):\n","    black_pixels = np.where(\n","        (img[:, :, 0] == 0) & \n","        (img[:, :, 1] == 0) & \n","        (img[:, :, 2] == 0)\n","    )\n","    img[black_pixels] = nuevoColor\n","    return img\n","\n","def blurFondoImagen(im):\n","  # Convert to the HSV color space\n","  hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n","  # aplica filtro Otsu threshold para obtener máscara\n","  ret, maskthresh = cv2.threshold(hsv[:,:,0], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","  # Genera la máscara negada\n","  maskthresh = 255 - maskthresh\n","  # We need a to copy the mask 3 times to fit the frames\n","  maskthresh = np.repeat(maskthresh[:, :, np.newaxis], 3, axis=2)\n","  #  Create a blurred frame using Gaussian blur\n","  blurred_frame = cv2.GaussianBlur(im, (25, 25), 0)\n","  # Combine the original with the blurred frame based on mask\n","  return np.where(maskthresh == (255, 255, 255), im, blurred_frame)\n","\n","def reducirFondoImagen(im):\n","  # aplica filtro Hue\n","  imhsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n","  # aplica filtro Otsu threshold para obtener máscara\n","  ret, maskthresh = cv2.threshold(imhsv[:,:,0], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","  # Genera la máscara negada\n","  maskthresh = 255 - maskthresh\n","  # aplica la máscara sobre la imagen\n","  imgfin = cv2.bitwise_and(im, im, mask = maskthresh)\n","  return imgfin\n","\n","def procesarImgRedFondo(imgList):\n","  nList = []\n","  for im in imgList:\n","    if accion_realizar == \"Blur Fondo\":\n","      # hacer blur del fondo\n","      imn = blurFondoImagen(im)\n","    elif accion_realizar == \"Eliminar Fondo y pasar a Negro\":\n","      # eliminar fondo y dejar negro\n","      imn = reducirFondoImagen(im)\n","    elif accion_realizar == \"Eliminar Fondo y pasar a Blanco\":\n","        # cambia fondo negro a casi negro \n","        # (para que no cambié después) \n","        imn = cambiarColorNegro(im, [0, 0, 1])\n","        # eliminar fondo\n","        imn = reducirFondoImagen(imn)\n","        # cambiar fondo a blanco\n","        imn = cambiarColorNegro(imn, [255, 255, 255])\n","    else:\n","      print(\"Acción no definida!\")\n","      break\n","    nList.append( imn )\n","  return nList\n","\n","\n","# degermina si hace algo o no\n","if accion_realizar != \"-\":\n","  # aplica filtros para intentar reducir el fondo de la imagen\n","  # cambiando las imágenes disponibles\n","  images_train = procesarImgRedFondo(images_train)\n","  images_test = procesarImgRedFondo(images_test)\n","\n","  if len(classes_train)>0:\n","    print(\"- Ejemplo Entrenamiento con fondo reducido \", classes_train[0], \" \", images_train[0].shape, \": \")\n","    display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","  if len(classes_test)>0:\n","    print(\"- Ejemplo Prueba con fondo reducido \", classes_test[0], \" \", images_test[0].shape, \": \")\n","    display( Image.fromarray(images_test[0], tipoImage_test) )"],"metadata":{"cellView":"form","id":"SRqjkD1y-ICV","executionInfo":{"status":"ok","timestamp":1674215477854,"user_tz":180,"elapsed":69,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPPvnkjTnTQN","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":562},"executionInfo":{"status":"ok","timestamp":1674215477856,"user_tz":180,"elapsed":67,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"2b7ed60a-e3eb-4573-c3ce-60bf34494b4d"},"source":["#@title Preparar imágenes para usar en el modelo\n","\n","# define función auxiliar para mostrar imágenes preparadas\n","def plot_image(imag):\n","  if IMAGE_SHAPE[2]==1:\n","    plt.imshow((imag).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8)) ## *255\n","    plt.gray()\n","  else:\n","    plt.imshow((imag).reshape(IMAGE_SHAPE).astype(np.uint8)) ## *255\n","  plt.axis(\"off\")  \n","\n","# define función auxiliar para preparar la lista de imágenes a procesar\n","def prepare_imageList(imagList):    \n","##  auxiAr = np.array(imagList).astype('float32') / 255.\n","##  auxiAr = auxiAr.reshape((len(auxiAr), num_inputs))  \n","  auxiAr = np.array(imagList)\n","  auxiAr = auxiAr.reshape((len(auxiAr), IMAGE_SHAPE[0], IMAGE_SHAPE[1], IMAGE_SHAPE[2]))  \n","  return auxiAr\n","\n","  return np.array(auxiAr)\n","\n","# define función auxiliar para preparar lista de clases \n","def prepare_clasesList(classesList, dictMapeo=None):\n","  if dictMapeo==None:\n","    # genera diccionario de mapeo\n","    auxDict = list(set(classesList))\n","    dictMapeo = dict( zip( auxDict, range(len(auxDict)) ) )\n","  # realiza el mapeo\n","  y = []\n","  for cl in classesList:\n","      y.append( dictMapeo[cl] )\n","  # convierte valores numéricos a columnas de vakores binarios (i.e. one hot encoded)\n","  dummy_y = np_utils.to_categorical(y)\n","  # devuelve\n","  return np.array(y), np.array(dummy_y), dictMapeo\n","\n","# define vector auxiliar de datos de entrada para usar en el entrenamiento y prueba\n","x_train = prepare_imageList(images_train)\n","x_test = prepare_imageList(images_test)\n","\n","# define vector auxiliar de datos de salida para usar en el entrenamiento y prueba\n","# también usa esta información para determinar la cantida de neuronas de salida\n","y_train, y_trainEnc, dictMapeo = prepare_clasesList(classes_train)\n","y_test, y_testEnc,_ = prepare_clasesList(classes_test, dictMapeo)\n","\n","daLayers_modelo = []\n","\n","# genera diccionario auxiliar para poder convertir de ID de clase a nombre de clase\n","clases_map = [ x for x,y in dictMapeo.items() ]\n","\n","print(\"> Para Entrenamiento: \")\n","print(\" - x_train (cant ejemplos, datos entrada): \", x_train.shape)\n","print(\" - y_trainEnc (cant): \", len(y_trainEnc))\n","print(\" - y_train (cant): \", len(y_train))\n","print(\"\\n\\n> Para Prueba: \")\n","print(\" - x_test (cant ejemplos, datos entrada): \", x_test.shape)\n","print(\" - y_testEnc (cant): \", len(y_testEnc))\n","print(\" - y_test (cant): \", len(y_test))\n","print(\"\\n\\n> Para Ambos: \")\n","print(\" - dictMapeo: \", dictMapeo)\n","print(\" - clases_map: \", clases_map)\n","if len(y_train)>0:\n","  print(\"\\n - Imagen reconstruida de \", clases_map[y_train[0]],  \"(\", y_train[0], \" / \", y_trainEnc[0], \")\")\n","  plot_image(x_train[0])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["> Para Entrenamiento: \n"," - x_train (cant ejemplos, datos entrada):  (240, 24, 24, 3)\n"," - y_trainEnc (cant):  240\n"," - y_train (cant):  240\n","\n","\n","> Para Prueba: \n"," - x_test (cant ejemplos, datos entrada):  (60, 24, 24, 3)\n"," - y_testEnc (cant):  60\n"," - y_test (cant):  60\n","\n","\n","> Para Ambos: \n"," - dictMapeo:  {'5': 0, '7': 1, '8': 2, '1': 3, '6': 4, '0': 5, '9': 6, '4': 7, '3': 8, '2': 9}\n"," - clases_map:  ['5', '7', '8', '1', '6', '0', '9', '4', '3', '2']\n","\n"," - Imagen reconstruida de  0 ( 5  /  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] )\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"_MlYyhEutC_O","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674215477857,"user_tz":180,"elapsed":59,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"b9d45087-6091-4a86-b18c-c16d686edf4e"},"source":["#@title Establecer modelo base para AutoKeras\n","\n","\n","cantidad_intentos_encontrar_modelo = 5 #@param {type:\"integer\"}\n","if cantidad_intentos_encontrar_modelo < 1:\n","  cantidad_intentos_encontrar_modelo = 1\n","\n","tipo_modelo_usar = \"Personalizado\" #@param [\"ImageClassifier\", \"Personalizado\"]\n","\n","max_cant_params_modelo =  50000000#@param {type:\"integer\"}\n","if max_cant_params_modelo <= 0:\n","  max_cant_params_modelo = None\n","#@markdown   (Nota: se limita la complejidad el modelo a usar para evitar problemas por limitación de memoria RAM.)\n","\n","# AutoKeras siempre se usa salida softmax \n","# (se puede usar salida lineal pero lo aplica el pipeline,\n","#  no el modelo que se exporta)\n","tipo_output_softMax = True\n","\n","if tipo_modelo_usar == \"ImageClassifier\":\n","    # Initialize the image classifier.\n","    AKmodel = ak.ImageClassifier(num_classes=len(clases_map), \n","                                          overwrite=True, \n","                                          seed=1,\n","                                          objective='val_accuracy',\n","                                          max_model_size=max_cant_params_modelo,\n","                                          max_trials=cantidad_intentos_encontrar_modelo)\n","else:\n","    # capa de entrada\n","    input_node = ak.ImageInput()\n","    # capas intermedias\n","    output_node = ak.ImageBlock(\n","        # Only search ConvNet architectures.\n","        block_type=\"vanilla\",\n","        # Normalize the dataset.\n","        normalize=True,\n","        # Allow do data augmentation.\n","        augment=True,\n","    )(input_node)\n","    # capa de salida\n","    output_node = ak.ClassificationHead(num_classes=len(clases_map))(output_node)\n","    # Initialize AutoModel personalizado\n","    AKmodel = ak.AutoModel(\n","        inputs=input_node, outputs=output_node,          \n","        overwrite=True, \n","        seed=1,\n","        objective='val_accuracy',\n","        max_model_size=max_cant_params_modelo,\n","        max_trials=cantidad_intentos_encontrar_modelo)\n","\n","print(\"Modelo preparado\")\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Modelo preparado\n"]}]},{"cell_type":"code","metadata":{"id":"6wMQ8atOM3lq","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674215792414,"user_tz":180,"elapsed":314609,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"430e5521-a4c2-49c3-a690-f3dc4fc0c6fa"},"source":["#@title Entrenar con AutoKeras\n","\n","\n","max_epocas_entrenamiento =  300#@param {type:\"integer\"}\n","if max_epocas_entrenamiento <= 0:\n","  max_epocas_entrenamiento = None\n","\n","\n","# separa al azar usando muestreo al azar del 10%\n","# para tomar algunos como datos de validación\n","x_t, x_v, y_t, y_v = train_test_split(x_train, \n","                                       (y_trainEnc if tipo_output_softMax else y_train), \n","                                       test_size=0.1)\n","\n","print(\"\\n> De los \", len(x_train), \"ejemplos de entrenamiento: \")\n","print(\"            se usan \", len(x_t), \"ejemplos para entrenar \")\n","print(\"            y \", len(x_v), \"ejemplos para validar.\")\n","\n","print(\"\\n\\n>Comienza el Entrenamiento:\")\n","\n","# el history sólo devuelve el del último trial\n","#history = \n","AKmodel.fit(x_t, y_t,\n","                      validation_data=(x_v, y_v,),\n","                      epochs=max_epocas_entrenamiento\n","                      )\n","\n","print(\"\\n>Entrenamiento Finalizado.\")\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 00m 45s]\n","val_accuracy: 1.0\n","\n","Best val_accuracy So Far: 1.0\n","Total elapsed time: 00h 02m 18s\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"]},{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 3s 86ms/step - loss: 2.4774 - accuracy: 0.0741 - val_loss: 2.3055 - val_accuracy: 0.0000e+00\n","Epoch 2/300\n","7/7 [==============================] - 0s 63ms/step - loss: 2.3019 - accuracy: 0.1065 - val_loss: 2.3166 - val_accuracy: 0.0000e+00\n","Epoch 3/300\n","7/7 [==============================] - 0s 61ms/step - loss: 2.2960 - accuracy: 0.1435 - val_loss: 2.3209 - val_accuracy: 0.0417\n","Epoch 4/300\n","7/7 [==============================] - 0s 54ms/step - loss: 2.2844 - accuracy: 0.1481 - val_loss: 2.3410 - val_accuracy: 0.0833\n","Epoch 5/300\n","7/7 [==============================] - 0s 58ms/step - loss: 2.1313 - accuracy: 0.2315 - val_loss: 2.0856 - val_accuracy: 0.1250\n","Epoch 6/300\n","7/7 [==============================] - 0s 58ms/step - loss: 2.1400 - accuracy: 0.1991 - val_loss: 2.0898 - val_accuracy: 0.2083\n","Epoch 7/300\n","7/7 [==============================] - 0s 55ms/step - loss: 1.9528 - accuracy: 0.2593 - val_loss: 1.3901 - val_accuracy: 0.6667\n","Epoch 8/300\n","7/7 [==============================] - 0s 55ms/step - loss: 1.7560 - accuracy: 0.3426 - val_loss: 1.2043 - val_accuracy: 0.6667\n","Epoch 9/300\n","7/7 [==============================] - 0s 54ms/step - loss: 1.6151 - accuracy: 0.3843 - val_loss: 1.1198 - val_accuracy: 0.7500\n","Epoch 10/300\n","7/7 [==============================] - 0s 56ms/step - loss: 1.5740 - accuracy: 0.4167 - val_loss: 1.0393 - val_accuracy: 0.5833\n","Epoch 11/300\n","7/7 [==============================] - 0s 61ms/step - loss: 1.4265 - accuracy: 0.4676 - val_loss: 0.8226 - val_accuracy: 0.7917\n","Epoch 12/300\n","7/7 [==============================] - 0s 59ms/step - loss: 1.3794 - accuracy: 0.5046 - val_loss: 0.7441 - val_accuracy: 0.7917\n","Epoch 13/300\n","7/7 [==============================] - 0s 64ms/step - loss: 1.2083 - accuracy: 0.5509 - val_loss: 1.0099 - val_accuracy: 0.5833\n","Epoch 14/300\n","7/7 [==============================] - 0s 56ms/step - loss: 1.2788 - accuracy: 0.5185 - val_loss: 0.8085 - val_accuracy: 0.7083\n","Epoch 15/300\n","7/7 [==============================] - 0s 55ms/step - loss: 1.2816 - accuracy: 0.5648 - val_loss: 0.8765 - val_accuracy: 0.6667\n","Epoch 16/300\n","7/7 [==============================] - 0s 55ms/step - loss: 1.1995 - accuracy: 0.5648 - val_loss: 0.9352 - val_accuracy: 0.7083\n","Epoch 17/300\n","7/7 [==============================] - 0s 54ms/step - loss: 1.1752 - accuracy: 0.5648 - val_loss: 0.8784 - val_accuracy: 0.6667\n","Epoch 18/300\n","7/7 [==============================] - 0s 57ms/step - loss: 1.0544 - accuracy: 0.6250 - val_loss: 0.8883 - val_accuracy: 0.7083\n","Epoch 19/300\n","7/7 [==============================] - 0s 55ms/step - loss: 1.0505 - accuracy: 0.6065 - val_loss: 0.8156 - val_accuracy: 0.7083\n","Epoch 20/300\n","7/7 [==============================] - 0s 55ms/step - loss: 1.0372 - accuracy: 0.6435 - val_loss: 0.6038 - val_accuracy: 0.7500\n","Epoch 21/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.9776 - accuracy: 0.6528 - val_loss: 0.4486 - val_accuracy: 0.8750\n","Epoch 22/300\n","7/7 [==============================] - 0s 55ms/step - loss: 1.0105 - accuracy: 0.6528 - val_loss: 0.4632 - val_accuracy: 0.8333\n","Epoch 23/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.9185 - accuracy: 0.6481 - val_loss: 0.5283 - val_accuracy: 0.8750\n","Epoch 24/300\n","7/7 [==============================] - 0s 55ms/step - loss: 1.0787 - accuracy: 0.6389 - val_loss: 0.6794 - val_accuracy: 0.7083\n","Epoch 25/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.8590 - accuracy: 0.6944 - val_loss: 0.6772 - val_accuracy: 0.7917\n","Epoch 26/300\n","7/7 [==============================] - 0s 53ms/step - loss: 0.8413 - accuracy: 0.7083 - val_loss: 0.3709 - val_accuracy: 0.9167\n","Epoch 27/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.8464 - accuracy: 0.6806 - val_loss: 0.4542 - val_accuracy: 0.7917\n","Epoch 28/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.9563 - accuracy: 0.6574 - val_loss: 0.4938 - val_accuracy: 0.8333\n","Epoch 29/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.8579 - accuracy: 0.6991 - val_loss: 0.4970 - val_accuracy: 0.8333\n","Epoch 30/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.8353 - accuracy: 0.6944 - val_loss: 0.3120 - val_accuracy: 0.9167\n","Epoch 31/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.8365 - accuracy: 0.6667 - val_loss: 0.3993 - val_accuracy: 0.8750\n","Epoch 32/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.7602 - accuracy: 0.7269 - val_loss: 0.6034 - val_accuracy: 0.8750\n","Epoch 33/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.7409 - accuracy: 0.7361 - val_loss: 0.3813 - val_accuracy: 0.8333\n","Epoch 34/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.7420 - accuracy: 0.7269 - val_loss: 0.3019 - val_accuracy: 0.8750\n","Epoch 35/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.6786 - accuracy: 0.7454 - val_loss: 0.3432 - val_accuracy: 0.8750\n","Epoch 36/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.7201 - accuracy: 0.7593 - val_loss: 0.1698 - val_accuracy: 0.9167\n","Epoch 37/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.7073 - accuracy: 0.7361 - val_loss: 0.3694 - val_accuracy: 0.8333\n","Epoch 38/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.8556 - accuracy: 0.6944 - val_loss: 0.3341 - val_accuracy: 0.8333\n","Epoch 39/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.7219 - accuracy: 0.7083 - val_loss: 0.3789 - val_accuracy: 0.7500\n","Epoch 40/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.8346 - accuracy: 0.6713 - val_loss: 0.3430 - val_accuracy: 0.8333\n","Epoch 41/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.7085 - accuracy: 0.7222 - val_loss: 0.2198 - val_accuracy: 0.9583\n","Epoch 42/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.7583 - accuracy: 0.7454 - val_loss: 0.2396 - val_accuracy: 0.8750\n","Epoch 43/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.7429 - accuracy: 0.7361 - val_loss: 0.3871 - val_accuracy: 0.8333\n","Epoch 44/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.7975 - accuracy: 0.7176 - val_loss: 0.3085 - val_accuracy: 0.8750\n","Epoch 45/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.7143 - accuracy: 0.7593 - val_loss: 0.2433 - val_accuracy: 0.9167\n","Epoch 46/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.6116 - accuracy: 0.7593 - val_loss: 0.2363 - val_accuracy: 0.8750\n","Epoch 47/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.7010 - accuracy: 0.7500 - val_loss: 0.2257 - val_accuracy: 0.9167\n","Epoch 48/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.7558 - accuracy: 0.7315 - val_loss: 0.2365 - val_accuracy: 0.8750\n","Epoch 49/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.6232 - accuracy: 0.7731 - val_loss: 0.3014 - val_accuracy: 0.8750\n","Epoch 50/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.6290 - accuracy: 0.7824 - val_loss: 0.3168 - val_accuracy: 0.9167\n","Epoch 51/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.6160 - accuracy: 0.7963 - val_loss: 0.4946 - val_accuracy: 0.7917\n","Epoch 52/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.6954 - accuracy: 0.7685 - val_loss: 0.3773 - val_accuracy: 0.7917\n","Epoch 53/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.6351 - accuracy: 0.7963 - val_loss: 0.4067 - val_accuracy: 0.7917\n","Epoch 54/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.6388 - accuracy: 0.7593 - val_loss: 0.2119 - val_accuracy: 0.8750\n","Epoch 55/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.6550 - accuracy: 0.7870 - val_loss: 0.2653 - val_accuracy: 0.9583\n","Epoch 56/300\n","7/7 [==============================] - 0s 71ms/step - loss: 0.6956 - accuracy: 0.7685 - val_loss: 0.1894 - val_accuracy: 0.8750\n","Epoch 57/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.6214 - accuracy: 0.7824 - val_loss: 0.1716 - val_accuracy: 0.9583\n","Epoch 58/300\n","7/7 [==============================] - 1s 69ms/step - loss: 0.6405 - accuracy: 0.7824 - val_loss: 0.1276 - val_accuracy: 0.9583\n","Epoch 59/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.6447 - accuracy: 0.7824 - val_loss: 0.1885 - val_accuracy: 0.9167\n","Epoch 60/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.6125 - accuracy: 0.7546 - val_loss: 0.2647 - val_accuracy: 0.9167\n","Epoch 61/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.6753 - accuracy: 0.7407 - val_loss: 0.5655 - val_accuracy: 0.7917\n","Epoch 62/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.5820 - accuracy: 0.7593 - val_loss: 0.3757 - val_accuracy: 0.8750\n","Epoch 63/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.6211 - accuracy: 0.7593 - val_loss: 0.3100 - val_accuracy: 0.8333\n","Epoch 64/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.6513 - accuracy: 0.7778 - val_loss: 0.3407 - val_accuracy: 0.8750\n","Epoch 65/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5849 - accuracy: 0.7731 - val_loss: 0.4205 - val_accuracy: 0.8333\n","Epoch 66/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.6692 - accuracy: 0.7639 - val_loss: 0.5769 - val_accuracy: 0.8333\n","Epoch 67/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5057 - accuracy: 0.8102 - val_loss: 0.4587 - val_accuracy: 0.8750\n","Epoch 68/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.6731 - accuracy: 0.7546 - val_loss: 0.2032 - val_accuracy: 0.8750\n","Epoch 69/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.7228 - accuracy: 0.7083 - val_loss: 0.1845 - val_accuracy: 0.9167\n","Epoch 70/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.6270 - accuracy: 0.7639 - val_loss: 0.2461 - val_accuracy: 0.8750\n","Epoch 71/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.6379 - accuracy: 0.7639 - val_loss: 0.2332 - val_accuracy: 0.8750\n","Epoch 72/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.5853 - accuracy: 0.7685 - val_loss: 0.2726 - val_accuracy: 0.8750\n","Epoch 73/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.5752 - accuracy: 0.7593 - val_loss: 0.2410 - val_accuracy: 0.8750\n","Epoch 74/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4812 - accuracy: 0.8333 - val_loss: 0.1577 - val_accuracy: 0.9583\n","Epoch 75/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.6111 - accuracy: 0.8009 - val_loss: 0.1723 - val_accuracy: 0.9167\n","Epoch 76/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.5205 - accuracy: 0.7917 - val_loss: 0.2765 - val_accuracy: 0.8750\n","Epoch 77/300\n","7/7 [==============================] - 0s 65ms/step - loss: 0.5137 - accuracy: 0.7963 - val_loss: 0.3663 - val_accuracy: 0.8750\n","Epoch 78/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.5665 - accuracy: 0.7963 - val_loss: 0.3535 - val_accuracy: 0.8333\n","Epoch 79/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5482 - accuracy: 0.7824 - val_loss: 0.7018 - val_accuracy: 0.7500\n","Epoch 80/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.6611 - accuracy: 0.7546 - val_loss: 0.1526 - val_accuracy: 0.9167\n","Epoch 81/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5842 - accuracy: 0.7963 - val_loss: 0.3458 - val_accuracy: 0.8750\n","Epoch 82/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.6002 - accuracy: 0.7639 - val_loss: 0.2088 - val_accuracy: 0.8750\n","Epoch 83/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.4824 - accuracy: 0.8148 - val_loss: 0.1030 - val_accuracy: 1.0000\n","Epoch 84/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5881 - accuracy: 0.7778 - val_loss: 0.3255 - val_accuracy: 0.9167\n","Epoch 85/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.6067 - accuracy: 0.8009 - val_loss: 0.2543 - val_accuracy: 0.9167\n","Epoch 86/300\n","7/7 [==============================] - 0s 63ms/step - loss: 0.5116 - accuracy: 0.7824 - val_loss: 0.2971 - val_accuracy: 0.9167\n","Epoch 87/300\n","7/7 [==============================] - 0s 53ms/step - loss: 0.4408 - accuracy: 0.8380 - val_loss: 0.3599 - val_accuracy: 0.7917\n","Epoch 88/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4996 - accuracy: 0.8380 - val_loss: 0.1449 - val_accuracy: 0.9167\n","Epoch 89/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4555 - accuracy: 0.8241 - val_loss: 0.2754 - val_accuracy: 0.8750\n","Epoch 90/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4619 - accuracy: 0.8148 - val_loss: 0.2346 - val_accuracy: 0.8750\n","Epoch 91/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.5027 - accuracy: 0.8102 - val_loss: 0.2581 - val_accuracy: 0.8333\n","Epoch 92/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5657 - accuracy: 0.7870 - val_loss: 0.2792 - val_accuracy: 0.9167\n","Epoch 93/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4349 - accuracy: 0.8056 - val_loss: 0.4622 - val_accuracy: 0.7917\n","Epoch 94/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4364 - accuracy: 0.8472 - val_loss: 0.5533 - val_accuracy: 0.8750\n","Epoch 95/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4443 - accuracy: 0.8333 - val_loss: 0.1913 - val_accuracy: 0.8750\n","Epoch 96/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4487 - accuracy: 0.8148 - val_loss: 0.1017 - val_accuracy: 0.9583\n","Epoch 97/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.6450 - accuracy: 0.7500 - val_loss: 0.2413 - val_accuracy: 0.8750\n","Epoch 98/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.5234 - accuracy: 0.7870 - val_loss: 0.1021 - val_accuracy: 0.9583\n","Epoch 99/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.5575 - accuracy: 0.7963 - val_loss: 0.1714 - val_accuracy: 0.9583\n","Epoch 100/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5131 - accuracy: 0.8287 - val_loss: 0.2894 - val_accuracy: 0.8750\n","Epoch 101/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5535 - accuracy: 0.7963 - val_loss: 0.1819 - val_accuracy: 0.9167\n","Epoch 102/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4776 - accuracy: 0.8102 - val_loss: 0.3806 - val_accuracy: 0.8750\n","Epoch 103/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4900 - accuracy: 0.7731 - val_loss: 0.6329 - val_accuracy: 0.7500\n","Epoch 104/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5414 - accuracy: 0.7917 - val_loss: 0.2728 - val_accuracy: 0.9167\n","Epoch 105/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5825 - accuracy: 0.8102 - val_loss: 0.4919 - val_accuracy: 0.7917\n","Epoch 106/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4448 - accuracy: 0.8241 - val_loss: 0.4297 - val_accuracy: 0.8750\n","Epoch 107/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.5339 - accuracy: 0.8056 - val_loss: 0.2901 - val_accuracy: 0.8750\n","Epoch 108/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5074 - accuracy: 0.7870 - val_loss: 0.4021 - val_accuracy: 0.8750\n","Epoch 109/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4318 - accuracy: 0.8519 - val_loss: 0.3916 - val_accuracy: 0.8750\n","Epoch 110/300\n","7/7 [==============================] - 0s 53ms/step - loss: 0.5172 - accuracy: 0.7917 - val_loss: 0.2342 - val_accuracy: 0.8750\n","Epoch 111/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4414 - accuracy: 0.8148 - val_loss: 0.1710 - val_accuracy: 0.9167\n","Epoch 112/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4467 - accuracy: 0.8056 - val_loss: 0.2486 - val_accuracy: 0.8750\n","Epoch 113/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.4326 - accuracy: 0.8519 - val_loss: 0.1892 - val_accuracy: 0.9167\n","Epoch 114/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.4739 - accuracy: 0.8148 - val_loss: 0.3117 - val_accuracy: 0.8750\n","Epoch 115/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4554 - accuracy: 0.8426 - val_loss: 0.3170 - val_accuracy: 0.8750\n","Epoch 116/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4890 - accuracy: 0.7870 - val_loss: 0.2008 - val_accuracy: 0.8750\n","Epoch 117/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.4773 - accuracy: 0.7963 - val_loss: 0.1456 - val_accuracy: 0.9583\n","Epoch 118/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.4875 - accuracy: 0.8009 - val_loss: 0.1949 - val_accuracy: 0.8750\n","Epoch 119/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5449 - accuracy: 0.8241 - val_loss: 0.2252 - val_accuracy: 0.8333\n","Epoch 120/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5286 - accuracy: 0.7917 - val_loss: 0.1402 - val_accuracy: 0.9167\n","Epoch 121/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5600 - accuracy: 0.7778 - val_loss: 0.1349 - val_accuracy: 1.0000\n","Epoch 122/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4502 - accuracy: 0.8102 - val_loss: 0.1481 - val_accuracy: 0.8750\n","Epoch 123/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4542 - accuracy: 0.8194 - val_loss: 0.0847 - val_accuracy: 0.9583\n","Epoch 124/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4514 - accuracy: 0.8056 - val_loss: 0.0658 - val_accuracy: 1.0000\n","Epoch 125/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5680 - accuracy: 0.8056 - val_loss: 0.2523 - val_accuracy: 0.8750\n","Epoch 126/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.4886 - accuracy: 0.8194 - val_loss: 0.1033 - val_accuracy: 0.9583\n","Epoch 127/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4712 - accuracy: 0.8148 - val_loss: 0.1324 - val_accuracy: 0.9583\n","Epoch 128/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5384 - accuracy: 0.7639 - val_loss: 0.2665 - val_accuracy: 0.9167\n","Epoch 129/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4391 - accuracy: 0.7870 - val_loss: 0.1774 - val_accuracy: 0.8750\n","Epoch 130/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4479 - accuracy: 0.8333 - val_loss: 0.2504 - val_accuracy: 0.8750\n","Epoch 131/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4972 - accuracy: 0.8056 - val_loss: 0.1177 - val_accuracy: 0.9167\n","Epoch 132/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4363 - accuracy: 0.8241 - val_loss: 0.1588 - val_accuracy: 0.9167\n","Epoch 133/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4484 - accuracy: 0.8194 - val_loss: 0.1582 - val_accuracy: 0.9167\n","Epoch 134/300\n","7/7 [==============================] - 0s 53ms/step - loss: 0.5318 - accuracy: 0.7963 - val_loss: 0.0994 - val_accuracy: 0.9167\n","Epoch 135/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.3507 - accuracy: 0.8472 - val_loss: 0.1674 - val_accuracy: 0.9167\n","Epoch 136/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4240 - accuracy: 0.8333 - val_loss: 0.0912 - val_accuracy: 0.9167\n","Epoch 137/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4224 - accuracy: 0.8194 - val_loss: 0.0963 - val_accuracy: 0.9583\n","Epoch 138/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.3804 - accuracy: 0.8380 - val_loss: 0.0945 - val_accuracy: 1.0000\n","Epoch 139/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4064 - accuracy: 0.8519 - val_loss: 0.1722 - val_accuracy: 0.8750\n","Epoch 140/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.3497 - accuracy: 0.8796 - val_loss: 0.0641 - val_accuracy: 1.0000\n","Epoch 141/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4441 - accuracy: 0.8380 - val_loss: 0.1063 - val_accuracy: 0.9583\n","Epoch 142/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.5444 - accuracy: 0.7963 - val_loss: 0.3005 - val_accuracy: 0.8750\n","Epoch 143/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.4242 - accuracy: 0.8380 - val_loss: 0.1880 - val_accuracy: 0.9167\n","Epoch 144/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5248 - accuracy: 0.8148 - val_loss: 0.2719 - val_accuracy: 0.9167\n","Epoch 145/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4358 - accuracy: 0.8426 - val_loss: 0.0976 - val_accuracy: 1.0000\n","Epoch 146/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4490 - accuracy: 0.8241 - val_loss: 0.0974 - val_accuracy: 0.9583\n","Epoch 147/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4550 - accuracy: 0.8009 - val_loss: 0.1265 - val_accuracy: 0.9583\n","Epoch 148/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4999 - accuracy: 0.8148 - val_loss: 0.2200 - val_accuracy: 0.8750\n","Epoch 149/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5823 - accuracy: 0.7917 - val_loss: 0.2573 - val_accuracy: 0.8750\n","Epoch 150/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4324 - accuracy: 0.8333 - val_loss: 0.1077 - val_accuracy: 0.9583\n","Epoch 151/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4401 - accuracy: 0.8194 - val_loss: 0.4058 - val_accuracy: 0.7917\n","Epoch 152/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4782 - accuracy: 0.8056 - val_loss: 0.4383 - val_accuracy: 0.8333\n","Epoch 153/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4220 - accuracy: 0.8241 - val_loss: 0.3913 - val_accuracy: 0.8333\n","Epoch 154/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4765 - accuracy: 0.8380 - val_loss: 0.1943 - val_accuracy: 0.8750\n","Epoch 155/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.3984 - accuracy: 0.8519 - val_loss: 0.1230 - val_accuracy: 1.0000\n","Epoch 156/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.3938 - accuracy: 0.8565 - val_loss: 0.0929 - val_accuracy: 0.9583\n","Epoch 157/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4560 - accuracy: 0.8426 - val_loss: 0.1060 - val_accuracy: 1.0000\n","Epoch 158/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4370 - accuracy: 0.8241 - val_loss: 0.0925 - val_accuracy: 1.0000\n","Epoch 159/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.4252 - accuracy: 0.8194 - val_loss: 0.1819 - val_accuracy: 0.9167\n","Epoch 160/300\n","7/7 [==============================] - 0s 54ms/step - loss: 0.5018 - accuracy: 0.7963 - val_loss: 0.1180 - val_accuracy: 0.9167\n","Epoch 161/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4105 - accuracy: 0.8565 - val_loss: 0.1671 - val_accuracy: 0.9583\n","Epoch 162/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4201 - accuracy: 0.8333 - val_loss: 0.4808 - val_accuracy: 0.8750\n","Epoch 163/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.3783 - accuracy: 0.8426 - val_loss: 0.1652 - val_accuracy: 0.9167\n","Epoch 164/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4469 - accuracy: 0.8380 - val_loss: 0.1524 - val_accuracy: 0.9583\n","Epoch 165/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4945 - accuracy: 0.8194 - val_loss: 0.3224 - val_accuracy: 0.8750\n","Epoch 166/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4829 - accuracy: 0.8194 - val_loss: 0.2268 - val_accuracy: 0.9167\n","Epoch 167/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.5495 - accuracy: 0.7917 - val_loss: 0.2558 - val_accuracy: 0.8333\n","Epoch 168/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4972 - accuracy: 0.8194 - val_loss: 0.3459 - val_accuracy: 0.8750\n","Epoch 169/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5253 - accuracy: 0.8194 - val_loss: 0.1863 - val_accuracy: 0.9583\n","Epoch 170/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4013 - accuracy: 0.8426 - val_loss: 0.2581 - val_accuracy: 0.8750\n","Epoch 171/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5034 - accuracy: 0.8287 - val_loss: 0.1498 - val_accuracy: 0.9583\n","Epoch 172/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.4796 - accuracy: 0.8241 - val_loss: 0.2391 - val_accuracy: 0.8750\n","Epoch 173/300\n","7/7 [==============================] - 0s 64ms/step - loss: 0.4457 - accuracy: 0.8426 - val_loss: 0.2474 - val_accuracy: 0.8750\n","Epoch 174/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3383 - accuracy: 0.8796 - val_loss: 0.3066 - val_accuracy: 0.8750\n","Epoch 175/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5611 - accuracy: 0.8148 - val_loss: 0.3658 - val_accuracy: 0.8750\n","Epoch 176/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5041 - accuracy: 0.8380 - val_loss: 0.4779 - val_accuracy: 0.8750\n","Epoch 177/300\n","7/7 [==============================] - 0s 63ms/step - loss: 0.5211 - accuracy: 0.7917 - val_loss: 0.1840 - val_accuracy: 0.9583\n","Epoch 178/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.4604 - accuracy: 0.8194 - val_loss: 0.1315 - val_accuracy: 0.9167\n","Epoch 179/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5085 - accuracy: 0.8056 - val_loss: 0.2446 - val_accuracy: 0.8333\n","Epoch 180/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4102 - accuracy: 0.8426 - val_loss: 0.2202 - val_accuracy: 0.8750\n","Epoch 181/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.3599 - accuracy: 0.8287 - val_loss: 0.3400 - val_accuracy: 0.8750\n","Epoch 182/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.3777 - accuracy: 0.8472 - val_loss: 0.6489 - val_accuracy: 0.7500\n","Epoch 183/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4025 - accuracy: 0.8380 - val_loss: 0.4446 - val_accuracy: 0.9167\n","Epoch 184/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3732 - accuracy: 0.8426 - val_loss: 0.0554 - val_accuracy: 1.0000\n","Epoch 185/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.7668 - accuracy: 0.7731 - val_loss: 0.3373 - val_accuracy: 0.8750\n","Epoch 186/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.7219 - accuracy: 0.7361 - val_loss: 0.4504 - val_accuracy: 0.8333\n","Epoch 187/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.6920 - accuracy: 0.7315 - val_loss: 0.4075 - val_accuracy: 0.8750\n","Epoch 188/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.6916 - accuracy: 0.7546 - val_loss: 0.6666 - val_accuracy: 0.6667\n","Epoch 189/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.7826 - accuracy: 0.7315 - val_loss: 0.5073 - val_accuracy: 0.8333\n","Epoch 190/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.6567 - accuracy: 0.7778 - val_loss: 0.8063 - val_accuracy: 0.7917\n","Epoch 191/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.6089 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7917\n","Epoch 192/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.7437 - accuracy: 0.7500 - val_loss: 0.2007 - val_accuracy: 0.8750\n","Epoch 193/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.8730 - accuracy: 0.7500 - val_loss: 0.1663 - val_accuracy: 0.9167\n","Epoch 194/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.6086 - accuracy: 0.7870 - val_loss: 0.1890 - val_accuracy: 0.8750\n","Epoch 195/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.7154 - accuracy: 0.7500 - val_loss: 0.1768 - val_accuracy: 0.9583\n","Epoch 196/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5405 - accuracy: 0.7917 - val_loss: 0.3515 - val_accuracy: 0.8750\n","Epoch 197/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5251 - accuracy: 0.7917 - val_loss: 0.2691 - val_accuracy: 0.8750\n","Epoch 198/300\n","7/7 [==============================] - 0s 55ms/step - loss: 0.5123 - accuracy: 0.8009 - val_loss: 0.1767 - val_accuracy: 0.9167\n","Epoch 199/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4231 - accuracy: 0.8380 - val_loss: 0.3726 - val_accuracy: 0.8750\n","Epoch 200/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5167 - accuracy: 0.8241 - val_loss: 0.2841 - val_accuracy: 0.8750\n","Epoch 201/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.5238 - accuracy: 0.8148 - val_loss: 0.3666 - val_accuracy: 0.8750\n","Epoch 202/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.3915 - accuracy: 0.8472 - val_loss: 0.2615 - val_accuracy: 0.8750\n","Epoch 203/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4744 - accuracy: 0.8241 - val_loss: 0.3103 - val_accuracy: 0.8333\n","Epoch 204/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4432 - accuracy: 0.8148 - val_loss: 0.3413 - val_accuracy: 0.8333\n","Epoch 205/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.3566 - accuracy: 0.8333 - val_loss: 0.5677 - val_accuracy: 0.7500\n","Epoch 206/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5059 - accuracy: 0.8241 - val_loss: 0.3969 - val_accuracy: 0.7917\n","Epoch 207/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.5031 - accuracy: 0.8056 - val_loss: 0.1358 - val_accuracy: 0.8750\n","Epoch 208/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4148 - accuracy: 0.8241 - val_loss: 0.0948 - val_accuracy: 0.9583\n","Epoch 209/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.4232 - accuracy: 0.8519 - val_loss: 0.1032 - val_accuracy: 0.9583\n","Epoch 210/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4393 - accuracy: 0.8241 - val_loss: 0.5652 - val_accuracy: 0.7083\n","Epoch 211/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.5121 - accuracy: 0.8056 - val_loss: 0.0720 - val_accuracy: 0.9583\n","Epoch 212/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4486 - accuracy: 0.8194 - val_loss: 0.1038 - val_accuracy: 0.9583\n","Epoch 213/300\n","7/7 [==============================] - 0s 62ms/step - loss: 0.4648 - accuracy: 0.8148 - val_loss: 0.1524 - val_accuracy: 0.9167\n","Epoch 214/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.4532 - accuracy: 0.8380 - val_loss: 0.0631 - val_accuracy: 1.0000\n","Epoch 215/300\n","7/7 [==============================] - 1s 80ms/step - loss: 0.3898 - accuracy: 0.8565 - val_loss: 0.0397 - val_accuracy: 1.0000\n","Epoch 216/300\n","7/7 [==============================] - 1s 107ms/step - loss: 0.4451 - accuracy: 0.8519 - val_loss: 0.0657 - val_accuracy: 1.0000\n","Epoch 217/300\n","7/7 [==============================] - 1s 102ms/step - loss: 0.5078 - accuracy: 0.8056 - val_loss: 0.0620 - val_accuracy: 1.0000\n","Epoch 218/300\n","7/7 [==============================] - 1s 100ms/step - loss: 0.4651 - accuracy: 0.8333 - val_loss: 0.1459 - val_accuracy: 0.9583\n","Epoch 219/300\n","7/7 [==============================] - 0s 65ms/step - loss: 0.5456 - accuracy: 0.7778 - val_loss: 0.1155 - val_accuracy: 0.9583\n","Epoch 220/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.4090 - accuracy: 0.8611 - val_loss: 0.1932 - val_accuracy: 0.8750\n","Epoch 221/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.3704 - accuracy: 0.8426 - val_loss: 0.1372 - val_accuracy: 0.9583\n","Epoch 222/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4287 - accuracy: 0.8426 - val_loss: 0.1135 - val_accuracy: 0.9167\n","Epoch 223/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.3433 - accuracy: 0.8750 - val_loss: 0.0765 - val_accuracy: 0.9583\n","Epoch 224/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4452 - accuracy: 0.8287 - val_loss: 0.0747 - val_accuracy: 1.0000\n","Epoch 225/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.6210 - accuracy: 0.8148 - val_loss: 0.1335 - val_accuracy: 1.0000\n","Epoch 226/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.5732 - accuracy: 0.7778 - val_loss: 0.1336 - val_accuracy: 0.9167\n","Epoch 227/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.5460 - accuracy: 0.8287 - val_loss: 0.1470 - val_accuracy: 0.9167\n","Epoch 228/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.5017 - accuracy: 0.7963 - val_loss: 0.1214 - val_accuracy: 0.9167\n","Epoch 229/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.5345 - accuracy: 0.7870 - val_loss: 0.1349 - val_accuracy: 0.9167\n","Epoch 230/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5969 - accuracy: 0.7593 - val_loss: 0.1032 - val_accuracy: 0.9583\n","Epoch 231/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.5857 - accuracy: 0.7639 - val_loss: 0.1277 - val_accuracy: 0.9583\n","Epoch 232/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5172 - accuracy: 0.7731 - val_loss: 0.2184 - val_accuracy: 0.8750\n","Epoch 233/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4040 - accuracy: 0.8241 - val_loss: 0.0622 - val_accuracy: 1.0000\n","Epoch 234/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.3638 - accuracy: 0.8519 - val_loss: 0.1113 - val_accuracy: 0.9167\n","Epoch 235/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4308 - accuracy: 0.8657 - val_loss: 0.2492 - val_accuracy: 0.8750\n","Epoch 236/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4648 - accuracy: 0.8333 - val_loss: 0.5211 - val_accuracy: 0.8333\n","Epoch 237/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4335 - accuracy: 0.8611 - val_loss: 0.3249 - val_accuracy: 0.8333\n","Epoch 238/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.5609 - accuracy: 0.7870 - val_loss: 0.3496 - val_accuracy: 0.8333\n","Epoch 239/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4755 - accuracy: 0.7963 - val_loss: 0.4243 - val_accuracy: 0.7917\n","Epoch 240/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.4431 - accuracy: 0.8333 - val_loss: 0.1030 - val_accuracy: 0.9583\n","Epoch 241/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.3905 - accuracy: 0.8519 - val_loss: 0.0524 - val_accuracy: 1.0000\n","Epoch 242/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.3254 - accuracy: 0.8565 - val_loss: 0.0673 - val_accuracy: 0.9583\n","Epoch 243/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.3406 - accuracy: 0.8704 - val_loss: 0.0591 - val_accuracy: 0.9583\n","Epoch 244/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4304 - accuracy: 0.8472 - val_loss: 0.0815 - val_accuracy: 0.9583\n","Epoch 245/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4543 - accuracy: 0.8148 - val_loss: 0.0851 - val_accuracy: 0.9583\n","Epoch 246/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.5202 - accuracy: 0.8102 - val_loss: 0.1337 - val_accuracy: 0.9583\n","Epoch 247/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3695 - accuracy: 0.8333 - val_loss: 0.1298 - val_accuracy: 0.9167\n","Epoch 248/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.3844 - accuracy: 0.8241 - val_loss: 0.0704 - val_accuracy: 0.9583\n","Epoch 249/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4227 - accuracy: 0.8472 - val_loss: 0.0835 - val_accuracy: 0.9583\n","Epoch 250/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.3651 - accuracy: 0.8380 - val_loss: 0.1451 - val_accuracy: 0.9583\n","Epoch 251/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.3109 - accuracy: 0.8657 - val_loss: 0.1519 - val_accuracy: 0.9583\n","Epoch 252/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3728 - accuracy: 0.8472 - val_loss: 0.2648 - val_accuracy: 0.8333\n","Epoch 253/300\n","7/7 [==============================] - 0s 56ms/step - loss: 0.3813 - accuracy: 0.8333 - val_loss: 0.4008 - val_accuracy: 0.9167\n","Epoch 254/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.3680 - accuracy: 0.8657 - val_loss: 0.1581 - val_accuracy: 0.8750\n","Epoch 255/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4220 - accuracy: 0.8426 - val_loss: 0.2548 - val_accuracy: 0.8750\n","Epoch 256/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3546 - accuracy: 0.8704 - val_loss: 0.2186 - val_accuracy: 0.9167\n","Epoch 257/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.3488 - accuracy: 0.8611 - val_loss: 0.2977 - val_accuracy: 0.8750\n","Epoch 258/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3794 - accuracy: 0.8380 - val_loss: 0.4801 - val_accuracy: 0.7917\n","Epoch 259/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.3802 - accuracy: 0.8519 - val_loss: 0.3967 - val_accuracy: 0.8333\n","Epoch 260/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.4117 - accuracy: 0.8611 - val_loss: 0.3128 - val_accuracy: 0.8750\n","Epoch 261/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4432 - accuracy: 0.8380 - val_loss: 0.5231 - val_accuracy: 0.7917\n","Epoch 262/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.3208 - accuracy: 0.8704 - val_loss: 0.3832 - val_accuracy: 0.8750\n","Epoch 263/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.3725 - accuracy: 0.8657 - val_loss: 0.3155 - val_accuracy: 0.8750\n","Epoch 264/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4102 - accuracy: 0.8472 - val_loss: 0.3973 - val_accuracy: 0.8333\n","Epoch 265/300\n","7/7 [==============================] - 0s 62ms/step - loss: 0.3378 - accuracy: 0.8472 - val_loss: 0.3372 - val_accuracy: 0.9167\n","Epoch 266/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.4118 - accuracy: 0.8287 - val_loss: 0.4716 - val_accuracy: 0.7917\n","Epoch 267/300\n","7/7 [==============================] - 0s 62ms/step - loss: 0.3843 - accuracy: 0.8750 - val_loss: 0.1443 - val_accuracy: 0.9583\n","Epoch 268/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.3976 - accuracy: 0.8426 - val_loss: 0.2513 - val_accuracy: 0.8333\n","Epoch 269/300\n","7/7 [==============================] - 0s 64ms/step - loss: 0.4476 - accuracy: 0.8287 - val_loss: 0.3578 - val_accuracy: 0.7917\n","Epoch 270/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4697 - accuracy: 0.8241 - val_loss: 0.7600 - val_accuracy: 0.7917\n","Epoch 271/300\n","7/7 [==============================] - 0s 67ms/step - loss: 0.4409 - accuracy: 0.8380 - val_loss: 0.4419 - val_accuracy: 0.7917\n","Epoch 272/300\n","7/7 [==============================] - 0s 64ms/step - loss: 0.3535 - accuracy: 0.8333 - val_loss: 0.1493 - val_accuracy: 0.8750\n","Epoch 273/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4058 - accuracy: 0.8241 - val_loss: 0.1115 - val_accuracy: 0.9167\n","Epoch 274/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4335 - accuracy: 0.8472 - val_loss: 0.1855 - val_accuracy: 0.9167\n","Epoch 275/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.4804 - accuracy: 0.8380 - val_loss: 0.0449 - val_accuracy: 1.0000\n","Epoch 276/300\n","7/7 [==============================] - 0s 64ms/step - loss: 0.5765 - accuracy: 0.8009 - val_loss: 0.2300 - val_accuracy: 0.8750\n","Epoch 277/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4078 - accuracy: 0.8426 - val_loss: 0.7318 - val_accuracy: 0.8750\n","Epoch 278/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.4360 - accuracy: 0.8426 - val_loss: 0.5502 - val_accuracy: 0.8333\n","Epoch 279/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3931 - accuracy: 0.8287 - val_loss: 0.0880 - val_accuracy: 1.0000\n","Epoch 280/300\n","7/7 [==============================] - 0s 57ms/step - loss: 0.4118 - accuracy: 0.8333 - val_loss: 0.2753 - val_accuracy: 0.8750\n","Epoch 281/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.4635 - accuracy: 0.8241 - val_loss: 0.2633 - val_accuracy: 0.8750\n","Epoch 282/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3354 - accuracy: 0.8750 - val_loss: 0.1694 - val_accuracy: 0.9167\n","Epoch 283/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.4430 - accuracy: 0.8519 - val_loss: 0.2436 - val_accuracy: 0.9583\n","Epoch 284/300\n","7/7 [==============================] - 0s 61ms/step - loss: 0.3983 - accuracy: 0.8472 - val_loss: 0.1865 - val_accuracy: 0.9167\n","Epoch 285/300\n","7/7 [==============================] - 0s 62ms/step - loss: 0.4411 - accuracy: 0.8333 - val_loss: 0.2153 - val_accuracy: 0.8750\n","Epoch 286/300\n","7/7 [==============================] - 0s 60ms/step - loss: 0.4430 - accuracy: 0.8380 - val_loss: 0.7737 - val_accuracy: 0.7500\n","Epoch 287/300\n","7/7 [==============================] - 0s 63ms/step - loss: 0.4390 - accuracy: 0.8472 - val_loss: 0.6901 - val_accuracy: 0.7917\n","Epoch 288/300\n","7/7 [==============================] - 0s 58ms/step - loss: 0.3889 - accuracy: 0.8472 - val_loss: 0.5188 - val_accuracy: 0.7500\n","Epoch 289/300\n","7/7 [==============================] - 0s 62ms/step - loss: 0.4079 - accuracy: 0.8472 - val_loss: 0.8588 - val_accuracy: 0.7500\n","Epoch 290/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4062 - accuracy: 0.8519 - val_loss: 0.2390 - val_accuracy: 0.9583\n","Epoch 291/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4637 - accuracy: 0.8241 - val_loss: 0.1137 - val_accuracy: 0.9583\n","Epoch 292/300\n","7/7 [==============================] - 0s 64ms/step - loss: 0.4033 - accuracy: 0.8287 - val_loss: 0.6428 - val_accuracy: 0.8333\n","Epoch 293/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3884 - accuracy: 0.8611 - val_loss: 0.4588 - val_accuracy: 0.8333\n","Epoch 294/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3449 - accuracy: 0.8750 - val_loss: 0.4731 - val_accuracy: 0.7917\n","Epoch 295/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.3881 - accuracy: 0.8333 - val_loss: 0.1082 - val_accuracy: 0.9167\n","Epoch 296/300\n","7/7 [==============================] - 0s 62ms/step - loss: 0.4258 - accuracy: 0.8380 - val_loss: 0.2262 - val_accuracy: 0.8750\n","Epoch 297/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.4059 - accuracy: 0.8565 - val_loss: 0.1613 - val_accuracy: 0.9167\n","Epoch 298/300\n","7/7 [==============================] - 0s 64ms/step - loss: 0.3805 - accuracy: 0.8426 - val_loss: 0.0743 - val_accuracy: 0.9583\n","Epoch 299/300\n","7/7 [==============================] - 0s 59ms/step - loss: 0.5065 - accuracy: 0.8565 - val_loss: 0.1449 - val_accuracy: 0.9167\n","Epoch 300/300\n","7/7 [==============================] - 0s 62ms/step - loss: 0.4131 - accuracy: 0.8287 - val_loss: 0.1579 - val_accuracy: 0.9583\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n","WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\n",">Entrenamiento Finalizado.\n"]}]},{"cell_type":"code","source":[" #@title Mostrar Resumen de las Pruebas realizadas por AutoKeras\n"," print(AKmodel.tuner.results_summary())\n","\n","resEval = AKmodel.evaluate(x_test, (y_testEnc if tipo_output_softMax else y_test),)\n","print(\"\\n>Evaluación del Mejor Modelo con datos de Prueba: \")\n","print(\"    - Error: \", resEval[0])\n","print(\"    - Exactitud: \", resEval[1]*100)\n","print(\"\\n\")"],"metadata":{"cellView":"form","id":"EYSWCTEsN27U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674215795002,"user_tz":180,"elapsed":2596,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"d1d9a49b-6239-43b9-9e6c-9623a79e52d4"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Results summary\n","Results in ./auto_model\n","Showing 10 best trials\n","<keras_tuner.engine.objective.Objective object at 0x7f440a0aa310>\n","Trial summary\n","Hyperparameters:\n","image_block_1/image_augmentation_1/translation_factor: 0.1\n","image_block_1/image_augmentation_1/horizontal_flip: True\n","image_block_1/image_augmentation_1/vertical_flip: True\n","image_block_1/image_augmentation_1/rotation_factor: 0.0\n","image_block_1/image_augmentation_1/zoom_factor: 0.0\n","image_block_1/image_augmentation_1/contrast_factor: 0.0\n","image_block_1/conv_block_1/kernel_size: 3\n","image_block_1/conv_block_1/separable: False\n","image_block_1/conv_block_1/max_pooling: True\n","image_block_1/conv_block_1/num_blocks: 2\n","image_block_1/conv_block_1/num_layers: 2\n","image_block_1/conv_block_1/filters_0_0: 32\n","image_block_1/conv_block_1/filters_0_1: 32\n","image_block_1/conv_block_1/dropout: 0.0\n","image_block_1/conv_block_1/filters_1_0: 32\n","image_block_1/conv_block_1/filters_1_1: 32\n","classification_head_1/spatial_reduction_1/reduction_type: flatten\n","classification_head_1/dropout: 0\n","optimizer: adam\n","learning_rate: 0.01\n","Score: 1.0\n","Trial summary\n","Hyperparameters:\n","image_block_1/image_augmentation_1/translation_factor: 0.0\n","image_block_1/image_augmentation_1/horizontal_flip: True\n","image_block_1/image_augmentation_1/vertical_flip: True\n","image_block_1/image_augmentation_1/rotation_factor: 0.0\n","image_block_1/image_augmentation_1/zoom_factor: 0.0\n","image_block_1/image_augmentation_1/contrast_factor: 0.0\n","image_block_1/conv_block_1/kernel_size: 3\n","image_block_1/conv_block_1/separable: False\n","image_block_1/conv_block_1/max_pooling: True\n","image_block_1/conv_block_1/num_blocks: 2\n","image_block_1/conv_block_1/num_layers: 2\n","image_block_1/conv_block_1/filters_0_0: 32\n","image_block_1/conv_block_1/filters_0_1: 32\n","image_block_1/conv_block_1/dropout: 0.0\n","image_block_1/conv_block_1/filters_1_0: 32\n","image_block_1/conv_block_1/filters_1_1: 32\n","classification_head_1/spatial_reduction_1/reduction_type: flatten\n","classification_head_1/dropout: 0\n","optimizer: adam\n","learning_rate: 0.01\n","Score: 0.9583333134651184\n","Trial summary\n","Hyperparameters:\n","image_block_1/image_augmentation_1/translation_factor: 0.0\n","image_block_1/image_augmentation_1/horizontal_flip: True\n","image_block_1/image_augmentation_1/vertical_flip: True\n","image_block_1/image_augmentation_1/rotation_factor: 0.0\n","image_block_1/image_augmentation_1/zoom_factor: 0.0\n","image_block_1/image_augmentation_1/contrast_factor: 0.0\n","image_block_1/conv_block_1/kernel_size: 3\n","image_block_1/conv_block_1/separable: False\n","image_block_1/conv_block_1/max_pooling: True\n","image_block_1/conv_block_1/num_blocks: 2\n","image_block_1/conv_block_1/num_layers: 2\n","image_block_1/conv_block_1/filters_0_0: 32\n","image_block_1/conv_block_1/filters_0_1: 32\n","image_block_1/conv_block_1/dropout: 0.0\n","image_block_1/conv_block_1/filters_1_0: 32\n","image_block_1/conv_block_1/filters_1_1: 32\n","classification_head_1/spatial_reduction_1/reduction_type: flatten\n","classification_head_1/dropout: 0.0\n","optimizer: adam\n","learning_rate: 0.01\n","Score: 0.9583333134651184\n","Trial summary\n","Hyperparameters:\n","image_block_1/image_augmentation_1/translation_factor: 0.0\n","image_block_1/image_augmentation_1/horizontal_flip: True\n","image_block_1/image_augmentation_1/vertical_flip: True\n","image_block_1/image_augmentation_1/rotation_factor: 0.0\n","image_block_1/image_augmentation_1/zoom_factor: 0.0\n","image_block_1/image_augmentation_1/contrast_factor: 0.0\n","image_block_1/conv_block_1/kernel_size: 3\n","image_block_1/conv_block_1/separable: False\n","image_block_1/conv_block_1/max_pooling: True\n","image_block_1/conv_block_1/num_blocks: 2\n","image_block_1/conv_block_1/num_layers: 2\n","image_block_1/conv_block_1/filters_0_0: 32\n","image_block_1/conv_block_1/filters_0_1: 32\n","image_block_1/conv_block_1/dropout: 0.0\n","image_block_1/conv_block_1/filters_1_0: 32\n","image_block_1/conv_block_1/filters_1_1: 32\n","classification_head_1/spatial_reduction_1/reduction_type: global_avg\n","classification_head_1/dropout: 0.5\n","optimizer: adam\n","learning_rate: 0.01\n","Score: 0.9583333134651184\n","Trial summary\n","Hyperparameters:\n","image_block_1/image_augmentation_1/translation_factor: 0.0\n","image_block_1/image_augmentation_1/horizontal_flip: True\n","image_block_1/image_augmentation_1/vertical_flip: True\n","image_block_1/image_augmentation_1/rotation_factor: 0.0\n","image_block_1/image_augmentation_1/zoom_factor: 0.0\n","image_block_1/image_augmentation_1/contrast_factor: 0.0\n","image_block_1/conv_block_1/kernel_size: 3\n","image_block_1/conv_block_1/separable: False\n","image_block_1/conv_block_1/max_pooling: True\n","image_block_1/conv_block_1/num_blocks: 2\n","image_block_1/conv_block_1/num_layers: 2\n","image_block_1/conv_block_1/filters_0_0: 32\n","image_block_1/conv_block_1/filters_0_1: 32\n","image_block_1/conv_block_1/dropout: 0.25\n","image_block_1/conv_block_1/filters_1_0: 32\n","image_block_1/conv_block_1/filters_1_1: 32\n","classification_head_1/spatial_reduction_1/reduction_type: flatten\n","classification_head_1/dropout: 0\n","optimizer: adam\n","learning_rate: 0.01\n","Score: 0.9583333134651184\n","None\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"]},{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 13ms/step - loss: 0.3656 - accuracy: 0.8833\n","\n",">Evaluación del Mejor Modelo con datos de Prueba: \n","    - Error:  0.36564934253692627\n","    - Exactitud:  88.33333253860474\n","\n","\n"]}]},{"cell_type":"code","source":["#@title Exportar Modelo y Re-Entrenar (opcional)\n","\n","reentrenar_modelo = False #@param {type:\"boolean\"}\n","\n","cant_epocas_reentrenamiento =  500#@param {type:\"integer\"}\n","if cant_epocas_reentrenamiento <= 0:\n","  cant_epocas_reentrenamiento = None\n","\n","\n","# exporta el modelo y lo muestra\n","print(\"\\n>> Mejor modelo generado: \")\n","model = AKmodel.export_model()\n","model.summary()\n","print(\"\")\n","\n","if reentrenar_modelo: \n","  # realiza el re-entrenamiento del modelo\n","  print(\"\\n\\n>Comienza el Re-Entrenamiento:\")\n","  history = model.fit(x_t, y_t,\n","                        validation_data=(x_v, y_v,),\n","                        epochs=cant_epocas_reentrenamiento\n","                        )\n","  print(\"\\n>Re-Entrenamiento Finalizado.\")"],"metadata":{"cellView":"form","id":"zH6F8UnmN5si","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674215798204,"user_tz":180,"elapsed":3220,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"c82e0ff9-c671-4aa9-ad1e-ede38d75e8f0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n",">> Mejor modelo generado: \n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer-3._random_generator._generator._state_var\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer-4._random_generator._generator._state_var\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting Bitcast\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 24, 24, 3)]       0         \n","                                                                 \n"," cast_to_float32 (CastToFloa  (None, 24, 24, 3)        0         \n"," t32)                                                            \n","                                                                 \n"," normalization (Normalizatio  (None, 24, 24, 3)        7         \n"," n)                                                              \n","                                                                 \n"," random_translation (RandomT  (None, 24, 24, 3)        0         \n"," ranslation)                                                     \n","                                                                 \n"," random_flip (RandomFlip)    (None, 24, 24, 3)         0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 22, 22, 32)        896       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 20, 20, 32)        9248      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 10, 10, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 8, 8, 32)          9248      \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 6, 6, 32)          9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 3, 3, 32)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 288)               0         \n","                                                                 \n"," dense (Dense)               (None, 10)                2890      \n","                                                                 \n"," classification_head_1 (Soft  (None, 10)               0         \n"," max)                                                            \n","                                                                 \n","=================================================================\n","Total params: 31,537\n","Trainable params: 31,530\n","Non-trainable params: 7\n","_________________________________________________________________\n","\n"]}]},{"cell_type":"code","source":["#@title Probar red entrenada con datos de entrenamiento\n","mostrar_detalle_imagenes_entrenamiento = False #@param {type:\"boolean\"}\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo(x, y, esDAimag, clases_map, mostrarImagenes=False):\n","\n","    # procesa las imágenes de prueba con el modelo \n","    predClass = model.predict(x)\n","\n","    # muestra los resultados con las imágenes \n","    umbralClas = 0.5\n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # asigna el nombre de la clase real\n","        clReal = clases_map[ y[i] ] \n","\n","        # determina la clase predecida\n","        if tipo_output_softMax:\n","            ## determina clase predecida de acuerdo a la que tiene mayor valor\n","            idclPred = int( np.argmax(predClass[i], axis=0) )\n","            idclPredRnd = idclPred\n","        else:\n","            ## determina clase predecida de acuerdo al umbral de clasificación\n","            idclPred = predClass[i][0]       \n","            idclPredRnd = int(idclPred)\n","            if (idclPred - idclPredRnd)>0.5 and (idclPredRnd+1)<len(clases_map):\n","                    idclPredRnd = idclPredRnd + 1\n","\n","        # asigna el nombre de la clase predecida\n","        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n","            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA!\"\n","        else:      \n","            clPred = clases_map[ idclPredRnd ]\n","\n","        # agrega a vevtores auxiliares\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","\n","        # sólo muestra las imágenes no generadas por DA\n","        if mostrarImagenes:\n","          strTitulo = 'Real: ' + clReal + ' / RNA: ' \n","          strTitulo = strTitulo + clPred + ' (' + str( idclPred ) +')'    \n","\n","          # muestra comparación con la imagen\n","          fig = plt.figure()\n","          fig.suptitle( strTitulo )\n","          ax1 = fig.add_subplot(121)\n","          plot_image( x[i] )\n","          \n","          plt.tight_layout()\n","          fig = plt.gcf()\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds))\n","\n","    # muestra matriz de confusion\n","    print('\\n Matriz de Confusión ( real / modelo ): ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm, \n","        index=['r:{:}'.format(x) for x in clases_map], \n","        columns=['m:{:}'.format(x) for x in clases_map]\n","      )\n","    cmtx.sort_index(axis=0, inplace=True)\n","    cmtx.sort_index(axis=1, inplace=True)    \n","    print(cmtx)\n","    print(\"\\n\")\n","\n","    if mostrarImagenes:\n","      print(\"\\n>Resultados: \")\n","\n","\n","# prueba con los datos de prueba\n","print(\"*** Resultados con datos de Entrenamiento: \")\n","probarModelo(x_train, y_train, esDAimag_train, clases_map, mostrar_detalle_imagenes_entrenamiento)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"02ARxkaI_z_N","executionInfo":{"status":"ok","timestamp":1674215798731,"user_tz":180,"elapsed":542,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"84a4d41b-6974-4400-8212-ce3ae806beb2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["*** Resultados con datos de Entrenamiento: \n","8/8 [==============================] - 0s 11ms/step\n","\n"," Reporte de Clasificación: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98        24\n","           1       0.92      1.00      0.96        24\n","           2       1.00      0.96      0.98        24\n","           3       1.00      0.83      0.91        24\n","           4       0.96      0.96      0.96        24\n","           5       0.86      1.00      0.92        24\n","           6       0.83      0.62      0.71        24\n","           7       1.00      0.96      0.98        24\n","           8       0.96      1.00      0.98        24\n","           9       0.70      0.88      0.78        24\n","\n","    accuracy                           0.92       240\n","   macro avg       0.92      0.92      0.92       240\n","weighted avg       0.92      0.92      0.92       240\n","\n","\n"," Matriz de Confusión ( real / modelo ): \n","     m:0  m:1  m:2  m:3  m:4  m:5  m:6  m:7  m:8  m:9\n","r:0   23    0    0    0    0    0    0    0    0    1\n","r:1    0   24    0    0    0    0    0    0    0    0\n","r:2    0    0   23    0    0    1    0    0    0    0\n","r:3    0    0    0   20    0    2    1    0    1    0\n","r:4    0    1    0    0   23    0    0    0    0    0\n","r:5    0    0    0    0    0   24    0    0    0    0\n","r:6    0    0    0    0    0    1   15    0    0    8\n","r:7    0    1    0    0    0    0    0   23    0    0\n","r:8    0    0    0    0    0    0    0    0   24    0\n","r:9    0    0    0    0    1    0    2    0    0   21\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"A15K-9TRtq7U","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1674215798734,"user_tz":180,"elapsed":23,"user":{"displayName":"pgp tensorflow","userId":"04809512947468796788"}},"outputId":"a5c5c60e-8379-4bfa-a92d-111576d22d73"},"source":["#@title Probar red entrenada con datos de prueba\n","mostrar_detalle_imagenes_prueba = False #@param {type:\"boolean\"}\n"," \n"," # evalua al modelo entrenado\n","resEval = model.evaluate(x_test, (y_testEnc if tipo_output_softMax else y_test),)\n","print(\"\\n>Evaluación del Modelo: \")\n","print(\"    - Error: \", resEval[0])\n","print(\"    - Exactitud: \", resEval[1]*100)\n","print(\"\\n\")\n","\n","# prueba con los datos de entrenamiento\n","print(\"\\n\\n*** Resultados con datos de Prueba: \")\n","probarModelo(x_test, y_test, esDAimag_test, clases_map, mostrar_detalle_imagenes_prueba)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8833\n","\n",">Evaluación del Modelo: \n","    - Error:  0.36564934253692627\n","    - Exactitud:  88.33333253860474\n","\n","\n","\n","\n","*** Resultados con datos de Prueba: \n","2/2 [==============================] - 0s 15ms/step\n","\n"," Reporte de Clasificación: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         6\n","           1       1.00      0.67      0.80         6\n","           2       1.00      1.00      1.00         6\n","           3       1.00      1.00      1.00         6\n","           4       1.00      1.00      1.00         6\n","           5       1.00      1.00      1.00         6\n","           6       0.75      0.50      0.60         6\n","           7       0.86      1.00      0.92         6\n","           8       0.75      1.00      0.86         6\n","           9       0.57      0.67      0.62         6\n","\n","    accuracy                           0.88        60\n","   macro avg       0.89      0.88      0.88        60\n","weighted avg       0.89      0.88      0.88        60\n","\n","\n"," Matriz de Confusión ( real / modelo ): \n","     m:0  m:1  m:2  m:3  m:4  m:5  m:6  m:7  m:8  m:9\n","r:0    6    0    0    0    0    0    0    0    0    0\n","r:1    0    4    0    0    0    0    0    1    1    0\n","r:2    0    0    6    0    0    0    0    0    0    0\n","r:3    0    0    0    6    0    0    0    0    0    0\n","r:4    0    0    0    0    6    0    0    0    0    0\n","r:5    0    0    0    0    0    6    0    0    0    0\n","r:6    0    0    0    0    0    0    3    0    0    3\n","r:7    0    0    0    0    0    0    0    6    0    0\n","r:8    0    0    0    0    0    0    0    0    6    0\n","r:9    0    0    0    0    0    0    1    0    1    4\n","\n","\n"]}]}]}