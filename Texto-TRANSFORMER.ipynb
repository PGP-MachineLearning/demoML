{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"2OvlxnFIsNyT"},"source":["# Demo redes Transformers (o LLM) para clasificar (atributo clase discreto), estimar (atributo clase continuo)  o generar (atributo clase texto) usando como entrada Texto\n","Basado en \n","\n","https://keras.io/guides/functional_api/ \n","\n","https://keras.io/examples/generative/text_generation_with_miniature_gpt/\n","\n","https://keras.io/examples/nlp/text_classification_with_transformer/\n","\n","\n","Nota: la fuente de datos para datos <FilmAffinity.csv> es https://www.kaggle.com/code/ricardomoya/an-lisis-de-sentimientos-clasificaci-n-de-textos/data pero se corrigieron unos detalles que tenía."]},{"cell_type":"code","metadata":{"id":"gcVLfyLKsaCj","cellView":"form"},"source":["#@title Librerías a usar\n","from tensorflow import keras\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import plot_model\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import math\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","import ipywidgets as widgets\n","from ipywidgets import Box, Layout\n","from IPython.display import clear_output\n","\n","import unicodedata\n","import copy\n","import random\n","import os\n","import csv\n","\n","print(\"Librerías cargadas\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6joPlYF2RWdW","cellView":"form"},"source":["#@title Acceder al Drive\n","\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# directorio local en Google Drive\n","path = '/content/gdrive/My Drive/IA/demoML/texto/'  #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHvuVOLpRdSy","cellView":"form"},"source":["#@title Cargar datos\n","\n","#@markdown ### Archivo de datos a utilizar:\n","archivo_datos = 'FilmAffinity.csv'  #@param {type:\"string\"}\n","#@markdown ### Configuración del archivo CSV:\n","delimitador_columnas = '\\\\|\\\\|' #@param {type:\"string\"}\n","\n","## selección de los parámetros \n","\n","\n","def checkValidCharacter(str):\n","  if len(str) == 0:\n","    return False  \n","  for ch in str:\n","    # controla cada caracter\n","    if (ch != \"\\n\") and \\\n","       (unicodedata.category(ch) in {'Cc', 'Cf', 'Cn', 'Co', 'Cs'}):\n","      return False\n","    # nota: ver categorias en https://www.fileformat.info/info/unicode/category/index.htm\n","  return True    \n","\n","def limpiarTexto(texto_ori):\n","  auxList = []\n","  t = list( texto_ori.strip() )\n","  for c in t:\n","    if checkValidCharacter(c):\n","      auxList.append( c )\n","  return \"\".join(auxList)\n","\n","\n","# función para cargar configuración datos automática\n","def cargarNombreClases(path, archivo_datos):\n","  # importa definición de la clase\n","  arClasesFN = archivo_datos.split('.')[0] + '_nombreClases.txt'\n","  if os.path.isfile( path + '/' + arClasesFN ):\n","    with open( path + '/' + arClasesFN, mode='r') as csvfile:\n","        r = csv.reader(csvfile, delimiter=',')\n","        auxAtributo = r.__next__()\n","        auxClases = r.__next__()\n","    print('\\n> Definición de los valores discretos para la clase cargada de ' + arClasesFN +'.\\n')\n","    return auxAtributo[0], ','.join(auxClases)\n","  else:\n","    return \"\", \"\"\n","\n","\n","# configura para que muestre todas las columnas y filas\n","pd.options.display.max_rows = 100\n","pd.options.display.max_columns = 100\n","\n","# inicializa valores\n","Xori = None\n","X = None\n","Y = None\n","nombre_atributos_entrada = []\n","texto_cargado = None\n","\n","# determina tipo de archivo a usar (si es de Texto o Datos)\n","if \".csv\" in archivo_datos.lower():\n","    # se condidera un archivo de datos\n","    esArchivoDatos = True\n","\n","    # función auxiliara para que no ejecute UI cada vez\n","    def hacerNada():\n","      return\n","\n","    # se define esta función para que se ocupe de aplicar la configuración\n","    def on_buttonAplicar_clicked(b):  \n","      print(\"\")\n","      funcionCambiaSeleccion_ConfigDatos(combo_att_clase.value, texto_nomClases.value, combo_att_entrada.value)\n","\n","    # aplica configuración de datos\n","    def funcionCambiaSeleccion_ConfigDatos(attClase, nomClases, att_entrada):\n","      global Y, Xori, nombre_clases, nombre_atributos_entrada\n","\n","      if (attClase is None) or (attClase ==\"\") or\\\n","        (att_entrada is None) or (att_entrada ==\"\"):\n","        return\n","      \n","      # si el atributo clase está como de entrada, lo saca (no tiene sentido)\n","      att_entrada = list(att_entrada)\n","      if attClase in att_entrada:\n","        print(\"Eliminando atributo \" + attClase + \" como de entrada dado que es clase.\")\n","        att_entrada.remove( attClase )\n","\n","      if (att_entrada == \"\") or (len(att_entrada)==0):\n","        print(\"No se han definido atributos de entrada!\")\n","        return\n","\n","      # guarda configuración\n","      nombre_clases = nomClases\n","      nombre_atributos_entrada = att_entrada\n","\n","        # genera los datos solo con los atributos seleccionados\n","      Y = np.array(df[attClase])\n","      Xori = np.array(df[att_entrada])\n","      \n","      # muestra resultados\n","      print(\"\\n> Atributos entrada: \", att_entrada)\n","      print(\"\\t X: \", Xori.shape)\n","      \n","      if (nombre_clases is None) or (nombre_clases==\"\"): \n","        print(\"\\n> Atributo clase: \", attClase)\n","      else:\n","        print(\"\\n> Atributo clase: \", attClase, \" [\", nombre_clases, \"]\")\n","      print(\"\\t Y: \", Y.shape)\n","\n","    ## aplicación de los parámetros elegidos\n","\n","    # Carga los datos del CSV y muestra los primeros\n","    df = pd.read_csv(path + archivo_datos,  sep=delimitador_columnas, engine=\"python\")\n","    print(\"Archivo de datos \", archivo_datos, \" cargado\")\n","\n","    print(\"\\n> Cabecera: \")\n","    print(df.head())\n","    print(\"\\n> Características: \")\n","    print(df.describe())\n","    print(\"\\n\")\n","\n","    # intenta cargar configuración asociada a los datos\n","    # trata de obtener la configuración del archivo asociado\n","    atributo_clase, nombre_clases = cargarNombreClases(path, archivo_datos)\n","\n","    # muestra interface para cargar configuración\n","\n","    # auxiliar para que muestre bien la descripción\n","    style_3D = {'description_width': 'initial'}\n","\n","    tit = widgets.Label(\"Ajuste para configuración de los Datos: \")\n","        \n","    # prepara combo para determinar atributo clase\n","    selecc_atributos = [ ]\n","    selecc_atributos.extend( df.columns.values.tolist() )\n","    if (atributo_clase is None) or (atributo_clase==\"\") or (atributo_clase not in selecc_atributos):\n","      att_selecc_defecto = 0\n","    else:\n","      att_selecc_defecto = selecc_atributos.index(atributo_clase)\n","    combo_att_clase = widgets.Dropdown(\n","        options = selecc_atributos,\n","        value = selecc_atributos[att_selecc_defecto], # mostrar por defecto de config\n","        description = 'Atributo clase:',\n","        style=style_3D,\n","        disabled = False,\n","    )\n","    # prepara campo para ingresar nombre clases (toma por defecto de config)\n","    texto_nomClases = widgets.Text(\n","        value=nombre_clases,\n","        placeholder='Ingrese nombre clases (si corresponde) separados por comas',\n","        description='Nombre clases:',\n","        style=style_3D,\n","        disabled=False\n","    )\n","\n","    combo_att_entrada = widgets.SelectMultiple(\n","        options=selecc_atributos,\n","        value=selecc_atributos,\n","        #rows=10,\n","        description='Atributos de entrada:',\n","        style=style_3D,\n","        disabled=False\n","    )\n","\n","    # prepara botón y grilla con objetos\n","    btnAplicar = widgets.Button(\n","        description='Aplicar'\n","    )\n","    configDatos_ui = widgets.GridBox(\n","          children=[tit, combo_att_clase, texto_nomClases, combo_att_entrada, btnAplicar],\n","          layout=Layout(width='100%')  )\n","    btnAplicar.on_click(on_buttonAplicar_clicked)\n","\n","    # clear_output()  \n","    out_config = widgets.interactive_output(hacerNada, {})  \n","    display(configDatos_ui)\n","\n","    # ejecuta para que muestre\n","    on_buttonAplicar_clicked(btnAplicar)\n","\n","else:\n","    # se condidera un archivo de texto\n","    esArchivoDatos = False\n","    \n","    X = None\n","    Y = None\n","\n","    # levanta el archivo de texto del Drive para procesar\n","    texto_cargado = open(\"\".join(path + archivo_datos), 'rb').read().decode(encoding='utf-8', errors='ignore')\n","    print(\"Archivo de texto \", archivo_datos, \" cargado\")\n","\n","    # saca caracteres en blanco al principio y fin\n","    # y caracteres de control especiales\n","    print(\"> Se limpian caracteres especiales de control\")\n","    texto_cargado = limpiarTexto(texto_cargado)\n","\n","    print(\"\\n> Características: \")\n","    print (' -- Tamaño total del texto: {} caracteres'.format(len(texto_cargado)))\n","\n","    # muestra los primeros 250 caracteres del texto\n","    print(\"\\n -- Ejemplo: \\n\", texto_cargado[:250])"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Generar datos de entrada como Texto\n","\n","incluir_nombre_atributos = False #@param {type:\"boolean\"}\n","marcar_separador_atributos = \"xATx \" #@param {type:\"string\"}\n","\n","if esArchivoDatos:\n","    # para archivo de datos\n","    if Xori is None:\n","      raise(Exception(\"Falta definir configuración de la carga de datos!\"))\n","\n","    print(\"> Uniendo atributos X en campo de texto de Datos: \")\n","\n","    print(\"\\n Datos X originales: \", Xori.shape)\n","    print(Xori[:3])\n","\n","    X = []\n","    for xEj in Xori:\n","      auxX = \"\"\n","      for atEj, nomAt in zip(xEj, nombre_atributos_entrada):\n","        if (auxX != \"\"):\n","          auxX = auxX + \" \" + marcar_separador_atributos\n","        if incluir_nombre_atributos:\n","          auxX = auxX + nomAt + \" \"\n","        auxX = auxX + str(atEj)\n","      X.append( limpiarTexto(auxX) )\n","    X = np.array( X )\n","    print(\"\\n Nuevo X: \", X.shape)\n","    print(X[:3])\n","\n","else:\n","    # para archivo de texto\n","    print(\"No se necesita ejecutar porque se usa archivo de texto.\")"],"metadata":{"cellView":"form","id":"L1VUfIvCLXX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Preparar datos \n","\n","#@markdown Determina si el atributo clase debe ser considerado como Discreto o Continuo\n","considerar_atributo_clase = \"dicreto - CLASIFICACION\" #@param [\"dicreto - CLASIFICACION\", \"continuo - ESTIMACION\", \"texto - GENERACION\"] \n","\n","#@markdown Porcentaje de datos para usar en el entrenamiento:\n","proporcion_porcentaje_datos_entrenamiento =   75#@param {type:\"integer\"}\n","\n","# inicializa\n","x_train, x_test, y_train, y_test = None, None, None, None\n","\n","if esArchivoDatos:\n","    # para archivo de datos\n","\n","    if X is None or Y is None:\n","      raise(Exception(\"Falta definir configuración de la carga de datos!\"))\n","\n","    # determina la proporción a usar para entrenar y probar\n","    if proporcion_porcentaje_datos_entrenamiento>100:\n","      propTrain = 1\n","    elif proporcion_porcentaje_datos_entrenamiento<1:\n","      propTrain = 0.1\n","    else:\n","      propTrain = proporcion_porcentaje_datos_entrenamiento/100\n","\n","    # determina si es problema de clasificación o estimación o generación de texto\n","    if (considerar_atributo_clase[0].upper() == \"T\"):\n","      # generación de texto\n","      tipoProblemaAplicar = \"T\"\n","    elif (considerar_atributo_clase[0].upper() == \"D\"):\n","      # clasificación\n","      tipoProblemaAplicar = \"C\"\n","    else:\n","      # estimación\n","      tipoProblemaAplicar = \"E\"\n","\n","    # separa al azar usando muestreo con proporción indicada\n","    if (tipoProblemaAplicar == \"C\"):\n","      # intenta hacer muestreo estatificado \n","      try:\n","        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain), stratify=Y)\n","      except ValueError:\n","        print(\"-- No se puede aplicar Muestreo Estratificado! -> se usa Muestreo Simple \\n\")\n","        # hace muestreo simple\n","        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain))\n","    else:\n","      # hace muestreo simple\n","      x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=(1-propTrain))\n","\n","    # inicializa\n","    y_trainEnc = []\n","    y_testEnc =  []\n","\n","    CLASES = []\n","    if (tipoProblemaAplicar == \"C\"):\n","      print(\"> se considera problema de CLASIFICACIÓN \\n\")\n","\n","      # define nombre de clases     \n","      if (nombre_clases == \"\") or (nombre_clases == \"-\"):\n","          # toma los valores de clase orginales del archivo\n","          print(Y[0])\n","          if str(Y[0]).replace(\".\",\"\").isnumeric():\n","            # Y son numeros\n","            for val in range(int(np.max(Y))+1):\n","              CLASES.append( \"clase {:>3}\".format(val) )\n","          else:\n","              # Y no son números          \n","              CLASES = list(set(Y))\n","              CLASES.sort()          \n","              # cambia valores para que sean enteros\n","              y_train = [ CLASES.index(y) for y in y_train]\n","              y_test = [ CLASES.index(y) for y in y_test]\n","      else:\n","          # toma configuración de nombre de clases\n","          for val in nombre_clases.split(','):\n","            CLASES.append( val )\n","\n","      # genera salida codificada para softMax\n","      y_trainEnc =  np_utils.to_categorical(y_train)\n","      y_testEnc =  np_utils.to_categorical(y_test)\n","\n","      # muestra resultados\n","      print(\"> Definición de CLASES: \")\n","      print(\" - dictMapeo (\", len(CLASES), \"): \", CLASES)\n","\n","    elif (tipoProblemaAplicar == \"T\"):\n","      print(\"> se considera problema de GENERACIÓN DE TEXTO \\n\")\n","\n","    else: # (tipoProblemaAplicar == \"E\"):\n","      print(\"> se considera problema de ESTIMACIÓN \\n\") \n","\n","    print(\"\\n> Para Entrenamiento: \")\n","    print(\" - x_train (cant): \", x_train.shape)\n","    print(\" - y_train (cant): \", len(y_train))\n","    if (tipoProblemaAplicar == \"C\"):\n","      for i in range(len(CLASES)):\n","        cant = 0\n","        for y in y_train:\n","          if i == int(y): cant = cant + 1\n","        print(\"    \", CLASES[i], \"[\", i, \"]:\", cant)\n","\n","    print(\"\\n Para Prueba: \")\n","    print(\" - x_test (cant): \", x_test.shape)\n","    print(\" - y_test (cant): \", len(y_test))\n","    if (tipoProblemaAplicar == \"C\"):\n","      for i in range(len(CLASES)):\n","        cant = 0\n","        for y in y_test:\n","          if i == int(y): cant = cant + 1\n","        print(\"    \", CLASES[i], \"[\", i, \"]:\", cant)\n","\n","else:\n","    # para archivo de texto\n","    tipoProblemaAplicar = \"T\"\n","    print(\"Al usar Archivo de Texto: \")\n","    print(\"-- se considera problema de GENERACIÓN DE TEXTO\")\n","    print(\"-- se utiliza el texto completo para entrenamiento\")\n","    print(\"-- se divide el texto completo usando saltos de líneas (\\\\n)\")\n","\n","    # se divide el texto usando salto de líneas\n","    y_train = texto_cargado.split(\"\\n\")\n","    print(\"\\n> Para Entrenamiento: \")\n","    print(\" - Frases (cant): \", len(y_train))\n","\n","    if len(y_train)>3:\n","      print(\"\\nEjemplos: \")\n","      for i in range(3):\n","        print(\"\\t\", y_train[i])\n","        "],"metadata":{"id":"bKTkkIYpJCYy","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Definir Encoding & Embeding del Texto\n","\n","#@markdown Parámetros para Encoding:\n","tipo_vocabuario = \"caracteres\" #@param [\"palabras\", \"caracteres\"]\n","tamaño_maximo_vocabulario = 5000 #@param {type:\"integer\"}\n","tamaño_maximo_frase_texto = 100 #@param {type:\"integer\"}\n","estandarizar_usar_todo_minusculas = True #@param {type:\"boolean\"}\n","estandarizar_sacar_puntuacion = True #@param {type:\"boolean\"}\n","\n","#@markdown Parámetros para Embeding:\n","tamaño_dimensiones_vectores = 64 #@param {type:\"integer\"}\n","\n","# función auxiliar para codificar texto\n","def codificarTexto(encoder, texto):\n","  return encoder(texto).numpy()\n","\n","def separarTexto(texto , separadorTokens):\n","  if separadorTokens==\"\":\n","    splitText = list(texto)\n","  else:\n","    splitText = texto.split(separadorTokens)\n","  return splitText\n","\n","# muestra texto codificado\n","def mostrarCodificarTexto(encoder, texto, separadorTokens=\" \"):\n","  textoCodif = codificarTexto(encoder, texto)\n","  print(\"Texto: \", texto)\n","  splitText = separarTexto(texto, separadorTokens)\n","  print(\"Vector[\" + str(len(splitText)) +  \"]: \", splitText)\n","  print(\"Codif[\" + str(len(textoCodif)) + \"]: \", textoCodif)\n","  return textoCodif\n","\n","# rellena vector con valores ceros\n","def rellenar_vector(vec, nshape):\n","  # hace una copia del vector\n","  aux = copy.deepcopy(vec)\n","  # le cambia el tamaño\n","  aux.resize(nshape, refcheck=False)\n","  # lo devuelve\n","  return aux\n","\n","# aplica configuración\n","if tamaño_maximo_vocabulario < 10:\n","  tamaño_maximo_vocabulario = 10\n","\n","if tamaño_maximo_frase_texto < 10:\n","  tamaño_maximo_frase_texto = 10\n","\n","if tamaño_dimensiones_vectores < 10:\n","  tamaño_dimensiones_vectores = 10\n","\n","if tipo_vocabuario == \"palabras\":\n","  split_type = \"whitespace\"\n","  separadorTokens = \" \"\n","elif tipo_vocabuario == \"caracteres\":\n","  split_type = \"character\"\n","  separadorTokens = \"\"\n","else:\n","  # no se usa porque no hace ninguna separación\n","  split_type = None \n","  separadorTokens = \"\"\n","\n","if estandarizar_usar_todo_minusculas and estandarizar_sacar_puntuacion:\n","  standardize_type = \"lower_and_strip_punctuation\"\n","elif estandarizar_usar_todo_minusculas:\n","  standardize_type = \"lower\"\n","elif estandarizar_sacar_puntuacion:\n","  standardize_type = \"strip_punctuation\"\n","else:\n","  standardize_type = None\n","\n","if esArchivoDatos:\n","    # para archivo de datos solamente\n","\n","    # prepara para manejar datos (usados por todos)\n","    print(\"\\n-- Crear Encoder para datos.\")\n","\n","    # crea codificador\n","    x_encoderLay = tf.keras.layers.TextVectorization(\n","        max_tokens = tamaño_maximo_vocabulario,\n","        standardize = standardize_type,\n","        split = split_type,\n","        output_sequence_length = tamaño_maximo_frase_texto,\n","        name = \"encoding-Data\")\n","\n","    # lo inicializa usando los textos de entrada para entrenamiento\n","    x_encoderLay.adapt(x_train)\n","\n","    # obtiene el vocabulario\n","    x_vocab = np.array(x_encoderLay.get_vocabulary())\n","    ##print( x_vocab[:20] )\n","\n","    # determina el tamaño del vocabulario\n","    x_vocab_size = len(x_vocab)\n","    print(\"\\t tamaño vocabulario de datos = \", x_vocab_size)\n","\n","\n","if (tipoProblemaAplicar == \"T\"):\n","\n","    # prepara para generación de texto (solo datos Y)\n","    # se usa con archivos de datos o de texto\n","\n","    # determina tags especiales (constantes) \n","    # notar que no se peuden usar símbolos especiales porque luego se filtran\n","    if tipo_vocabuario == \"palabras\":\n","        tag_gentext_begin = \"ästartä\"\n","        tag_gentext_end = \"üendü\"\n","    else: # tipo_vocabuario == \"caracter\":\n","        tag_gentext_begin = \"ä\"\n","        tag_gentext_end = \"ü\"\n","\n","    # crea codificador\n","    print(\"\\n-- Crear Encoder para texto.\")\n","    y_encoderLay = tf.keras.layers.TextVectorization(\n","        max_tokens = tamaño_maximo_vocabulario,\n","        standardize = standardize_type,\n","        split = split_type,        \n","        output_mode = \"int\",\n","        output_sequence_length = tamaño_maximo_frase_texto,\n","        name = \"encoding-Text\")\n","    \n","    # lo inicializa usando los textos de entrada y salida para entrenamiento\n","    auxYcompleto = [tag_gentext_begin, tag_gentext_end]\n","    auxYcompleto.extend( y_train )\n","    if esArchivoDatos:\n","        # para archivo de datos                \n","        auxYcompleto.extend( y_test )    \n","    y_encoderLay.adapt( auxYcompleto )\n","\n","    # obtiene el vocabulario\n","    y_vocab = np.array(y_encoderLay.get_vocabulary())\n","    ##print( y_vocab[:20] )\n","\n","    # determina el tamaño del vocabulario\n","    y_vocab_size = len( y_vocab )\n","    print(\"\\t tamaño vocabulario de texto = \", y_vocab_size)\n","\n","    # determina codificación de tags\n","    codif_gentext_begin = y_encoderLay(tag_gentext_begin).numpy()[0]\n","    codif_gentext_end = y_encoderLay(tag_gentext_end).numpy()[0]\n","    print(\"\\n-- Tags especiales: \")\n","    print(\"\\t comienzo = \" + tag_gentext_begin + \" (\" + str(codif_gentext_begin) + \")\")\n","    print(\"\\t fin = \" + tag_gentext_end + \" (\" + str(codif_gentext_end) + \")\")\n","\n","    if esArchivoDatos:\n","        # para archivo de datos   \n","        print(\"\\n-- Preparando múltiples entradas y salida para generar texto.\")\n","    else:\n","        # para archivo de texto   \n","        print(\"\\n-- Preparando entrada y salida para generar texto.\")\n","\n","    inputs_x_train = [] # entrada para datos\n","    inputs_prevText_train = [] # entrada para texto previo (o begin)\n","    y_trainEnc = [] # salida de texto (un elemento por vez)\n","    for i in range(len(y_train)):\n","      if esArchivoDatos:\n","          # determina los datos \n","          x = x_train[i]\n","      # determina texto\n","      y = y_train[i]\n","      # si la salida está definida\n","      if len(y) > 1:\n","        # codifica la salida (le agrega los tags para marcar comienzo y fin)\n","        yCodif = codificarTexto(y_encoderLay, \" \".join([tag_gentext_begin, y, tag_gentext_end]) )\n","        yCodifShape = yCodif.shape \n","        # va tomando por partes\n","        if esArchivoDatos:\n","          # como tiene datos complementarios, puede arrancar con el tag_gentext_begin\n","          jIni = 1\n","        else:\n","          # como no tiene datos complementarios, debe tener además de tag_gentext_begin alguna palabra\n","          # sino no sabe como arrancar\n","          jIni = 2\n","        for j in range(jIni, len(yCodif)):\n","            if esArchivoDatos:\n","              # determina entrada de datos (copiada igual por cada una de texto previo)\n","              inputs_x_train.append( x )\n","            # determina entrada de texto previo (competa con ceros para tener largo fijo)        \n","            inputs_prevText_train.append( rellenar_vector(yCodif[:j], yCodifShape) )\n","            # determina salida texto (un lemento)\n","            y_trainEnc.append( yCodif[j] )       \n","            # si llego al tag de END, termina\n","            if (yCodif[j] == codif_gentext_end) or (yCodif[j] == tag_gentext_end):\n","              break\n","        \n","    # convierte a arrays\n","    if esArchivoDatos:\n","        inputs_x_train = np.array( inputs_x_train )\n","    inputs_prevText_train = np.array( inputs_prevText_train )\n","    y_trainEnc = np.array( y_trainEnc ) \n","\n","    # muestra formas\n","    if esArchivoDatos:\n","        print(\"\\tinputs_x_train: \", inputs_x_train.shape)\n","    print(\"\\tinputs_prevText_train: \", inputs_prevText_train.shape)\n","    print(\"\\ty_trainEnc: \", y_trainEnc.shape)    \n","\n","    print(\"\\n> Ejemplos de codificación: \\n\")\n","    for _ in range(3):\n","      posAzar = random.randint(1, len(inputs_prevText_train)) - 1\n","      if esArchivoDatos:\n","          print(\"-INPUT DATOS: \")\n","          mostrarCodificarTexto(x_encoderLay,  inputs_x_train[posAzar], separadorTokens)\n","      auxT = \"\"\n","      auxV = inputs_prevText_train[posAzar]\n","      for v in auxV:\n","        auxT = auxT + separadorTokens + y_vocab[v]\n","      print(\"-INPUT TEXTO: \", auxT, \" \\n--> \",  inputs_prevText_train[posAzar] )        \n","      auxV = y_trainEnc[posAzar] \n","      print(\"-OUTPUT:      \", y_vocab[auxV], \" --> [\", auxV, \"]\")\n","      print(\"\")\n","\n","else:\n","    # muesta ejemplos sólo datos\n","    print(\"\\n> Ejemplos de codificación: \\n\")\n","    for _ in range(3):\n","      posAzar = random.randint(1, len(x_train)) - 1\n","      mostrarCodificarTexto(x_encoderLay,  x_train[posAzar], separadorTokens)\n","      print(\"\")\n","  "],"metadata":{"cellView":"form","id":"XNWJtTUXWo2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Establecer modelo Transfomer tipo miniGPT \n","\n","#@markdown ### Parámetros para capas Transfotmer:\n","# cantidad de transformers block\n","trnsf_cant_bloques = 2 #@param {type: \"integer\"}\n","# Hidden layer size in feed forward network inside transformer\n","trnsf_MultiHeadAttention_head_size = 256 #@param {type: \"integer\"}\n","# Number of attention heads\n","trnsf_MultiHeadAttention_num_heads = 4 #@param {type: \"integer\"}\n","trnsf_porc_capa_DropOut = 0.1 #@param {type:\"number\"}\n","\n","\n","#@markdown ### Parámetros de las capas Lineales:\n","lineal_cant_neuronas_capas_ocultas = '128, D,  64' #@param {type:\"string\"}\n","lineal_porc_capa_DropOut = 0.4 #@param {type:\"number\"}\n","\n","#@markdown ### Parámetros de la capa de Salida:\n","red_tipo_capa_salida = 'softmax-MultiClase' #@param [\"lineal-Numero\", \"softmax-MultiClase\"]\n","\n","#@markdown ### Parámetros del Optimizador:\n","opt_tipo = \"Adam\" #@param [\"Gradiente Decreciente\", \"Adam\", \"Adadelta\", \"Adagrad\", \"Adamax\", \"Nadam\", \"FTRL\"]\n","opt_learning_rate = 0.001 #@param {type: \"number\"}\n","\n","# aplica parámetros\n","\n","if trnsf_MultiHeadAttention_head_size < 1:\n","  trnsf_MultiHeadAttention_head_size = 1\n","\n","if trnsf_MultiHeadAttention_num_heads < 1:\n","  trnsf_MultiHeadAttention_num_heads = 1\n","\n","if trnsf_cant_bloques < 1:\n","  trnsf_cant_bloques = 1\n","\n","# chequea configuración de drop out\n","if trnsf_porc_capa_DropOut <= 0:\n","  trnsf_porc_capa_DropOut = 0.10\n","elif trnsf_porc_capa_DropOut > 0.9:\n","    trnsf_porc_capa_DropOut = 0.9\n","\n","# cantidad de neuronas ocultas \n","hidden_layers = []\n","for val in lineal_cant_neuronas_capas_ocultas.split(','):\n","  val = val.strip()\n","  if val == \"D\":\n","    hidden_layers.append( \"DropOut\" )  \n","  elif val == \"BN\":\n","    hidden_layers.append( \"BatchNormalization\" )  \n","  elif val.isnumeric():\n","    hidden_layers.append( val )\n","  else:\n","    print(\"Capa \", val, \"descartada!\")\n","\n","# define si el tipo de capa de salida es softmax( True )  o lineal ( False )\n","# esto implica también cambiar cómo se codifican los valores de las clases a usar\n","if (tipoProblemaAplicar == \"C\"):\n","  tipo_output_softMax = (red_tipo_capa_salida[:7] == 'softmax')\n","else:  \n","  tipo_output_softMax = False\n","\n","if opt_tipo == \"Gradiente Decreciente\":\n","  opt = keras.optimizers.SGD(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adam\":\n","  opt = keras.optimizers.Adam(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adadelta\":\n","  opt = keras.optimizers.Adadelta(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adagrad\":\n","  opt = keras.optimizers.Adagrad(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Adamax\":\n","  opt = keras.optimizers.Adamax(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"Nadam\":\n","  opt = keras.optimizers.Nadam(learning_rate=opt_learning_rate)\n","elif opt_tipo == \"FTRL\":\n","  opt = keras.optimizers.Ftrl(learning_rate=opt_learning_rate)\n","else:\n","  opt = keras.optimizers.Ad\n","\n","# funciones auxiliares para definir modelo GPT\n","def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n","    \"\"\"\n","    Mask the upper half of the dot product matrix in self attention.\n","    This prevents flow of information from future tokens to current token.\n","    1's in the lower triangle, counting from the lower right corner.\n","    \"\"\"\n","    i = tf.range(n_dest)[:, None]\n","    j = tf.range(n_src)\n","    m = i >= j - n_src + n_dest\n","    mask = tf.cast(m, dtype)\n","    mask = tf.reshape(mask, [1, n_dest, n_src])\n","    mult = tf.concat(\n","        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n","    )\n","    return tf.tile(mask, mult)\n","\n","class TransformerBlock(tf.keras.layers.Layer):\n","    def __init__(self, embed_dim, num_heads, feed_forward_dim, dp_rate=0.1, nameCust=None):\n","        if nameCust is None:\n","          super().__init__()\n","        else:\n","          super().__init__(name=nameCust,)\n","        self.att = tf.keras.layers.MultiHeadAttention(num_heads, embed_dim)\n","        self.ffn = keras.Sequential(\n","            [tf.keras.layers.Dense(feed_forward_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = tf.keras.layers.Dropout(dp_rate)\n","        self.dropout2 = tf.keras.layers.Dropout(dp_rate)\n","\n","    def call(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size = input_shape[0]\n","        seq_len = input_shape[1]\n","        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n","        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n","        attention_output = self.dropout1(attention_output)\n","        out1 = self.layernorm1(inputs + attention_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, maxlen, vocab_size, embed_dim, nameCust=None):\n","        super().__init__(trainable=True, name=nameCust, dtype=None, dynamic=False,)\n","        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","    def call(self, x):\n","        maxlen = tf.shape(x)[-1]\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions\n","\n","# variable auxiliar para transformer block\n","aux_trnsf_tamaño_dimensiones_vectores = 0\n","\n","# define la arquitectura de capas teniendo en cuenta la definición dada anteriomente\n","if esArchivoDatos:\n","  # para archivo de datos\n","\n","  # agrega capas de entrada y encoding  para datos de entrada  \n","  x_inputLay = tf.keras.layers.Input(dtype=tf.string, shape=(1,), name=\"input-Data\")\n","  eachLay = x_encoderLay(x_inputLay)\n","\n","  # crea capa para embedding\n","  # que convierte las secuencias de índices codficadas\n","  # en secuencias de vectores usados para entrenar\n","  embedding_layer = TokenAndPositionEmbedding(maxlen=tamaño_maximo_frase_texto, \n","                                              vocab_size=x_vocab_size, \n","                                              embed_dim=tamaño_dimensiones_vectores,\n","                                              nameCust=\"Tnsf-embedding-Data\")\n","  eachLay = embedding_layer(eachLay)\n","  aux_trnsf_tamaño_dimensiones_vectores = aux_trnsf_tamaño_dimensiones_vectores + tamaño_dimensiones_vectores\n","\n","\n","if (tipoProblemaAplicar == \"T\"):\n","  # para archivo de datos o texto\n","  \n","  # agrega capas entrada y encoding  para generación de texto  \n","  ####y_inputLay = tf.keras.layers.Input(dtype=tf.string, shape=(1,), name=\"input-Text\")\n","  ####eachLay_text = y_encoderLay(y_inputLay)\n","\n","  y_inputLay = tf.keras.layers.Input(shape=inputs_prevText_train[0].shape, name=\"input-prevText\")\n","  eachLay_text = y_inputLay\n","\n","  # crea capa para embedding\n","  # que convierte las secuencias de índices codficadas\n","  # en secuencias de vectores usados para entrenar\n","  embedding_layer = TokenAndPositionEmbedding(maxlen=tamaño_maximo_frase_texto, \n","                                              vocab_size=y_vocab_size, \n","                                              embed_dim=tamaño_dimensiones_vectores,\n","                                              nameCust=\"Tnsf-embedding-prevText\")\n","  eachLay_text = embedding_layer(eachLay_text)\n","  aux_trnsf_tamaño_dimensiones_vectores = aux_trnsf_tamaño_dimensiones_vectores + tamaño_dimensiones_vectores\n","\n","  if esArchivoDatos:\n","    # solo si es archivo de datos\n","    # une los dos embeddings juntos para ser procesados por la red\n","    concatLay = tf.keras.layers.concatenate([eachLay, eachLay_text], name=\"MergeInputs\")\n","    eachLay = concatLay\n","\n","  else:\n","      # para archivo de texto  \n","      eachLay = eachLay_text\n","\n","\n","# caps de bloques de transformer\n","for n in range(trnsf_cant_bloques):\n","    transformer_block = TransformerBlock(embed_dim=aux_trnsf_tamaño_dimensiones_vectores,\n","                                          num_heads=trnsf_MultiHeadAttention_num_heads,\n","                                          feed_forward_dim=trnsf_MultiHeadAttention_head_size, \n","                                          dp_rate=trnsf_porc_capa_DropOut, \n","                                          nameCust=\"Tnsf-tf_\"+str(n+1))\n","    eachLay = transformer_block(eachLay)\n","\n","# hace un flatten especial\n","eachLay = tf.keras.layers.GlobalAveragePooling1D(name=\"Tnsf-gap\")(eachLay)\n","\n","# agrega capas lineales\n","auxName = 'lineal_'\n","auxId = 1 \n","for val_hid in hidden_layers:  \n","\n","  if val_hid == \"DropOut\":\n","    auxlayerName = \"d_\"+str(auxId)\n","    auxId = auxId + 1\n","    eachLay = tf.keras.layers.Dropout(lineal_porc_capa_DropOut,name=auxlayerName)(eachLay)\n","  elif val_hid == \"BatchNormalization\":\n","    auxlayerName = \"bn_\"+str(auxId)\n","    auxId = auxId + 1\n","    eachLay = tf.keras.layers.BatchNormalization(name=auxlayerName)(eachLay)\n","  elif val_hid.isnumeric():\n","    # agrega la capa oculta\n","    auxlayerName = auxName+str(auxId)\n","    auxId = auxId + 1\n","    eachLay = tf.keras.layers.Dense(int(val_hid), name=auxlayerName)(eachLay) # capas ocultas\n","\n","# agrega capa de salida\n","if (tipoProblemaAplicar == \"T\"):\n","    # se genera capa lineal con salida igual al tamaño del vocabulario\n","    outputLay = tf.keras.layers.Dense(y_vocab_size, activation='softmax', name='outputText')(eachLay) # capa de salida\n","\n","elif (tipoProblemaAplicar == \"C\") and tipo_output_softMax:\n","    # se genera una capa softmax\n","    outputLay = tf.keras.layers.Dense(units = len(CLASES), activation='softmax', name='output')(eachLay) # capa de salida\n","else:\n","    # se genera una capa lineal con una salida numérica\n","    outputLay = tf.keras.layers.Dense(1, activation=None, name='output')(eachLay) # capa de salida\n","\n","# agrega capa de salida\n","if (tipoProblemaAplicar == \"T\"):\n","    # se genera capa lineal con salida igual al tamaño del vocabulario\n","    outputLay = tf.keras.layers.Dense(y_vocab_size, name='outputText')(eachLay) # capa de salida\n","\n","elif (tipoProblemaAplicar == \"C\") and tipo_output_softMax:\n","    # se genera una capa softmax\n","    outputLay = tf.keras.layers.Dense(units = len(CLASES), activation='softmax', name='output')(eachLay) # capa de salida\n","else:\n","    # se genera una capa lineal con una salida numérica\n","    outputLay = tf.keras.layers.Dense(1, activation=None, name='output')(eachLay) # capa de salida\n","\n","\n","# genera el modelo \n","if (tipoProblemaAplicar == \"T\"):\n","    if esArchivoDatos:\n","      # para archivo de datos\n","      # modelo con 2 entradas\n","      model = keras.Model(\n","          inputs=[x_inputLay, y_inputLay], \n","          outputs=outputLay, \n","          name=\"GenText-GPT\")\n","    \n","    else:\n","      # para archivo de texto\n","      # modelo con entrada de texto previo\n","      model = keras.Model(\n","          inputs=y_inputLay, \n","          outputs=outputLay, \n","          name=\"GenText-GPT\")        \n","    \n","    # utiliza un loss especial\n","    sccLoss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    model.compile(optimizer=opt, loss=sccLoss, metrics=['accuracy'])\n","\n","else:\n","    # modelo normal\n","    model = keras.Model(\n","        inputs=x_inputLay,\n","        outputs=outputLay, \n","        name=\"Text-\"+tipoProblemaAplicar+\"-GPT\")\n","      \n","    if  tipo_output_softMax:\n","        # utiliza un loss de multiple clases\n","        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","    else:\n","        # utiliza un loss de valor numérico\n","        if (tipoProblemaAplicar == \"C\"):\n","          model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n","        else:\n","          model.compile(optimizer=opt, loss='mse', metrics=['RootMeanSquaredError'])\n","\n","print(\"Modelo creado con \", len(model.layers), \" capas:\")\n","model.summary()\n","print(\"\\n\")\n","plot_model(model, show_layer_names=True, show_shapes=True)\n","\n"],"metadata":{"cellView":"form","id":"9qBj-3TEIZyz"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MlYyhEutC_O","cellView":"form"},"source":["#@title Entrenar\n","\n","cant_epocas_entrenamiento = 15 #@param {type:\"integer\"}\n","\n","# cantidad de épocas del entrenamiento\n","cantEpocas = (1 if cant_epocas_entrenamiento<1 else cant_epocas_entrenamiento)\n","\n","activar_corte_por_estabilidad_error_val = True #@param {type:\"boolean\"}\n","\n","\n","if (tipoProblemaAplicar == \"T\"):  \n","    # entrena con múltiples entradas para generar texto\n","    # (no se usa activar_corte_por_estabilidad_error_val)\n","    print(\"\\n--- No se utilizan datos de validación ---\")\n","    if esArchivoDatos:\n","        # para archivo de datos\n","        print(\"\\n\\n>Comienza el Entrenamiento con múltiples entradas:\")\n","        history = model.fit([inputs_x_train, inputs_prevText_train], \n","                            y_trainEnc,\n","                            epochs = cant_epocas_entrenamiento) \n","    else:\n","        # para archivo de texto\n","        print(\"\\n\\n>Comienza el Entrenamiento:\")\n","        history = model.fit(inputs_prevText_train, \n","                            y_trainEnc,\n","                            epochs = cant_epocas_entrenamiento) \n","\n","else:\n","    # entrena normalmente\n","\n","    # separa al azar usando muestreo al azar del 10%\n","    # para tomar algunos como datos de validación\n","    x_t, x_v, y_t, y_v = train_test_split(x_train, \n","                                          (y_trainEnc if tipo_output_softMax else y_train), \n","                                          test_size=0.1)\n","\n","\n","    print(\"\\n> De los \", len(x_train), \"ejemplos de entrenamiento: \")\n","    print(\"            se usan \", len(x_t), \"ejemplos para entrenar \")\n","    print(\"            y \", len(x_v), \"ejemplos para validar.\")\n","\n","\n","    print(\"\\n\\n>Comienza el Entrenamiento:\")\n","\n","    if activar_corte_por_estabilidad_error_val:\n","      # se agrega un callBack para que corte \n","      # si el error de validación no sigue bajando\n","      # y devuelva los mejores pesos obtenidos\n","      early_stopping_monitor = keras.callbacks.EarlyStopping(\n","          monitor='val_loss',\n","          min_delta=0.01,\n","          patience=20,\n","          verbose=0,\n","          mode='min',\n","          baseline=None,\n","          restore_best_weights=True\n","      )\n","      callbacksEntr = [early_stopping_monitor]\n","    else:\n","      early_stopping_monitor = None\n","      callbacksEntr = []\n","\n","    # lleva a cabo el entrenamiento\n","    history = model.fit(x_t, y_t,\n","              epochs = cantEpocas, \n","              validation_data=(x_v, y_v,),\n","              callbacks=callbacksEntr ) \n","\n","print(\"\\n>Entrenamiento Finalizado.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSc0MnFGVbnR","cellView":"form"},"source":["#@title Mostrar Gráficos del Entrenamiento\n","plt.figure(figsize=(15,8)) \n","plt.plot(history.history['loss'])\n","if (tipoProblemaAplicar != \"T\"):\n","  plt.plot(history.history['val_loss'])\n","plt.title('Gráfico del Error del Entrenamiento')\n","plt.ylabel('')\n","plt.xlabel('epoch')\n","if (tipoProblemaAplicar != \"T\"):\n","  plt.legend(['entrenamiento', 'validación'], loc='upper left')\n","plt.show()\n","\n","plt.figure(figsize=(15,8)) \n","if (tipoProblemaAplicar == \"C\") or (tipoProblemaAplicar == \"T\"):\n","  plt.plot(history.history['accuracy'])\n","  if (tipoProblemaAplicar != \"T\"):\n","    plt.plot(history.history['val_accuracy'])\n","  plt.title('Gráfico de la Exactitud del Entrenamiento')\n","elif (tipoProblemaAplicar == \"E\"):\n","  plt.plot(history.history['root_mean_squared_error'])\n","  plt.plot(history.history['val_root_mean_squared_error'])\n","  plt.title('Gráfico de la Distancia Media Cuadrática Mínima del Entrenamiento')\n","  \n","plt.ylabel('')\n","plt.xlabel('epoch')\n","plt.legend(['entrenamiento', 'validación'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HKlnG0DLlSj","cellView":"form"},"source":["#@title Evaluar red entrenada con datos de entrenamiento\n","\n","mostrar_detalle_entrenamiento = False #@param {type:\"boolean\"}\n","\n","# clase especial para generar texto\n","class TextGenerator():\n","\n","  def __init__(self, model, text_encoder, tagBegin, tagEnd, sepTokens=\" \"):\n","      self.model = model\n","      self.textEncoder = text_encoder\n","      self.y_vocab = np.array(text_encoder.get_vocabulary())\n","      self.tagBegin = tagBegin\n","      self.tagEnd = tagEnd\n","      self.sepTokens = sepTokens\n","      self.cantModelInputs = self.determinarCantModelInputs()\n","\n","  def determinarCantModelInputs(self):\n","      cantInputs = 0\n","      for layer in self.model.layers:\n","        if isinstance(layer, keras.layers.InputLayer):\n","          cantInputs = cantInputs + 1\n","      return cantInputs\n","\n","  def samplePreds(self, preds, temperature):\n","      # función que se usa para generar mayor diversidad al generar texto\n","      # helper function to sample an index from a probability array\n","      preds = np.asarray(preds).astype(\"float64\")\n","      if temperature > 0.0:\n","        preds = preds / temperature\n","      ##preds = np.log(preds) / temperature\n","      ##preds = np.nan_to_num(preds)\n","      exp_preds = np.exp(preds)\n","      preds = exp_preds / np.sum(exp_preds)\n","      probas = np.random.multinomial(1, preds, 1)\n","      return np.argmax(probas)\n","\n","  def generar(self, datos=None, startText=\"\", diversity=0.5):\n","      # prepara datos\n","      if (datos is None) or (len(datos)==0):\n","        input_x = None\n","        if self.cantModelInputs == 2:\n","          raise(Exception(\"No se ha indicado los datos complementarios!\"))          \n","          return None\n","      else:\n","        input_x = np.array( [ datos ] )      \n","      # prepara texto inicio\n","      input_text = self.tagBegin \n","      pos_sgte_input_text = 1\n","      if startText != \"\":\n","        input_text = input_text + self.sepTokens + startText\n","        y_texto = startText\n","      else:\n","        y_texto = \"\"\n","      # codifica texto de inicio      \n","      input_textCodif = np.array( [ self.textEncoder(input_text) ] )\n","      # determina siguiente posición a usar\n","      if startText != \"\":\n","        for i in range(len(input_textCodif[0])):\n","          if input_textCodif[0][i] == 0:\n","            pos_sgte_input_text = i\n","            break\n","      # chequea temperatura\n","      if diversity <= 0.0:\n","        diversity = 0.001\n","      for _ in range(100):\n","        # ejecuta modelo\n","        if self.cantModelInputs == 2:\n","          y = self.model.predict( [ input_x,  input_textCodif ], verbose=0 )\n","        else:\n","          y = self.model.predict( input_textCodif, verbose=0 )\n","        # determina salida\n","        id = self.samplePreds(y[0], diversity)\n","        ##id = int( np.argmax(y[0], axis=0) )    \n","        res = self.y_vocab[id]        \n","        # contrala si tiene que termina\n","        if (id == 0) or (res == self.tagEnd):\n","            break        \n","        # concatena texto de salida sólo si es caracter válido\n","        if checkValidCharacter(res):\n","          y_texto = y_texto + self.sepTokens + res\n","        else:\n","          print(\"-- se descarta caracter inválido: (\", ord(res), \")\")\n","          print(\"\\t\\t\\t\", res)\n","        # agrega salida para siguiente ejecución del modelo       \n","        input_textCodif[0][pos_sgte_input_text] = id\n","        pos_sgte_input_text = pos_sgte_input_text + 1    \n","      return y_texto\n","\n","\n","def probarModelo_GenTextoEjemplos(gt, x, y, mostrarTodos=False):    \n","  if mostrarTodos:\n","    # muestra varios (no todos porque sino tarda demasiado)\n","    cantTotal = len(y)    \n","    tomalAlAzar = False\n","    posEj = 0\n","    print(\"    ( procesando todos los \"+str(cantTotal)+\" ejemplos )\")\n","  else:\n","    # prueba con <cantMostrar> ejemplos\n","    cantTotal = 10\n","    tomalAlAzar = True\n","    print(\"    ( procesando \"+str(cantTotal)+\" ejemplos al azar )\")\n","  if (x is None) or (len(x)==0):\n","    x = None\n","    input_datos = None\n","  auxStartText = \"\"\n","  for i in range(cantTotal):\n","    if tomalAlAzar:\n","      # toma al azar\n","      posEj = random.randint(1, len(y))-1\n","    else:\n","      # toma secuencial\n","      posEj = posEj + 1\n","    print(\"\\n\", i+1, \") Ejemplo \", posEj)\n","    if not(x is None):\n","      # ejecuta con datos\n","      input_datos = x[posEj]\n","      print(\"* Datos: \", input_datos )\n","    else:\n","      # ejecuta sin datos y pasando la primera palabra\n","      auxStartText = separarTexto(y[posEj], separadorTokens)[0]    \n","    print(\"+ Texto Original: \", y[posEj] ) \n","    if auxStartText != \"\":\n","      print(\"> se ingresa: \", auxStartText)\n","    # genera texto   \n","    for diversityPreds in [0.1, 0.5, 1.0, 1.5]:\n","      textoRes = gt.generar(datos=input_datos, startText=auxStartText, diversity=diversityPreds)\n","      print(\"- Texto Generado (diversity=\"+str(+diversityPreds)+\"): \", textoRes )  \n","    print(\"--------------------------------------------------------------\")\n","\n","\n","# función auxiliara para que no ejecute UI cada vez\n","def hacerNada():\n","  return\n","\n","def prepararUI_GenTextoIngresado():\n","    global probar_startText, probar_diversity\n","\n","    print(\"\\n\")\n","\n","    # auxiliar para que muestre bien la descripción\n","    style_3D = {'description_width': 'initial'}\n","\n","    # prepara campo para ingresar nombre clases (toma por defecto de config)\n","    probar_startText = widgets.Text(\n","        value='',\n","        placeholder='',\n","        description='Ingrese texto inicial:',\n","        style=style_3D,\n","        disabled=False\n","    )\n","\n","    probar_diversity = widgets.FloatSlider(\n","        value=0.5,\n","        min=0.1,\n","        max=2.0,\n","        step=0.1,\n","        description='Diversity Temperature:',\n","        style=style_3D,\n","        disabled=False,\n","        continuous_update=False,\n","        orientation='horizontal',\n","        readout=True,\n","        readout_format='.1f',\n","    )\n","\n","    # prepara botón y grilla con objetos\n","    btnProbar = widgets.Button(\n","        description='Probar'\n","    )\n","\n","    probarGentText_ui = widgets.GridBox(\n","          children=[probar_startText, probar_diversity, btnProbar],\n","          layout=Layout(width='100%')  )\n","    btnProbar.on_click(on_buttonProbar_clicked)\n","\n","    # clear_output()      \n","    out_probarGenText = widgets.interactive_output(hacerNada, {})  \n","    display(probarGentText_ui)\n","    print(\"\\n\")\n","\n","def on_buttonProbar_clicked(b): \n","  auxStartText = probar_startText.value\n","  divTemp = probar_diversity.value\n","  # inicializa y usa generador de texto  \n","  textoRes = gt.generar(datos=None, startText=auxStartText, diversity=divTemp)    \n","  print(\"> se ingresa: \", auxStartText)\n","  print(\"- Texto Generado: \", textoRes )  \n","  print(\"--------------------------------------------------------------\")\n","\n","# función auxiliar para el cálculo de error\n","def calcErrores(pred, real, mostrarDetalle=False):\n","  arAbs = []\n","  arRel = []\n","  \n","  if mostrarDetalle:\n","    print(\"\\n\")\n","    print(\"\\t Real \\t\\t\\t Estimado \\t\\t Error Absoluto \\t Error Relativo\")\n","\n","  for pV, r in zip(pred, real):\n","    # toma el valor estimado/predecido\n","    p = pV[0]\n","    # controla que sean números\n","    if not(math.isnan(r) or math.isnan(p)):\n","      # hace los cálculos\n","      eAbs = abs(r - p)\n","      if r != 0:\n","        eRel = (eAbs / r)*100.0\n","      else:\n","        eRel = (eAbs / 0.00001)*100.0\n","      arAbs.append(eAbs)\n","      arRel.append(eRel)\n","    \n","      if mostrarDetalle:\n","        print(\"\\t{:>8.2f} \\t\\t {:>8.2f} \\t\\t {:>8.2f} \\t\\t {:>8.2f}%\".format(r, p, eAbs, eRel))\n","\n","  return arAbs, arRel\n","\n","def generarGrafico(ar, tit, b=10, c=None):\n","     # genera gráfico de los errores\n","    fig = plt.figure(figsize=(15,5)) \n"," #   ax = fig.add_axes( [0, 0, 0.8, 0.8] )\n"," #   ax.boxplot( [arAbs, arRel] )\n"," #   ax.set_xticklabels( [\"Error Absoluto\", \"Error Relativo\"] )\n","#    plt.legend([\"Error Absoluto\", \"Error Relativo\"], loc='best')\n","    plt.hist( ar, bins=b, color=c )\n","    plt.grid(color='lightgrey', which='both', axis='both', linestyle='solid', linewidth=0.3)\n","    plt.title(\"Distribución de \"+ tit)\n","    plt.show()\n","\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo_Estimacion(x, y, detalle=False):\n","\n","    # procesa las imágenes de prueba con el modelo \n","    estimVals = model.predict(x, verbose=0)\n","\n","    # llama a la función\n","    arAbs, arRel = calcErrores(estimVals, y, detalle)\n","\n","    # muestra métricas\n","    print(\"\\n\")\n","    print(\"\\n Error Absoluto: \")\n","    print(\"            Mínimo: {:.5f} \".format(np.min(arAbs)) )\n","    print(\"            Promedio: {:.5f} ± {:.5f}\".format(np.mean(arAbs), np.std(arAbs)) )\n","    print(\"            Máximo: {:.5f} \".format(np.max(arAbs)) )\n","    generarGrafico(arAbs, \"Error Absoluto\", 20, \"red\")\n","    \n","    print(\"\\n Error Relativo: \")\n","    print(\"            Mínimo: {:.2f}% \".format(np.min(arRel)) )\n","    print(\"            Promedio: {:.2f} ± {:.2f}\".format(np.mean(arRel), np.std(arRel)) )\n","    print(\"            Máximo: {:.2f}% \".format(np.max(arRel)) )\n","    generarGrafico(arRel, \"Error Relativo\", 10, \"magenta\")\n","\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo_Clasificacion(x, y, clases_map, mostrarDetalle=False):\n","\n","    # procesa las imágenes de prueba con el modelo \n","    predClass = model.predict(x, verbose=0)\n","\n","    # muestra los resultados con las imágenes \n","    umbralClas = 0.5\n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # prepara salida\n","        clReal = clases_map[ int(y[i]) ] \n","\n","        # determina la clase predecida\n","        if tipo_output_softMax:\n","            ## determina clase predecida de acuerdo a la que tiene mayor valor\n","            idclPred = int( np.argmax(predClass[i], axis=0) )\n","            idclPredRnd = idclPred\n","        else:\n","            ## determina clase predecida de acuerdo al umbral de clasificación\n","            idclPred = predClass[i][0]       \n","            idclPredRnd = int(idclPred)\n","            if (idclPred - idclPredRnd)>0.5 and (idclPredRnd+1)<len(clases_map):\n","                    idclPredRnd = idclPredRnd + 1\n","\n","        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n","            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA\"\n","        else:      \n","            clPred = clases_map[ idclPredRnd ]\n","\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","\n","        strTitulo = 'Real: ' + str(clReal) + ' / Modelo(RNA): ' \n","        strTitulo = strTitulo + str(clPred) + ' (' + str( idclPred ) +')'   \n","        strTitulo = strTitulo + \": \" + (\"ok\" if (clPred==clReal) else \"error!\")\n","\n","        # muestra comparación con la imagen\n","        if mostrarDetalle:\n","          print(strTitulo)\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds))\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión ( real / modelo ): ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm, \n","        index=['r:{:}'.format(x) for x in clases_map], \n","        columns=['m:{:}'.format(x) for x in clases_map]\n","      )\n","    # agrega para poder mostrar la matrix de confusión completa\n","    pd.options.display.max_rows = 100\n","    pd.options.display.max_columns = 100\n","    cmtx.sort_index(axis=0, inplace=True)\n","    cmtx.sort_index(axis=1, inplace=True)    \n","    print(cmtx)\n","    print(\"\\n\")\n","\n","    # gráfico de comparación\n","    plt.title('Gráfico de Confusión: ')\n","    plt.xlabel('Real')\n","    plt.ylabel('Modelo')\n","    plt.scatter(classReal, classPreds)\n","\n","# prueba con los datos de entrenamiento\n","print(\"*** Resultados con datos de Entrenamiento: \")\n","if (tipoProblemaAplicar == \"T\"):\n","  # inicializa y usa generador de texto\n","  gt = TextGenerator(model, y_encoderLay, tag_gentext_begin, tag_gentext_end, separadorTokens)  \n","  # prueba gen texto  \n","  probarModelo_GenTextoEjemplos(gt, x_train, y_train, mostrar_detalle_entrenamiento)\n","  # prepara interface para ingresar otro texto\n","  # (se usa en la de prueba)\n","  ##prepararUI_GenTextoIngresado()\n","elif (tipoProblemaAplicar == \"C\"):\n","  # prueba clasificación\n","  probarModelo_Clasificacion(x_train, y_train, CLASES, mostrar_detalle_entrenamiento)\n","else:\n","  # prueba estimación\n","  probarModelo_Estimacion(x_train, y_train, mostrar_detalle_entrenamiento)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A15K-9TRtq7U","cellView":"form"},"source":["#@title Evaluar red entrenada con datos de prueba\n","mostrar_detalle_prueba = False #@param {type:\"boolean\"}\n","\n","if (tipoProblemaAplicar != \"T\"):\n","  # evalua al modelo entrenado\n","  resEval = model.evaluate(x_test, (y_testEnc if tipo_output_softMax else y_test), verbose=0)\n","  print(\"\\n>Evaluación del Modelo: \")\n","  print(\"    - Error: \", round(resEval[0],3))\n","  if (tipoProblemaAplicar == \"C\"):\n","    print(\"    - Exactitud: \", round(resEval[1]*100,2))\n","  else:\n","    print(\"    - Distancia Media Cuadrática Mínima: \", round(resEval[1],3))\n","  \n","# prueba con los datos de prueba\n","print(\"\\n\\n*** Resultados con datos de Prueba: \")\n","if (tipoProblemaAplicar == \"T\"):\n","  if esArchivoDatos:\n","    # prueba gen texto con ejemplos de datos\n","    probarModelo_GenTextoEjemplos(gt, x_test, y_test, mostrar_detalle_prueba)\n","  else:\n","    # para archivo de textos\n","    # prepara interface para ingresar otro texto\n","    prepararUI_GenTextoIngresado()\n","elif (tipoProblemaAplicar == \"C\"):\n","  # prueba clasificación\n","  probarModelo_Clasificacion(x_test, y_test, CLASES, mostrar_detalle_prueba)\n","else:\n","  # prueba estimación\n","  probarModelo_Estimacion(x_test, y_test, mostrar_detalle_prueba)\n"],"execution_count":null,"outputs":[]}]}